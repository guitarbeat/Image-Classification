{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Focus and Astigmatism Classifier\n",
    "- **Author:** [Aaron Woods](https://aaronwoods.info)\n",
    "- **Date Created:** September 21, 2023\n",
    "- **Repository:** [Image Classification on VSCode](https://insiders.vscode.dev/tunnel/midnightsim/c:/Users/User/Desktop/Image-Classification)\n",
    "\n",
    "### Description\n",
    "This script provides an end-to-end machine learning pipeline for image classification. It can categorize images as \"In Focus\" or \"Out of Focus\" while also detecting astigmatism-related issues. The design is modular, making it adaptable to various image classification tasks.\n",
    "\n",
    "### Features\n",
    "- Ingests data from Excel spreadsheets.\n",
    "- Utilizes multiple machine learning models.\n",
    "- Modular design for easy customization.\n",
    "\n",
    "### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Package Installation (Optional)\n",
    "# ------------------------------\n",
    "# Uncomment the following lines to install required packages if running on a new machine.\n",
    "\n",
    "%pip install opencv-python numpy pandas matplotlib protobuf seaborn scikit-learn openpyxl\n",
    "\n",
    "# ------------------------------\n",
    "# TensorFlow Installation with GPU Support\n",
    "# ------------------------------\n",
    "# Note: TensorFlow versions above 2.10 are not supported on GPUs on native Windows installations.\n",
    "# For more details, visit: https://www.tensorflow.org/install/pip#windows-wsl2_1\n",
    "\n",
    "# Uncomment the following line to install TensorFlow if needed.\n",
    "# %pip install \"tensorflow<2.11\" --user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# System and TensorFlow Info Check\n",
    "# ------------------------------\n",
    "import platform\n",
    "import tensorflow as tf\n",
    "\n",
    "def get_system_info():\n",
    "    \"\"\"Get system and TensorFlow information.\"\"\"\n",
    "    system_info = {\"Platform\": platform.platform(), \"Python Version\": platform.python_version()}\n",
    "    \n",
    "    try:\n",
    "        system_info.update({\n",
    "            \"TensorFlow Version\": tf.__version__,\n",
    "            \"Num GPUs Available\": len(tf.config.list_physical_devices('GPU'))\n",
    "        })\n",
    "        system_info['Instructions'] = (\n",
    "            \"You're all set to run your model on a GPU.\" \n",
    "            if system_info['Num GPUs Available'] \n",
    "            else (\n",
    "                \"No GPUs found. To use a GPU, follow these steps:\\n\"\n",
    "                \"  1. Install NVIDIA drivers for your GPU.\\n\"\n",
    "                \"  2. Install a compatible CUDA toolkit.\\n\"\n",
    "                \"  3. Install the cuDNN library.\\n\"\n",
    "                \"  4. Make sure to install the GPU version of TensorFlow.\"\n",
    "            )\n",
    "        )\n",
    "    except ModuleNotFoundError:\n",
    "        system_info['Instructions'] = (\n",
    "            \"TensorFlow is not installed. \"\n",
    "            \"Install it using pip by running: !pip install tensorflow\"\n",
    "        )\n",
    "    \n",
    "    return system_info\n",
    "\n",
    "def configure_gpu_memory_growth():\n",
    "    \"\"\"Set GPU memory consumption growth to avoid OOM errors.\"\"\"\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "# Call functions to get system info and configure GPU memory.\n",
    "system_info = get_system_info()\n",
    "configure_gpu_memory_growth()\n",
    "\n",
    "# Print system information.\n",
    "formatted_info = \"\\n\".join(f\"{key}: {value}\" for key, value in system_info.items())\n",
    "print(formatted_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Import Libraries\n",
    "# ------------------------------\n",
    "\n",
    "# Standard Libraries\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import glob\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "# Third-Party Libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from IPython.display import clear_output\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "\n",
    "# TensorFlow and Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
    "from tensorflow.keras.callbacks import TensorBoard, Callback\n",
    "from tensorflow.keras.applications import InceptionV3, ResNet50\n",
    "from keras.models import load_model\n",
    "from tensorflow.data import Dataset\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Type Annotations\n",
    "from typing import List, Dict, Tuple, Union, Any, Optional\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict\n",
    "\n",
    "from sklearn.utils import resample\n",
    "import pandas as pd\n",
    "from typing import Dict, Any\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import callbacks, optimizers\n",
    "import os\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from matplotlib.legend_handler import HandlerTuple\n",
    "\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration Dictionary\n",
    "experiment_config = {\n",
    "    'NAME': \"PC_balanced_GPU_upsampled\",            # Experiment name\n",
    "    'RANDOM_SEED': 42,                             # Seed for reproducibility\n",
    "    'PROBLEM_TYPE': 'Multi-Output',                # Problem type: Binary, Multi-Class, Multi-Output, Multi-Label\n",
    "}\n",
    "\n",
    "model_config = {\n",
    "    'IMG_SIZE': 224,                               # Image input size\n",
    "    'BATCH_SIZE': 16,                              # Batch size for training\n",
    "    'TRAIN_SIZE': 0.8,                             # Fraction of data to use for training\n",
    "    'VAL_SIZE': 0.5,                               # Fraction of data to use for validation\n",
    "    'EPOCHS': 100,                                 # Number of training epochs\n",
    "    'LEARNING_RATE': 0.001,                        # Learning rate 1e-3\n",
    "    'EARLY_STOPPING_PATIENCE': 50,                 # Early stopping patience\n",
    "    'REDUCE_LR_PATIENCE': 3,                       # Reduce learning rate on plateau patience\n",
    "    'MIN_LR': 1e-6,                                # Minimum learning rate\n",
    "}\n",
    "\n",
    "label_mappings = {\n",
    "    'Focus_Label': {'SharpFocus': 0, 'SlightlyBlurred': 1, 'HighlyBlurred': 2},\n",
    "    'StigX_Label': {'OptimalStig_X': 0, 'ModerateStig_X': 1, 'SevereStig_X': 2},\n",
    "    'StigY_Label': {'OptimalStig_Y': 0, 'ModerateStig_Y': 1, 'SevereStig_Y': 2},\n",
    "}\n",
    "\n",
    "augmentation_config = {\n",
    "    'rotation_factor': 0.002,\n",
    "    'height_factor': (-0.18, 0.18),\n",
    "    'width_factor': (-0.18, 0.18),\n",
    "    'contrast_factor': 0.5,\n",
    "}\n",
    "\n",
    "# Combine Experiment, Model, Labels, and Augmentation Configurations\n",
    "config = {\n",
    "    'Experiment': experiment_config,\n",
    "    'Model': model_config,\n",
    "    'Labels': {'MAPPINGS': label_mappings},\n",
    "    'Augmentation': augmentation_config\n",
    "}\n",
    "\n",
    "# Dataset Creation Configuration\n",
    "csv_config = {\n",
    "    'CSV': {\n",
    "        'COLUMNS_TO_READ': ['ImageFile', 'Focus_Offset (V)', 'Stig_Offset_X (V)', 'Stig_Offset_Y (V)']\n",
    "    },\n",
    "    'Thresholds': {\n",
    "        'FOCUS_LOW': 30,                              # Lower focus threshold\n",
    "        'FOCUS_HIGH': 60,                             # Upper focus threshold\n",
    "        \n",
    "        'STIGX_LOW': 1,                               # Lower astigmatism threshold\n",
    "        'STIGX_HIGH': 2,                              # Upper astigmatism threshold\n",
    "        \n",
    "        'STIGY_LOW': 1,                               # Lower astigmatism threshold\n",
    "        'STIGY_HIGH': 2,                              # Upper astigmatism threshold\n",
    "    },\n",
    "    'Paths': {\n",
    "        'OLD_BASE_PATH': \"D:\\\\DOE\\\\\",\n",
    "        \n",
    "        # On Simulation Computer\n",
    "        # 'DATA_FILE': \"combined_output.csv\",\n",
    "        # 'NEW_BASE_PATH': \"Y:\\\\User\\\\Aaron-HX38\\\\DOE\\\\\", \n",
    "        \n",
    "        # On Laptop\n",
    "        'DATA_FILE': \"combined_output_cleaned.csv\",\n",
    "        'NEW_BASE_PATH': \"C:\\\\Users\\\\aaron.woods\\\\OneDrive - Thermo Fisher Scientific\\\\Desktop\\\\Dec 24\\\\\",\n",
    "    },\n",
    "    'SAMPLE_FRAC': 1,                                # Fraction of the data for quicker prototyping (1.0 means use all data)\n",
    "}\n",
    "\n",
    "# Update the main configuration dictionary with the dataset configuration\n",
    "config.update(csv_config)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(config['Experiment']['RANDOM_SEED'])\n",
    "tf.random.set_seed(config['Experiment']['RANDOM_SEED'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions for Preparation of CSV\n",
    "\n",
    "def read_csv(config: Dict):\n",
    "    # Functionality to read the data\n",
    "    data_file_path = os.path.join(config['Paths']['NEW_BASE_PATH'], config['Paths']['DATA_FILE'])\n",
    "    if not os.path.exists(data_file_path):\n",
    "        raise FileNotFoundError(f\"Error: File does not exist - {data_file_path}\")\n",
    "    try:\n",
    "        data = pd.read_csv(data_file_path, usecols=config['CSV']['COLUMNS_TO_READ'])\n",
    "        print(\"---> Data read successfully.\")\n",
    "        sample_frac = config.get('SAMPLE_FRAC', 1.0)\n",
    "        if 0 < sample_frac < 1.0:\n",
    "            data = data.sample(frac=sample_frac).reset_index(drop=True)\n",
    "            print(f\"---> Data sampled: Using {sample_frac * 100}% of the available data.\")\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error: Could not read data - {e}\") from e\n",
    "    return data\n",
    "\n",
    "def update_image_paths(df):\n",
    "    old_base_path = config['Paths']['OLD_BASE_PATH']\n",
    "    new_base_path = config['Paths']['NEW_BASE_PATH']\n",
    "    df['ImageFile'] = df['ImageFile'].str.replace(old_base_path, new_base_path, regex=False)\n",
    "    print(\"---> Image paths updated.\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def clean_csv(df: pd.DataFrame, save_cleaned: bool = False) -> pd.DataFrame:\n",
    "    def is_valid_string(image_path) -> bool:\n",
    "        return isinstance(image_path, str)\n",
    "    \n",
    "    def does_file_exist(image_path) -> bool:\n",
    "        return os.path.exists(image_path)\n",
    "    \n",
    "    def can_image_be_read(image_path) -> bool:\n",
    "        img = cv2.imread(image_path)\n",
    "        return img is not None\n",
    "    \n",
    "    removal_reasons = defaultdict(list)\n",
    "    total_rows = len(df)\n",
    "    csv_file_path = os.path.join(config['Paths']['NEW_BASE_PATH'], config['Paths']['DATA_FILE'])\n",
    "    print(\"Cleaning CSV file...\")\n",
    "    for index, row in enumerate(df.itertuples()):\n",
    "        progress = (index + 1) / total_rows * 100\n",
    "        print(f\"\\rProgress: {progress:.2f}%\", end=\"\")\n",
    "        \n",
    "        image_path = row.ImageFile\n",
    "        reason = None\n",
    "        \n",
    "        if not is_valid_string(image_path):\n",
    "            reason = \"Invalid ImageFile value - not a string\"\n",
    "        elif not does_file_exist(image_path):\n",
    "            reason = \"File does not exist\"\n",
    "        elif not can_image_be_read(image_path):\n",
    "            reason = \"Image can't be read\"\n",
    "        \n",
    "        if reason:\n",
    "            removal_reasons[reason].append(index)\n",
    "    \n",
    "    invalid_rows = [index for indices in removal_reasons.values() for index in indices]\n",
    "    df.drop(index=invalid_rows, inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    print(\"\\n\\nSummary of row removals:\")\n",
    "    for reason, indices in removal_reasons.items():\n",
    "        print(f\"{len(indices)} rows removed due to: {reason}\")\n",
    "        print(f\"Row indices: {indices}\")\n",
    "    \n",
    "    if save_cleaned and csv_file_path:\n",
    "        cleaned_csv_file_path = f\"{os.path.splitext(csv_file_path)[0]}_cleaned.csv\"\n",
    "        df.to_csv(cleaned_csv_file_path, index=False)\n",
    "        print(f\"Cleaned CSV saved to: {cleaned_csv_file_path}\")\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generating labels\n",
    "\n",
    "def generate_thresholds(label_key):\n",
    "    low_key = f\"{label_key.split('_')[0].upper()}_LOW\"\n",
    "    high_key = f\"{label_key.split('_')[0].upper()}_HIGH\"\n",
    "    return config.get('Thresholds', {}).get(low_key, 0), config.get('Thresholds', {}).get(high_key, 0)\n",
    "\n",
    "def generate_single_label(df_copy, label_key, offset_column, choices_dict):\n",
    "    low_threshold, high_threshold = generate_thresholds(label_key)\n",
    "    conditions = [\n",
    "        (df_copy[offset_column].abs() <= low_threshold),\n",
    "        (df_copy[offset_column].abs() > low_threshold) & (df_copy[offset_column].abs() <= high_threshold),\n",
    "        (df_copy[offset_column].abs() > high_threshold)\n",
    "    ]\n",
    "    choices = list(choices_dict.keys())\n",
    "    df_copy[label_key] = np.select(conditions, choices, default='Unknown')\n",
    "    le = LabelEncoder()\n",
    "    df_copy[label_key] = le.fit_transform(df_copy[label_key])\n",
    "    return le\n",
    "\n",
    "def generate_labels(df: pd.DataFrame):\n",
    "    print(\"---> Generating labels for Focus, StigX, and StigY...\")\n",
    "    labels_config = config.get('Labels', {}).get('MAPPINGS', {})\n",
    "    offset_column_mapping = {'Focus_Label': 'Focus_Offset (V)', 'StigX_Label': 'Stig_Offset_X (V)', 'StigY_Label': 'Stig_Offset_Y (V)'}\n",
    "\n",
    "    df_copy = df.copy()\n",
    "    label_encoders = {}\n",
    "\n",
    "    for label_key, choices_dict in labels_config.items():\n",
    "        offset_column = offset_column_mapping.get(label_key)\n",
    "        if not offset_column:\n",
    "            print(f\"Warning: No offset column mapping found for '{label_key}'. Skipping label generation.\")\n",
    "            continue\n",
    "        if offset_column not in df.columns:\n",
    "            print(f\"Warning: Column '{offset_column}' not found in DataFrame. Skipping label generation for '{label_key}'.\")\n",
    "            continue\n",
    "        label_encoders[label_key] = generate_single_label(df_copy, label_key, offset_column, choices_dict)\n",
    "        print(f\"---> Labels generated for {label_key}\")\n",
    "\n",
    "    if config.get('Experiment', {}).get('PROBLEM_TYPE') == 'Multi-Output':\n",
    "        df_copy['Multi_Output_Labels'] = df_copy.apply(lambda row: [row[key] for key in labels_config.keys()], axis=1)\n",
    "        print(\"---> Multi-Output Labels generated.\")\n",
    "        \n",
    "    return df_copy, label_encoders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Shuffling and Splitting the Data\n",
    "\n",
    "def shuffle_and_reset_index(data):\n",
    "    print(\"---> Shuffling and resetting index...\")\n",
    "    shuffled_df = data.sample(frac=1, random_state=config['Experiment']['RANDOM_SEED']).reset_index(drop=True)\n",
    "    print(\"---> Data shuffled and index reset.\")\n",
    "    return shuffled_df\n",
    "\n",
    "def prepare_datasets(df: pd.DataFrame):\n",
    "    \"\"\"Prepare training, validation, and test datasets.\"\"\"\n",
    "    # Check if DataFrame is empty\n",
    "    if df is None or df.empty:\n",
    "        print(\"Warning: DataFrame is empty. Cannot proceed with data preparation.\")\n",
    "        return {'train': None, 'valid': None, 'test': None}\n",
    "    # Split Data\n",
    "    try:\n",
    "        train_df, temp_df = train_test_split(df, test_size=1 - config['Model']['TRAIN_SIZE'], random_state=config['Experiment']['RANDOM_SEED'])\n",
    "        val_df, test_df = train_test_split(temp_df, test_size=1 - config['Model']['VAL_SIZE'], random_state=config['Experiment']['RANDOM_SEED'])\n",
    "    except ValueError:\n",
    "        print(\"Not enough data to split into training, validation, and test sets.\")\n",
    "        return {'train': None, 'valid': None, 'test': None}\n",
    "    print(\"---> Data split into training, validation, and test sets.\")\n",
    "    return {'train': train_df, 'valid': val_df, 'test': test_df}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Computting Class Weights\n",
    "\n",
    "def compute_class_weights_for_label(split: str, df: pd.DataFrame, label: str, label_encoders: Dict[str, LabelEncoder], all_records: List[Dict], is_multi_label: bool = False) -> None:\n",
    "    y_data = df[label].values if is_multi_label else df[label]\n",
    "    unique_labels = np.unique(y_data)\n",
    "    class_weights = compute_class_weight('balanced', classes=unique_labels, y=y_data)\n",
    "    class_weights_dict = dict(zip(unique_labels, class_weights))\n",
    "    \n",
    "    for cls, weight in class_weights_dict.items():\n",
    "        cnt = Counter(y_data)[cls]\n",
    "        original_class = label_encoders[label].inverse_transform([cls])[0]\n",
    "        all_records.append({\n",
    "            'split': split,\n",
    "            'label': label,\n",
    "            'class': original_class,\n",
    "            'Count': cnt,\n",
    "            'Weight': weight\n",
    "        })\n",
    "\n",
    "def compute_and_store_class_weights(datasets: Dict[str, pd.DataFrame], label_encoders: Dict[str, LabelEncoder]) -> pd.DataFrame:\n",
    "    problem_type = config.get('Experiment', {}).get('PROBLEM_TYPE', 'Binary')\n",
    "    all_records = []\n",
    "    \n",
    "    for split, df in datasets.items():\n",
    "        if df is None:\n",
    "            continue\n",
    "        for label in config['Labels']['MAPPINGS']:\n",
    "            compute_class_weights_for_label(\n",
    "                split, df, label, label_encoders, all_records, \n",
    "                is_multi_label=(problem_type == 'Multi-label')\n",
    "            )\n",
    "                \n",
    "    df_class_weights = pd.DataFrame.from_records(all_records)\n",
    "    df_class_weights.set_index(['split', 'label', 'class'], inplace=True)\n",
    "    return df_class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating Tensorflow Datasets\n",
    "\n",
    "def create_tf_datasets_from_dfs(dfs: Dict[str, pd.DataFrame], include_offset: bool = False) -> Dict[str, Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Create TensorFlow datasets from DataFrames for training, validation, and testing.\n",
    "    \"\"\"\n",
    "    problem_type = config.get('Experiment', {}).get('PROBLEM_TYPE')\n",
    "    batch_size = config.get('Model', {}).get('BATCH_SIZE', 32)\n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "    \n",
    "    preprocessing_layers = create_preprocessing_layers()\n",
    "    augmentation_layers = create_augmentation_layers()\n",
    "    \n",
    "    def load_and_preprocess_image(file_path: tf.Tensor, label: tf.Tensor, offset: Optional[tf.Tensor], augment: bool = False) -> Tuple:\n",
    "        file_path_str = file_path.numpy().decode('utf-8')\n",
    "        image = read_and_convert_image(file_path_str)\n",
    "        image = preprocessing_layers(image)\n",
    "        if augment:\n",
    "            image = augmentation_layers(image)\n",
    "            image = tf.clip_by_value(image, 0.0, 1.0)\n",
    "        label = tf.cast(label, tf.int32)\n",
    "        offset = tf.cast(offset, tf.float32) if offset is not None else None\n",
    "        return (image, label, offset) if include_offset else (image, label)\n",
    "\n",
    "    def prepare_dataset(file_paths, labels, offsets, augment):\n",
    "        ds = tf.data.Dataset.from_tensor_slices((file_paths, labels, offsets))\n",
    "        ds = ds.map(lambda file_path, label, offset: tf.py_function(\n",
    "            func=load_and_preprocess_image,\n",
    "            inp=[file_path, label, offset if offset is not None else tf.constant([], dtype=tf.float32), augment],\n",
    "            Tout=[tf.float32, label.dtype, tf.float32] if include_offset else [tf.float32, label.dtype]\n",
    "        ))\n",
    "        return ds.batch(batch_size).prefetch(buffer_size=AUTOTUNE) # If I have a lot of memory, I can use cache() here.\n",
    "\n",
    "    tf_datasets = {'train': {}, 'valid': {}, 'test': {}}\n",
    "    offset_column_mapping = {\n",
    "        'Focus_Label': 'Focus_Offset (V)',\n",
    "        'StigX_Label': 'Stig_Offset_X (V)',\n",
    "        'StigY_Label': 'Stig_Offset_Y (V)'\n",
    "    }\n",
    "\n",
    "    for split, df in dfs.items():\n",
    "        augment_data = (split == 'train')\n",
    "        if problem_type in ['Multi-Class', 'Binary']:\n",
    "            for label in ['Focus_Label', 'StigX_Label', 'StigY_Label']:\n",
    "                offset_column = offset_column_mapping.get(label)\n",
    "                offsets = df[offset_column].values if include_offset else None\n",
    "                tf_datasets[split][label] = prepare_dataset(df['ImageFile'].values, df[label].values, offsets, augment_data)\n",
    "        \n",
    "        elif problem_type == 'Multi-Output':\n",
    "            labels = df[['Focus_Label', 'StigX_Label', 'StigY_Label']].values\n",
    "            offsets = df[['Focus_Offset (V)', 'Stig_Offset_X (V)', 'Stig_Offset_Y (V)']].values if include_offset else None\n",
    "            tf_datasets[split]['Multi_Output'] = prepare_dataset(df['ImageFile'].values, labels, offsets, augment_data)\n",
    "        \n",
    "        else:\n",
    "            print(\"Unknown problem type specified in config. Please check.\")\n",
    "\n",
    "    return tf_datasets\n",
    "\n",
    "### Image Augmentation and Preprocessing\n",
    "\n",
    "def create_preprocessing_layers() -> keras.Sequential:\n",
    "    \"\"\"Create preprocessing layers for resizing and rescaling images.\"\"\"\n",
    "    img_size = config['Model']['IMG_SIZE']\n",
    "    return keras.Sequential([\n",
    "        layers.Resizing(img_size, img_size),\n",
    "        layers.Rescaling(1./255)\n",
    "    ])\n",
    "\n",
    "def create_augmentation_layers() -> keras.Sequential:\n",
    "    \"\"\"Create data augmentation layers.\"\"\"\n",
    "    aug_config = config['Augmentation']\n",
    "    try:\n",
    "        return keras.Sequential([\n",
    "            layers.RandomFlip(\"horizontal\"),\n",
    "            layers.RandomFlip(\"vertical\"),\n",
    "            layers.RandomRotation(aug_config['rotation_factor']),\n",
    "            layers.RandomTranslation(\n",
    "                height_factor=aug_config['height_factor'],\n",
    "                width_factor=aug_config['width_factor'],\n",
    "                fill_mode=\"reflect\"\n",
    "            ),\n",
    "            layers.RandomContrast(aug_config['contrast_factor']),\n",
    "        ])\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while creating augmentation layers: {e}\")\n",
    "        return None\n",
    "\n",
    "def read_and_convert_image(file_path: str) -> tf.Tensor:\n",
    "    \"\"\"Read an image from a file and convert it to a 3-channel tensor.\"\"\"\n",
    "    image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if image is None:\n",
    "        print(\"Failed to read the image.\")\n",
    "        return None\n",
    "    image = tf.convert_to_tensor(image, dtype=tf.float32)\n",
    "    image = tf.expand_dims(image, axis=-1)\n",
    "    return tf.image.grayscale_to_rgb(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Resample Datasets to deal with Imbalances (Optional)\n",
    "\n",
    "def validate_inputs(datasets: Dict[str, pd.DataFrame], resample_label: str, resample_strategy: str) -> None:\n",
    "    if not isinstance(datasets, dict):\n",
    "        raise ValueError(\"Input datasets should be a dictionary.\")\n",
    "    if resample_strategy not in [\"upsample\", \"downsample\", \"combined\"]:\n",
    "        raise ValueError(\"Invalid resample_strategy. Choose from 'upsample', 'downsample', or 'combined'.\")\n",
    "    for key, df in datasets.items():\n",
    "        if resample_label not in df.columns:\n",
    "            raise ValueError(f\"'{resample_label}' is not a valid column in the {key} dataset.\")\n",
    "\n",
    "def target_count_for_strategy(label_counts: pd.Series, strategy: str) -> int:\n",
    "    if strategy == \"downsample\":\n",
    "        return label_counts.min()\n",
    "    elif strategy == \"upsample\":\n",
    "        return label_counts.max()\n",
    "    return int(label_counts.median())\n",
    "\n",
    "def iterative_resampling(df: pd.DataFrame, resample_strategy: str, resample_label: str) -> pd.DataFrame:\n",
    "    label_counts = df[resample_label].apply(tuple).value_counts()\n",
    "    target_count = target_count_for_strategy(label_counts, resample_strategy)\n",
    "    subsets = [\n",
    "        resample(\n",
    "            df[df[resample_label].apply(tuple) == unique_label],\n",
    "            replace=(label_counts[unique_label] < target_count),\n",
    "            n_samples=target_count\n",
    "        )\n",
    "        for unique_label in label_counts.keys()\n",
    "    ]\n",
    "    return pd.concat(subsets).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "def resample_datasets(datasets: Dict[str, pd.DataFrame], resample_label='Multi_Output_Labels', resample_strategy=\"downsample\") -> Dict[str, pd.DataFrame]:\n",
    "    validate_inputs(datasets, resample_label, resample_strategy)\n",
    "    \n",
    "    int32_columns = [col for col, dtype in datasets.get('train', pd.DataFrame()).dtypes.items() if dtype == 'int32']\n",
    "    \n",
    "    def process_dataset(key: str, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        if key != 'train':\n",
    "            return df\n",
    "        resampled_data = iterative_resampling(df, resample_strategy, resample_label)\n",
    "        for col in int32_columns:\n",
    "            resampled_data[col] = resampled_data[col].astype('int32')\n",
    "        return resampled_data\n",
    "    \n",
    "    return {key: process_dataset(key, df) for key, df in datasets.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🚀 Enhanced Data Loading and Preprocessing Workflow\n",
    "\n",
    "print(\"\\n🔍 [START] Preprocessing CSV Data...\")\n",
    "data = read_csv(config)\n",
    "data = update_image_paths(data)\n",
    "# Uncomment the below line if you want to clean the CSV\n",
    "# data = clean_csv(data, save_cleaned=True)\n",
    "data, label_encoders = generate_labels(data)\n",
    "data = shuffle_and_reset_index(data)\n",
    "\n",
    "print(\"\\n📊 [LOAD] Preparing TensorFlow Datasets...\")\n",
    "datasets = prepare_datasets(data)\n",
    "print(\"  🏋️‍♂️ Computing class weights for original datasets...\")\n",
    "df_class_weights = compute_and_store_class_weights(datasets, label_encoders)\n",
    "\n",
    "print(\"\\n  🔁 Resampling datasets... (Optional)\")\n",
    "resampled_datasets = resample_datasets(datasets, resample_label='Multi_Output_Labels', resample_strategy=\"upsample\")\n",
    "print(\"  🏋️‍♀️ Computing class weights for resampled datasets...\")\n",
    "rdf_class_weights = compute_and_store_class_weights(resampled_datasets, label_encoders)\n",
    "\n",
    "print(\"\\n🔧 [BUILD] Creating TensorFlow datasets from DataFrames...\")\n",
    "datasets = create_tf_datasets_from_dfs(datasets, include_offset=True)\n",
    "resampled_datasets = create_tf_datasets_from_dfs(resampled_datasets, include_offset=True)\n",
    "\n",
    "print(\"\\n✅ [DONE] Preprocessing Complete!\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Class Distributions\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def add_annotations(ax, bars, sub_df):\n",
    "    \"\"\"\n",
    "    Adds annotations to the bars.\n",
    "    \"\"\"\n",
    "    for bar, (_, row) in zip(bars, sub_df.iterrows()):\n",
    "        x = bar.get_x() + bar.get_width() / 2.0\n",
    "        y = bar.get_height() + 0.5  # Shift annotation slightly above the bar for clarity\n",
    "        ax.annotate(f\"C: {int(row['Count'])}\\nW: {row['Weight']:.2f}\", \n",
    "                    (x, y), \n",
    "                    ha='center', \n",
    "                    va='bottom', \n",
    "                    fontsize=8)\n",
    "\n",
    "def plot_single_split(ax, df, split):\n",
    "    \"\"\"\n",
    "    Plots the class distribution for a single split (train/test/valid).\n",
    "    \"\"\"\n",
    "    filtered_df = df.loc[split]\n",
    "    x_ticks = []\n",
    "    x_tick_locs = []\n",
    "    current_x = 0  # Keep track of the current x-location for ticks\n",
    "    \n",
    "    labels = filtered_df.index.get_level_values('label').unique()\n",
    "    for label in labels:\n",
    "        sub_df = filtered_df.loc[label]\n",
    "        bars = ax.bar(sub_df.index, sub_df['Count'], label=f\"{label}\")\n",
    "        add_annotations(ax, bars, sub_df)\n",
    "        \n",
    "        x_ticks.extend([f\"{label}_{cls}\" for cls in sub_df.index])\n",
    "        x_tick_locs.extend([current_x + i for i in range(len(sub_df.index))])\n",
    "        current_x += len(sub_df.index)  # Update the x-location for the next set of bars\n",
    "    \n",
    "    ax.legend()\n",
    "    ax.set_xticks(x_tick_locs)  # Set tick locations\n",
    "    ax.set_xticklabels(x_ticks, rotation=90, fontsize=8)  # Set tick labels\n",
    "    ax.set_title(f\"{split.capitalize()} Data\")\n",
    "    ax.set_ylabel(\"Count\")  # Indicate that the bars represent counts\n",
    "\n",
    "\n",
    "def plot_dataset_info(df):\n",
    "    \"\"\"\n",
    "    Plots the class distribution for train, valid, and test splits.\n",
    "    \"\"\"\n",
    "    splits = ['train', 'valid', 'test']\n",
    "    fig, axs = plt.subplots(1, len(splits), figsize=(20, 8))\n",
    "    \n",
    "    for i, split in enumerate(splits):\n",
    "        plot_single_split(axs[i], df, split)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "plot_dataset_info(df_class_weights)\n",
    "plot_dataset_info(rdf_class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot Images from Dataset\n",
    "\n",
    "import textwrap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_single_image(ax, image, label_names, offsets):\n",
    "    \"\"\"\n",
    "    Plots a single image with associated labels and offsets.\n",
    "    \"\"\"\n",
    "    ax.imshow(image)\n",
    "    title_text = \", \".join(f\"{name} ({offset})\" for name, offset in zip(label_names, offsets))\n",
    "    ax.set_title(\"\\n\".join(textwrap.wrap(title_text, 30)))  # Wrap text to fit into the subplot\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "def extract_and_transform_labels(labels, label_keys, label_encoders):\n",
    "    \"\"\"\n",
    "    Extracts and transforms labels using label encoders.\n",
    "    \"\"\"\n",
    "    label_names = []\n",
    "    for label_value, label_key in zip(labels, label_keys):\n",
    "        label_encoder = label_encoders.get(label_key, None)\n",
    "        if label_encoder:\n",
    "            label_names.append(label_encoder.inverse_transform([label_value])[0])\n",
    "        else:\n",
    "            label_names.append(str(label_value))\n",
    "    return label_names\n",
    "\n",
    "def plot_images_from_dataset(label_encoders, config, datasets):\n",
    "    \"\"\"\n",
    "    Plots images, labels, and offsets (if available) from the provided datasets.\n",
    "    \n",
    "    Args:\n",
    "        label_encoders (dict): Dictionary of label encoders for each label key.\n",
    "        config (dict): Configuration dictionary containing problem type and other parameters.\n",
    "        datasets (dict): Dictionary of datasets, containing training data for each label key.\n",
    "    \"\"\"\n",
    "    label_keys = ['Focus_Label', 'StigX_Label', 'StigY_Label']\n",
    "    problem_type = config['Experiment']['PROBLEM_TYPE']\n",
    "\n",
    "    plt.rcParams.update({'font.size': 8})\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(12, 12))\n",
    "\n",
    "    # Helper function to get relevant dataset based on problem type\n",
    "    def get_relevant_dataset(problem_type, label_key):\n",
    "        return datasets['train'][label_key if problem_type in ['Multi-Class', 'Binary'] else 'Multi_Output']\n",
    "\n",
    "    # If problem type is not Multi-Output, re-use the same logic for both Binary and Multi-Class\n",
    "    relevant_datasets = [label_keys] if problem_type != \"Multi-Output\" else [\"Multi_Output\"]\n",
    "\n",
    "    for label_key in relevant_datasets:\n",
    "        label_encoder = label_encoders.get(label_key, None)\n",
    "        fig.suptitle(f\"Images for {label_key}\")\n",
    "\n",
    "        for data in get_relevant_dataset(problem_type, label_key).take(1):\n",
    "            images, labels = data[:2]\n",
    "            offsets = data[2] if len(data) > 2 else None\n",
    "\n",
    "            for i in range(min(len(images), 9)):\n",
    "                ax = axes[i // 3, i % 3]\n",
    "                current_labels = labels[i].numpy() if problem_type == \"Multi-Output\" else [labels[i].numpy()]\n",
    "                current_offsets = offsets[i].numpy() if offsets is not None else [\"N/A\"] * len(label_keys)\n",
    "                # Round offsets to 2 decimal places\n",
    "                current_offsets = [f\"{offset:.2f}\" for offset in current_offsets]\n",
    "\n",
    "                label_names = extract_and_transform_labels(current_labels, label_keys, label_encoders)\n",
    "                plot_single_image(ax, images[i].numpy(), label_names, current_offsets)\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "        plt.show()\n",
    "\n",
    "    if problem_type not in [\"Multi-Class\", \"Binary\", \"Multi-Output\"]:\n",
    "        print(\"Unknown problem type specified in config. Please check.\")\n",
    "\n",
    "# Example usage (assuming label_encoders, config, and datasets are defined elsewhere)\n",
    "plot_images_from_dataset(label_encoders, config, datasets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model Building (Define the Model)\n",
    "\n",
    "# Transfer learning models\n",
    "def create_transfer_model(base_model, input_shape: tuple, num_classes: int, hidden_units: list, dropout_rate: float, regularizer_rate: float) -> keras.Model:\n",
    "    \"\"\"Creates a transfer learning model based on a given base model.\"\"\"\n",
    "    base_model.trainable = False\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D()\n",
    "    ])\n",
    "\n",
    "    for units in hidden_units:\n",
    "        model.add(layers.Dense(units, kernel_regularizer=keras.regularizers.l2(regularizer_rate), bias_regularizer=keras.regularizers.l2(regularizer_rate)))\n",
    "        model.add(layers.LeakyReLU())\n",
    "        model.add(layers.Dropout(dropout_rate))\n",
    "        \n",
    "    activation, units = determine_activation_and_units(num_classes)\n",
    "    model.add(layers.Dense(units, activation=activation))\n",
    "\n",
    "    return model\n",
    "\n",
    "def create_mobilenetv2_transfer_model(input_shape: tuple, num_classes: int) -> keras.Model:\n",
    "    \"\"\"Creates a MobileNetV2 based transfer learning model.\"\"\"\n",
    "    base_model = tf.keras.applications.MobileNetV2(input_shape=input_shape, include_top=False, weights='imagenet')\n",
    "    return create_transfer_model(base_model, input_shape, num_classes, [128, 64], 0.5, 0.001)\n",
    "\n",
    "def create_inceptionv3_transfer_model(input_shape: tuple, num_classes: int) -> keras.Model:\n",
    "    \"\"\"Creates an InceptionV3 based transfer learning model.\"\"\"\n",
    "    base_model = tf.keras.applications.InceptionV3(input_shape=input_shape, include_top=False, weights='imagenet')\n",
    "    return create_transfer_model(base_model, input_shape, num_classes, [128, 64], 0.5, 0.001)\n",
    "\n",
    "def create_resnet50_transfer_model(input_shape: tuple, num_classes: int) -> keras.Model:\n",
    "    \"\"\"Creates a ResNet50 based transfer learning model.\"\"\"\n",
    "    base_model = tf.keras.applications.ResNet50(input_shape=input_shape, include_top=False, weights='imagenet')\n",
    "    return create_transfer_model(base_model, input_shape, num_classes, [256, 128], 0.5, 0.001)\n",
    "\n",
    "# Define the function to create a basic CNN model\n",
    "def create_basic_cnn_model(input_shape, num_classes):\n",
    "    conv2d_filter_size = (3, 3)\n",
    "    conv2d_activation = 'relu'\n",
    "    dense_activation = 'relu'\n",
    "    num_conv_blocks = 3\n",
    "\n",
    "    model = tf.keras.models.Sequential()\n",
    "\n",
    "    # Explicitly define the input shape\n",
    "    model.add(tf.keras.layers.Input(shape=input_shape))\n",
    "\n",
    "    for _ in range(num_conv_blocks):\n",
    "        model.add(tf.keras.layers.Conv2D(32 * (2**_), conv2d_filter_size, activation=conv2d_activation, padding='same'))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
    "    model.add(tf.keras.layers.Dense(128, activation=dense_activation))\n",
    "\n",
    "    activation, units = determine_activation_and_units(num_classes)\n",
    "    model.add(layers.Dense(units, activation=activation))\n",
    "\n",
    "    return model\n",
    "\n",
    "# Define the function to create a small version of the Xception network\n",
    "def create_small_xception_model(input_shape, num_classes):\n",
    "    # Input layer\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    # Entry block: Initial Convolution and BatchNormalization\n",
    "    x = layers.Rescaling(1.0 / 255)(inputs)\n",
    "    x = layers.Conv2D(128, 3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    previous_block_activation = x  # Set aside residual for later use\n",
    "\n",
    "    # Middle flow: Stacking Separable Convolution blocks\n",
    "    for size in [256, 512, 728]:\n",
    "        # ReLU activation\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        # Separable Convolution\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        # ReLU activation\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        # Separable Convolution\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        # Max Pooling\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual from previous block and add it to the current block\n",
    "        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(previous_block_activation)\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    # Exit flow: Final Separable Convolution, BatchNormalization, and Global Average Pooling\n",
    "    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "    activation, units = determine_activation_and_units(num_classes)\n",
    "\n",
    "    # Dropout and Dense output layer\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(units, activation=activation)(x)\n",
    "\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "# Model Selection function to select which model to use\n",
    "def select_model(model_name: str, input_shape: tuple, num_classes: int) -> keras.Model:\n",
    "    \"\"\"Selects a model to use based on the given model name.\"\"\"\n",
    "    model_map = {\n",
    "        \"mobilenetv2\": create_mobilenetv2_transfer_model,\n",
    "        \"inceptionv3\": create_inceptionv3_transfer_model,\n",
    "        \"resnet50\": create_resnet50_transfer_model,\n",
    "        \"small_xception\": create_small_xception_model,\n",
    "        \"basic_cnn\": create_basic_cnn_model\n",
    "    }\n",
    "    if model_name not in model_map:\n",
    "        raise ValueError(\"Invalid model name\")\n",
    "\n",
    "    return model_map[model_name](input_shape, num_classes)\n",
    "\n",
    "def determine_activation_and_units(num_classes: int) -> tuple:\n",
    "    \"\"\"Determine the activation function and units based on the number of classes and problem type from config.\"\"\"\n",
    "    problem_type = config.get('Experiment').get('PROBLEM_TYPE')\n",
    "    if problem_type == 'Multi-Label':\n",
    "        return \"sigmoid\", num_classes\n",
    "    elif problem_type == 'Binary' or num_classes == 2:\n",
    "        return \"sigmoid\", 1\n",
    "    elif problem_type in ['Multi-Class', 'Multi-Output']:         \n",
    "        # For multi-output, we can treat each output independently.\n",
    "        # Here we assume each output is a multi-class problem.\n",
    "        return \"softmax\", num_classes\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid problem_type: {problem_type}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model Initialization (Compile the Model)\n",
    "\n",
    "# Constants & Configurations\n",
    "LOSS_CONFIG = {\n",
    "    'Binary': 'binary_crossentropy',\n",
    "    'Multi-Class': 'categorical_crossentropy',\n",
    "    'Multi-Output': 'categorical_crossentropy',\n",
    "    'Multi-Label': 'binary_crossentropy'\n",
    "}\n",
    "\n",
    "RECOMMENDED_METRICS = {\n",
    "    'Binary': ['accuracy', 'binary_crossentropy', 'mean_squared_error'],\n",
    "    'Multi-Class': ['categorical_accuracy', 'categorical_crossentropy', 'mean_squared_error'],\n",
    "    'Multi-Output': ['categorical_accuracy', 'categorical_crossentropy', 'mean_squared_error'],\n",
    "    'Multi-Label': ['binary_accuracy', 'binary_crossentropy', 'mean_squared_error']\n",
    "}\n",
    "\n",
    "# Helper Functions\n",
    "def get_accuracy_metric(problem_type):\n",
    "    \"\"\"Determine the accuracy metric based on the problem type.\"\"\"\n",
    "    metric_map = {\n",
    "        'Binary': \"accuracy\",\n",
    "        'Multi-Label': \"binary_accuracy\",\n",
    "    }\n",
    "    return metric_map.get(problem_type, \"categorical_accuracy\")\n",
    "\n",
    "\n",
    "def create_directory(path):\n",
    "    \"\"\"Create a directory if it doesn't exist.\"\"\"\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "\n",
    "# Callback Setup Functions\n",
    "def setup_common_callbacks():\n",
    "    \"\"\"Set up common callbacks.\"\"\"\n",
    "    return [\n",
    "        callbacks.EarlyStopping(\n",
    "            patience=config['Model']['EARLY_STOPPING_PATIENCE'], \n",
    "            restore_best_weights=True\n",
    "        ),\n",
    "        callbacks.ReduceLROnPlateau(\n",
    "            patience=config['Model']['REDUCE_LR_PATIENCE'], \n",
    "            min_lr=config['Model']['MIN_LR']\n",
    "        )\n",
    "    ]\n",
    "\n",
    "\n",
    "def setup_specific_callbacks(model_name, model_dir, problem_type):\n",
    "    \"\"\"Set up model-specific callbacks.\"\"\"\n",
    "    datetime_str = datetime.now().strftime(\"%Y%m%d-%I%M%S%p\")\n",
    "    acc_metric = get_accuracy_metric(problem_type)\n",
    "    \n",
    "    checkpoint_path = os.path.join(\n",
    "        model_dir, \n",
    "        f\"saved_model_{datetime_str}_epoch_{{epoch}}_val_loss_{{val_loss:.2f}}_{acc_metric}_{{{{val_{acc_metric}:.2f}}}}.h5\"\n",
    "    )\n",
    "    return [\n",
    "        callbacks.ModelCheckpoint(checkpoint_path, save_best_only=True),\n",
    "        callbacks.TensorBoard(log_dir=os.path.join(model_dir, \"logs\", datetime_str))\n",
    "    ]\n",
    "\n",
    "\n",
    "# Model Compilation Functions\n",
    "def compile_model(model_name, input_shape, num_classes, problem_type):\n",
    "    \"\"\"Compile and return a model.\"\"\"\n",
    "    model = select_model(model_name, input_shape, num_classes)\n",
    "    metrics_to_use = RECOMMENDED_METRICS.get(problem_type, ['accuracy'])\n",
    "    loss_to_use = LOSS_CONFIG.get(problem_type, 'categorical_crossentropy')\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(config['Model']['LEARNING_RATE']), \n",
    "        loss=loss_to_use, \n",
    "        metrics=metrics_to_use\n",
    "    )\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "def compile_and_initialize_models():\n",
    "    \"\"\"Main function to compile and initialize models.\"\"\"\n",
    "    input_shape = (config['Model']['IMG_SIZE'], config['Model']['IMG_SIZE'], 3)\n",
    "    num_classes = 3\n",
    "    problem_type = config['Experiment']['PROBLEM_TYPE']\n",
    "\n",
    "    experiment_name = f\"{config['Experiment']['NAME']}\"\n",
    "    base_dir = f\"./{experiment_name}\"\n",
    "    create_directory(base_dir)\n",
    "\n",
    "    common_callbacks = setup_common_callbacks()\n",
    "    label_names = config['Labels']['MAPPINGS'].keys() if problem_type == 'Multi-Class' else ['']\n",
    "\n",
    "    compiled_models = {}\n",
    "    for label_name in label_names:\n",
    "        label_dir = os.path.join(base_dir, label_name)\n",
    "        create_directory(label_dir)\n",
    "\n",
    "        for model_name in ['mobilenetv2', 'inceptionv3', 'resnet50', 'small_xception', 'basic_cnn']:\n",
    "            model_dir = os.path.join(label_dir, model_name)\n",
    "            create_directory(model_dir)\n",
    "            \n",
    "            specific_callbacks = setup_specific_callbacks(model_name, model_dir, problem_type)\n",
    "            all_callbacks = common_callbacks + specific_callbacks\n",
    "            \n",
    "            model = compile_model(model_name, input_shape, num_classes, problem_type)\n",
    "            compiled_models[model_name] = {'model': model, 'callbacks': all_callbacks}\n",
    "    \n",
    "    return compiled_models\n",
    "\n",
    "# Execution\n",
    "compiled_models = compile_and_initialize_models()\n",
    "print(\"Models compiled and initialized successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare class weights for multi-output problems (Optional)\n",
    "\n",
    "def prepare_class_weights_for_multi_output(info: pd.DataFrame) -> Union[Dict[str, Dict[int, float]], None]:\n",
    "    \"\"\"\n",
    "    Prepare class weights for multi-output problems for Keras and TensorFlow.\n",
    "    \n",
    "    Parameters:\n",
    "    - info: DataFrame containing the class weights information\n",
    "    - config: Configuration dictionary.\n",
    "    \n",
    "    Returns:\n",
    "    - Dictionary mapping output layer names to their respective class weight dictionaries or None\n",
    "    \"\"\"\n",
    "    if not config.get('USE_CLASS_WEIGHTS', True):\n",
    "        print(\"Configuration says not to use class weights. Returning None.\")\n",
    "        return None\n",
    "\n",
    "    class_weights = {}\n",
    "    for label in info.index.get_level_values('label').unique():\n",
    "        class_weights[label] = {}\n",
    "        sub_df = info.loc[(slice(None), label), :]\n",
    "        for idx, row in sub_df.iterrows():\n",
    "            class_idx = label_encoders[label].transform([idx[2]])[0]  # Transforming class name to class index\n",
    "            class_weights[label][class_idx] = row['Weight']\n",
    "    return class_weights\n",
    "\n",
    "# Additions to the config\n",
    "config['USE_CLASS_WEIGHTS'] = False  # Decide whether to use class weights or not\n",
    "prepared_class_weights = prepare_class_weights_for_multi_output(df_class_weights)\n",
    "# print(prepared_class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Removing Offset Labels from the Dataset and Splitting\n",
    "\n",
    "def inspect_dataset_content(dataset, name, num_batches=3):\n",
    "    \"\"\"\n",
    "    Inspect the content of the dataset to determine the nature of the tensors.\n",
    "    \"\"\"\n",
    "    print(f\"Inspecting first few records of {name} dataset...\")\n",
    "    \n",
    "    for i, record in enumerate(dataset.take(num_batches)):\n",
    "        summary = {k: (v.shape, v.dtype) for k, v in record.items()}\n",
    "        print(f\"{name} record {i + 1}: {summary}\")\n",
    "        \n",
    "    print(f\"Inspecting unique values in {name} dataset...\")\n",
    "    \n",
    "    for i, batch in enumerate(dataset.take(num_batches)):\n",
    "        print(f\"Batch {i + 1} content:\")\n",
    "        \n",
    "        for tensor_name, tensor in batch.items():\n",
    "            unique_values = tf.unique(tf.reshape(tensor, [-1])).y.numpy()\n",
    "            print(f\"Unique values in {tensor_name}: {unique_values}\")\n",
    "        \n",
    "        print(\"------\")\n",
    "\n",
    "def select_tensors(*tensors):\n",
    "    return tensors[0], tensors[1]  # Return only the image and label tensors\n",
    "\n",
    "def get_dataset(raw_datasets, dataset_type):\n",
    "    \"\"\"Retrieve specific dataset type (train, valid, test) from the raw datasets dictionary.\"\"\"\n",
    "    return raw_datasets.get(dataset_type, {}).get('Multi_Output')\n",
    "\n",
    "def prepare_and_inspect_dataset(dataset, dataset_name):\n",
    "    \"\"\"Apply transformations and inspect a dataset.\"\"\"\n",
    "    if dataset is None:\n",
    "        print(f\"{dataset_name} dataset is None. Skipping.\")\n",
    "        return None\n",
    "\n",
    "    dataset = dataset.map(select_tensors)\n",
    "    # inspect_dataset_content(dataset, dataset_name)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def prepare_datasets_for_training(raw_datasets):\n",
    "    \"\"\"\n",
    "    Prepare and inspect datasets for training.\n",
    "\n",
    "    Returns:\n",
    "    - A tuple containing prepared TensorFlow datasets for training, validation, and testing.\n",
    "    \"\"\"\n",
    "    if raw_datasets is None:\n",
    "        print(\"Datasets dictionary is None. Exiting.\")\n",
    "        return None, None, None\n",
    "\n",
    "    train_dataset = prepare_and_inspect_dataset(get_dataset(raw_datasets, 'train'), 'Train')\n",
    "    valid_dataset = prepare_and_inspect_dataset(get_dataset(raw_datasets, 'valid'), 'Validation')\n",
    "    test_dataset = prepare_and_inspect_dataset(get_dataset(raw_datasets, 'test'), 'Test')\n",
    "    \n",
    "    return train_dataset, valid_dataset, test_dataset\n",
    "\n",
    "# Uncomment this line to run the function with your datasets\n",
    "train_dataset, valid_dataset, test_dataset = prepare_datasets_for_training(datasets)\n",
    "# train_dataset, valid_dataset, test_dataset = prepare_datasets_for_training(resampled_datasets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training the Classifiers (Main Function)\n",
    "\n",
    "class ExcelMetricsSaver(Callback):\n",
    "    def __init__(self, writer, sheet_name):\n",
    "        super().__init__()\n",
    "        self.writer = writer\n",
    "        self.sheet_name = sheet_name\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        logs['epoch'] = epoch + 1 # Add epoch number to logs\n",
    "        epoch_df = pd.DataFrame([logs])\n",
    "        if epoch == 0:\n",
    "            epoch_df.to_excel(self.writer, sheet_name=self.sheet_name, index=False)\n",
    "        else:\n",
    "            book = self.writer.book\n",
    "            writer_sheets = self.writer.sheets\n",
    "            worksheet = writer_sheets[self.sheet_name]\n",
    "            start_row = worksheet.max_row\n",
    "            epoch_df.to_excel(self.writer, sheet_name=self.sheet_name, startrow=start_row, header=False, index=False)\n",
    "\n",
    "def train_and_save_metrics(train_dataset, valid_dataset, test_dataset, compiled_models, prepared_class_weights):\n",
    "    try:\n",
    "        if train_dataset is None or valid_dataset is None or test_dataset is None:\n",
    "            print(\"One or more datasets are None. Exiting.\")\n",
    "            return\n",
    "        excel_filename = f\"{config['Experiment']['NAME']}.xlsx\"\n",
    "        excel_path = os.path.join(\"./\", excel_filename)\n",
    "        with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:\n",
    "            for model_name, model_info in compiled_models.items():\n",
    "                model = model_info.get('model')\n",
    "                callbacks = model_info.get('callbacks')\n",
    "                if model is None or callbacks is None:\n",
    "                    print(f\"Model or callbacks for {model_name} are None. Skipping.\")\n",
    "                    continue\n",
    "                print(f\"Training {model_name} for multi-output...\")\n",
    "                \n",
    "                excel_saver = ExcelMetricsSaver(writer, sheet_name=f\"{model_name}\")\n",
    "                callbacks.append(excel_saver)\n",
    "                history = model.fit(\n",
    "                    train_dataset,\n",
    "                    validation_data=valid_dataset,\n",
    "                    epochs=config['Model']['EPOCHS'],\n",
    "                    class_weight=prepared_class_weights,\n",
    "                    callbacks=callbacks\n",
    "                )\n",
    "                print(f\"\\nTraining for {model_name} completed.\")\n",
    "        print(f\"\\nSaved all metrics to {excel_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn error occurred: {e}\")\n",
    "\n",
    "# Uncomment this line to run the function with your datasets\n",
    "train_and_save_metrics(train_dataset, valid_dataset, test_dataset, compiled_models, prepared_class_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plotting Training Metrics (Metrics per Epoch) for each Model\n",
    "\n",
    "class HandlerTupleVertical(HandlerTuple):\n",
    "    def create_artists(self, legend, orig_handle, xdescent, ydescent, width, height, fontsize, trans):\n",
    "        numlines = len(orig_handle)\n",
    "        handler_map = legend.get_legend_handler_map()\n",
    "        height_y = (height / numlines)\n",
    "        leglines = []\n",
    "        for i, handle in enumerate(orig_handle):\n",
    "            handler = legend.get_legend_handler(handler_map, handle)\n",
    "            legline = handler.create_artists(legend, handle, xdescent, (2*i + 1)*height_y, width, 2*height, fontsize, trans)\n",
    "            leglines.extend(legline)\n",
    "        return leglines\n",
    "\n",
    "def get_dataframes_from_excel(xls):\n",
    "    \"\"\"Load DataFrames from the Excel file.\"\"\"\n",
    "    model_names = xls.sheet_names\n",
    "    return {model_name: pd.read_excel(xls, model_name) for model_name in model_names}\n",
    "\n",
    "def plot_metrics(ax, dfs, metric, readable_metric, color_dict):\n",
    "    \"\"\"Plot metrics for all models on a single graph.\"\"\"\n",
    "    for model_name, cleaned_name in zip(dfs.keys(), color_dict.keys()):\n",
    "        epochs = dfs[model_name]['epoch']\n",
    "        ax.plot(epochs, dfs[model_name][f'{metric}'], '--', color=color_dict[cleaned_name], label=f\"{cleaned_name}\") #Training\n",
    "        ax.plot(epochs, dfs[model_name][f'val_{metric}'], '-', color=color_dict[cleaned_name], label=f\"{cleaned_name}\") #Validation\n",
    "    ax.set_title(f\"{readable_metric} vs Epoch\")\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel(readable_metric)\n",
    "    \n",
    "model_name_mapping = {\n",
    "    \"mobilenetv2\": \"MobileNetV2 Transfer\",\n",
    "    \"inceptionv3\": \"InceptionV3 Transfer\",\n",
    "    \"resnet50\": \"ResNet50 Transfer\",\n",
    "    \"small_xception\": \"Small Xception\",\n",
    "    \"basic_cnn\": \"Basic CNN\"\n",
    "}\n",
    "def plot_metrics_from_excel(excel_path):\n",
    "    # Load the Excel file and get DataFrames\n",
    "    xls = pd.ExcelFile(excel_path)\n",
    "    model_names = xls.sheet_names\n",
    "    dfs = get_dataframes_from_excel(xls)\n",
    "    readable_model_names = [model_name_mapping.get(name, name) for name in model_names]\n",
    "    \n",
    "    # Metrics mapping and Seaborn style\n",
    "    metric_mapping = {\n",
    "        'loss': 'Loss',\n",
    "        'categorical_accuracy': 'Categorical Accuracy',\n",
    "        'categorical_crossentropy': 'Categorical Crossentropy',\n",
    "        'mean_squared_error': 'Mean Squared Error'\n",
    "    }\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    palette = sns.color_palette(\"tab10\", len(model_names))\n",
    "    color_dict = {readable_name: palette[i] for i, readable_name in enumerate(readable_model_names)}\n",
    "    \n",
    "    # Plotting\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(18, 10))\n",
    "    axes_flat = axes.ravel()\n",
    "    for i, (metric, readable_metric) in enumerate(metric_mapping.items()):\n",
    "        plot_metrics(axes_flat[i], dfs, metric, readable_metric, color_dict)\n",
    "        # Add legend to each subplot\n",
    "        handles, labels = axes_flat[i].get_legend_handles_labels()\n",
    "        new_handles = [(handles[j], handles[j + 1]) for j in range(0, len(handles), 2)]\n",
    "        axes_flat[i].legend(new_handles, labels[::2], handler_map={tuple: HandlerTupleVertical()})\n",
    "    \n",
    "    # Add main title\n",
    "    experiment_name = os.path.basename(excel_path).replace(\".xlsx\", \"\")\n",
    "    fig.suptitle(f\"Metrics for {experiment_name}\", fontsize=20, y=1.08)\n",
    "    \n",
    "    # Add informational note below the subplots\n",
    "    note_text = r\"$\\bf{Models}$\" + \"\\nTraining (Dashed) | Validation (Solid)\"\n",
    "    fig.text(0.5, -0.02, note_text, ha='center', fontsize=10, transform=fig.transFigure)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    \n",
    "    # Save and display\n",
    "    base_dir = os.path.dirname(excel_path)\n",
    "    output_dir = os.path.join(base_dir, f\"Plots/{experiment_name}\")\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    save_path = os.path.join(output_dir, \"Metrics_vs_Epoch.png\")\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    return save_path\n",
    "\n",
    "# Mocking the actual plot as the excel_path is not available\n",
    "excel_path = 'SIM_Unbalanced.xlsx'\n",
    "improved_save_path = plot_metrics_from_excel(excel_path)\n",
    "improved_save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Comparing Experiment Results\n",
    "\n",
    "def extract_key_metrics_updated(excel_path):\n",
    "    \"\"\"Extract key metrics from the provided Excel file without using determine_engine.\"\"\"\n",
    "    # Load the Excel file and get DataFrames\n",
    "    xls = pd.ExcelFile(excel_path, engine=\"openpyxl\")\n",
    "    dfs = get_dataframes_from_excel(xls)\n",
    "\n",
    "    return {\n",
    "        model_name: {\n",
    "            \"Min Validation Loss\": df[\"val_loss\"].min(),\n",
    "            \"Epoch at Min Validation Loss\": df[\"epoch\"].iloc[\n",
    "                df[\"val_loss\"].idxmin()\n",
    "            ],\n",
    "            \"Max Validation Categorical Accuracy\": df[\n",
    "                \"val_categorical_accuracy\"\n",
    "            ].max(),\n",
    "            \"Epoch at Max Validation Categorical Accuracy\": df[\"epoch\"].iloc[\n",
    "                df[\"val_categorical_accuracy\"].idxmax()\n",
    "            ],\n",
    "            \"Min Validation Categorical Crossentropy\": df[\n",
    "                \"val_categorical_crossentropy\"\n",
    "            ].min(),\n",
    "            \"Epoch at Min Validation Categorical Crossentropy\": df[\n",
    "                \"epoch\"\n",
    "            ].iloc[df[\"val_categorical_crossentropy\"].idxmin()],\n",
    "            \"Min Validation Mean Squared Error\": df[\n",
    "                \"val_mean_squared_error\"\n",
    "            ].min(),\n",
    "            \"Epoch at Min Validation Mean Squared Error\": df[\"epoch\"].iloc[\n",
    "                df[\"val_mean_squared_error\"].idxmin()\n",
    "            ],\n",
    "        }\n",
    "        for model_name, df in dfs.items()\n",
    "    }\n",
    "\n",
    "\n",
    "def visualize_metric_comparison_with_mapping_annotated(file_paths, name_mapping, metric_key, metric_title, epoch_key):\n",
    "    \"\"\"Visualize a specific metric across experiments using a name mapping and annotate bars with epoch numbers.\"\"\"\n",
    "    metric_data = {}\n",
    "    epoch_data = {}\n",
    "    \n",
    "    # Extract specific metric and epoch data\n",
    "    for excel_path in file_paths:\n",
    "        experiment_name = os.path.basename(excel_path).replace(\".xlsx\", \"\")\n",
    "        metrics = extract_key_metrics_updated(excel_path)\n",
    "        \n",
    "        # Use the model_name_mapping to rename models\n",
    "        mapped_metric_values = {name_mapping.get(model, model): data[metric_key] for model, data in metrics.items()}\n",
    "        mapped_epoch_values = {name_mapping.get(model, model): data[epoch_key] for model, data in metrics.items()}\n",
    "        \n",
    "        metric_data[experiment_name] = mapped_metric_values\n",
    "        epoch_data[experiment_name] = mapped_epoch_values\n",
    "    \n",
    "    # Convert to DataFrame for easy plotting\n",
    "    metric_df = pd.DataFrame(metric_data).transpose()\n",
    "    \n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    ax = metric_df.plot(kind=\"bar\", ax=plt.gca(), colormap=\"viridis\")\n",
    "    plt.title(metric_title, fontsize=18)\n",
    "    plt.ylabel(metric_key, fontsize=16)\n",
    "    plt.xlabel(\"Experiment\", fontsize=16)\n",
    "    plt.legend(title=\"Models\", bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=12, title_fontsize=14)\n",
    "    plt.xticks(rotation=45, fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    ax.grid(axis='y')\n",
    "    \n",
    "    # Annotate bars with epoch numbers\n",
    "    for idx, rect in enumerate(ax.patches):\n",
    "        experiment_idx = idx // len(metric_df.columns)\n",
    "        model_idx = idx % len(metric_df.columns)\n",
    "        experiment_name = metric_df.index[experiment_idx]\n",
    "        model_name = metric_df.columns[model_idx]\n",
    "        epoch_value = epoch_data[experiment_name][model_name]\n",
    "        ax.text(rect.get_x() + rect.get_width() / 2, rect.get_height(), f'Ep {epoch_value}', ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Visualize all the key metrics with annotations\n",
    "metric_visualization_keys_with_epochs = [\n",
    "    (\"Max Validation Categorical Accuracy\", \"Max Validation Categorical Accuracy Across Experiments\", \"Epoch at Max Validation Categorical Accuracy\"),\n",
    "    (\"Min Validation Loss\", \"Min Validation Loss Across Experiments\", \"Epoch at Min Validation Loss\"),\n",
    "    (\"Min Validation Categorical Crossentropy\", \"Min Validation Categorical Crossentropy Across Experiments\", \"Epoch at Min Validation Categorical Crossentropy\"),\n",
    "    (\"Min Validation Mean Squared Error\", \"Min Validation Mean Squared Error Across Experiments\", \"Epoch at Min Validation Mean Squared Error\")\n",
    "]\n",
    "\n",
    "for metric_key, metric_title, epoch_key in metric_visualization_keys_with_epochs:\n",
    "    visualize_metric_comparison_with_mapping_annotated(\n",
    "        [\"SIM_Unbalanced.xlsx\", \"V9_Laptop - Multi-Output.xlsx\", \"V9.1_Laptop - Multi-Output.xlsx\"],\n",
    "        model_name_mapping,\n",
    "        metric_key,\n",
    "        metric_title,\n",
    "        epoch_key\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Testing Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading the Best Model from Directories\n",
    "\n",
    "def get_best_model_filename(directory):\n",
    "    \"\"\"Identify the best model filename based on the minimum validation loss from the directory.\"\"\"\n",
    "    model_files = [f for f in os.listdir(directory) if f.endswith('.h5')]\n",
    "    if not model_files:\n",
    "        print(f\"No model files found in {directory}\")\n",
    "        return None\n",
    "    return min(model_files, key=lambda x: float(x.split('val_loss_')[1].split('_')[0]))\n",
    "\n",
    "def load_best_model(directory):\n",
    "    \"\"\"Loads the best model from the specified directory.\"\"\"\n",
    "    best_model_file = get_best_model_filename(directory)\n",
    "    if not best_model_file:\n",
    "        return None\n",
    "    best_model_path = os.path.join(directory, best_model_file)\n",
    "    # return load_model(best_model_path)\n",
    "    return load_model(best_model_path, compile=False)\n",
    "\n",
    "def get_label_directories(experiment_directory):\n",
    "    \"\"\"Determine label directories or just model directories in the experiment directory.\"\"\"\n",
    "    first_level_dirs = [os.path.join(experiment_directory, d) for d in os.listdir(experiment_directory) \n",
    "                        if os.path.isdir(os.path.join(experiment_directory, d))]\n",
    "    if any('mobilenetv2' in dir_name for dir_name in first_level_dirs):\n",
    "        return [experiment_directory]\n",
    "    return first_level_dirs\n",
    "\n",
    "def load_all_best_models(experiment_directory):\n",
    "    \"\"\"Load the best model for each model type within the experiment directory.\"\"\"\n",
    "    best_models = {}\n",
    "    label_dirs = get_label_directories(experiment_directory)\n",
    "    for label_dir in label_dirs:\n",
    "        for model_name in ['mobilenetv2', 'inceptionv3', 'resnet50', 'small_xception', 'basic_cnn']:\n",
    "            model_dir = os.path.join(label_dir, model_name)\n",
    "            best_model = load_best_model(model_dir)\n",
    "            if best_model:\n",
    "                key_name = f\"{os.path.basename(label_dir)}_{model_name}\"\n",
    "                best_models[key_name] = best_model\n",
    "    return best_models\n",
    "\n",
    "# Example Usage\n",
    "experiment_directory = \"SIM_Unbalanced\"\n",
    "all_best_models = load_all_best_models(experiment_directory)\n",
    "print(all_best_models.keys())  # This will display the keys of the loaded models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beta Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function for Confusion Matrix\n",
    "\n",
    "def make_confusion_matrix_multi_output(y_true, y_preds, classes=None, figsize=(10, 10), text_size=15, norm=False, savefig=False): \n",
    "    \"\"\"\n",
    "    Makes a labelled confusion matrix comparing predictions and ground truth labels for multi-output models.\n",
    "\n",
    "    Args:\n",
    "    y_true: List of arrays of truth labels (must be same shape as y_preds).\n",
    "    y_preds: List of arrays of predicted labels (must be same shape as y_true).\n",
    "    classes: List of arrays of class labels (e.g. string form). If `None`, integer labels are used.\n",
    "    ... (other arguments as before)\n",
    "\n",
    "    Returns:\n",
    "    A list of labelled confusion matrix plots comparing y_true and y_preds for each output.\n",
    "    \"\"\"\n",
    "    # Check if y_true and y_preds are lists, if not, convert them to lists (for single-output compatibility)\n",
    "    if not isinstance(y_true, list):\n",
    "        y_true = [y_true]\n",
    "    if not isinstance(y_preds, list):\n",
    "        y_preds = [y_preds]\n",
    "    \n",
    "    for i, (true, pred) in enumerate(zip(y_true, y_preds)):\n",
    "        print(f\"Output {i + 1}:\")\n",
    "        make_confusion_matrix(true, pred, classes[i] if classes else None, figsize, text_size, norm, savefig)\n",
    "        plt.show()\n",
    "\n",
    "def make_confusion_matrix(y_true, y_pred, classes=None, figsize=(10, 10), text_size=15, norm=False, savefig=False):\n",
    "    # (The function content remains the same as you provided)\n",
    "\n",
    "    # Create the confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]  # normalize it\n",
    "    n_classes = cm.shape[0]  # find the number of classes we're dealing with\n",
    "\n",
    "    # Plot the figure and make it pretty\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    cax = ax.matshow(cm, cmap=plt.cm.Blues)  # colors will represent how 'correct' a class is, darker == better\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Are there a list of classes?\n",
    "    labels = classes if classes else np.arange(cm.shape[0])\n",
    "    \n",
    "    # Label the axes\n",
    "    ax.set(title=\"Confusion Matrix\",\n",
    "           xlabel=\"Predicted label\",\n",
    "           ylabel=\"True label\",\n",
    "           xticks=np.arange(n_classes),\n",
    "           yticks=np.arange(n_classes),\n",
    "           xticklabels=labels,\n",
    "           yticklabels=labels)\n",
    "\n",
    "    # Make x-axis labels appear on bottom\n",
    "    ax.xaxis.set_label_position(\"bottom\")\n",
    "    ax.xaxis.tick_bottom()\n",
    "\n",
    "    # Set the threshold for different colors\n",
    "    threshold = (cm.max() + cm.min()) / 2.\n",
    "\n",
    "    # Plot the text on each cell\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if norm:\n",
    "            plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)\",\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > threshold else \"black\",\n",
    "                     size=text_size)\n",
    "        else:\n",
    "            plt.text(j, i, f\"{cm[i, j]}\",\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > threshold else \"black\",\n",
    "                     size=text_size)\n",
    "\n",
    "    # Save the figure to the current working directory\n",
    "    if savefig:\n",
    "        fig.savefig(f\"confusion_matrix_output_{i + 1}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_labels_from_dataset(dataset, problem_type):\n",
    "    \"\"\"\n",
    "    Extract labels from a TensorFlow dataset based on the problem type.\n",
    "    \n",
    "    Args:\n",
    "    - dataset (tf.data.Dataset): The TensorFlow dataset to extract labels from.\n",
    "    - problem_type (str): The type of problem ('Multi-Output', 'Multi-Class', or 'Binary').\n",
    "    \n",
    "    Returns:\n",
    "    - numpy array or dict: If 'Multi-Output', returns a numpy array with shape (num_samples, num_outputs).\n",
    "                           If 'Multi-Class' or 'Binary', returns a dictionary with label types as keys and \n",
    "                           arrays of labels as values.\n",
    "    \"\"\"\n",
    "    \n",
    "    if problem_type == 'Multi-Output':\n",
    "        labels_list = [labels for _, labels in dataset]\n",
    "        return np.array(labels_list).squeeze()\n",
    "\n",
    "    elif problem_type in ['Multi-Class', 'Binary']:\n",
    "        labels_dict = {}\n",
    "        for label_type in ['Focus_Label', 'StigX_Label', 'StigY_Label']:\n",
    "            label_data = []\n",
    "            for _, labels in dataset[label_type]:\n",
    "                label_data.extend(labels.numpy())\n",
    "            labels_dict[label_type] = np.array(label_data)\n",
    "        return labels_dict\n",
    "\n",
    "    else:\n",
    "        print(f\"Unknown problem type: {problem_type}\")\n",
    "        return None\n",
    "\n",
    "# Usage\n",
    "problem_type = config['Experiment']['PROBLEM_TYPE']\n",
    "test_labels = extract_labels_from_dataset(test_dataset, problem_type)\n",
    "\n",
    "# Choose a specific model (replace 'specific_model_name' with the actual model name you're interested in)\n",
    "model_name = 'specific_model_name'\n",
    "model = all_best_models[model_name]\n",
    "\n",
    "if not model:\n",
    "    print(f\"No model found for {model_name}\")\n",
    "    exit()\n",
    "\n",
    "# 1. Predict on the test data\n",
    "predictions = model.predict(test_dataset)\n",
    "\n",
    "\n",
    "# 2. Get true labels and predictions for each output\n",
    "# Assuming test_labels is a list where each item is an array of true labels for a given output\n",
    "true_labels = [test_labels[i] for i in range(len(predictions))]\n",
    "predicted_labels = [np.argmax(predictions[i], axis=1) for i in range(len(predictions))]\n",
    "\n",
    "# List of class names for each output, assuming they are the same for all outputs in this example\n",
    "classes_list = [list(range(3)) for _ in range(len(predictions))]\n",
    "\n",
    "# 3. Generate confusion matrices\n",
    "make_confusion_matrix_multi_output(true_labels, predicted_labels, classes_list)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
