{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Focus and Astigmatism Classifier\n",
    "- **Author:** [Aaron Woods](https://aaronwoods.info)\n",
    "- **Date Created:** September 21, 2023\n",
    "- **Repository:** [Image Classification on VSCode](https://insiders.vscode.dev/tunnel/midnightsim/c:/Users/User/Desktop/Image-Classification)\n",
    "\n",
    "### Description\n",
    "This script provides an end-to-end machine learning pipeline for image classification. It can categorize images as \"In Focus\" or \"Out of Focus\" while also detecting astigmatism-related issues. The design is modular, making it adaptable to various image classification tasks.\n",
    "\n",
    "### Features\n",
    "- Ingests data from Excel spreadsheets.\n",
    "- Utilizes multiple machine learning models.\n",
    "- Modular design for easy customization.\n",
    "\n",
    "### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Package Installation (Optional)\n",
    "# ------------------------------\n",
    "# Uncomment the following lines to install required packages if running on a new machine.\n",
    "\n",
    "%pip install opencv-python numpy pandas matplotlib protobuf seaborn scikit-learn openpyxl\n",
    "\n",
    "# ------------------------------\n",
    "# TensorFlow Installation with GPU Support\n",
    "# ------------------------------\n",
    "# Note: TensorFlow versions above 2.10 are not supported on GPUs on native Windows installations.\n",
    "# For more details, visit: https://www.tensorflow.org/install/pip#windows-wsl2_1\n",
    "\n",
    "# Uncomment the following line to install TensorFlow if needed.\n",
    "# %pip install \"tensorflow<2.11\" --user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# System and TensorFlow Info Check\n",
    "# ------------------------------\n",
    "import platform\n",
    "import tensorflow as tf\n",
    "\n",
    "def get_system_info():\n",
    "    \"\"\"Get system and TensorFlow information.\"\"\"\n",
    "    system_info = {\"Platform\": platform.platform(), \"Python Version\": platform.python_version()}\n",
    "    \n",
    "    try:\n",
    "        system_info.update({\n",
    "            \"TensorFlow Version\": tf.__version__,\n",
    "            \"Num GPUs Available\": len(tf.config.list_physical_devices('GPU'))\n",
    "        })\n",
    "        system_info['Instructions'] = (\n",
    "            \"You're all set to run your model on a GPU.\" \n",
    "            if system_info['Num GPUs Available'] \n",
    "            else (\n",
    "                \"No GPUs found. To use a GPU, follow these steps:\\n\"\n",
    "                \"  1. Install NVIDIA drivers for your GPU.\\n\"\n",
    "                \"  2. Install a compatible CUDA toolkit.\\n\"\n",
    "                \"  3. Install the cuDNN library.\\n\"\n",
    "                \"  4. Make sure to install the GPU version of TensorFlow.\"\n",
    "            )\n",
    "        )\n",
    "    except ModuleNotFoundError:\n",
    "        system_info['Instructions'] = (\n",
    "            \"TensorFlow is not installed. \"\n",
    "            \"Install it using pip by running: !pip install tensorflow\"\n",
    "        )\n",
    "    \n",
    "    return system_info\n",
    "\n",
    "def configure_gpu_memory_growth():\n",
    "    \"\"\"Set GPU memory consumption growth to avoid OOM errors.\"\"\"\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "# Call functions to get system info and configure GPU memory.\n",
    "system_info = get_system_info()\n",
    "configure_gpu_memory_growth()\n",
    "\n",
    "# Print system information.\n",
    "formatted_info = \"\\n\".join(f\"{key}: {value}\" for key, value in system_info.items())\n",
    "print(formatted_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Import Libraries\n",
    "# ------------------------------\n",
    "\n",
    "# Standard Libraries\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import glob\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# Third-Party Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "from sklearn.utils import class_weight, resample\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# TensorFlow and Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks, optimizers, applications\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
    "from tensorflow.keras.callbacks import TensorBoard, Callback\n",
    "from tensorflow.data import Dataset\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Other Imports\n",
    "import pickle\n",
    "import itertools\n",
    "from matplotlib.legend_handler import HandlerTuple\n",
    "\n",
    "# Type Annotations\n",
    "from typing import List, Dict, Tuple, Union, Any, Optional\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration Dictionary\n",
    "\n",
    "# DOE_v2 Experiment has classweights working!\n",
    "\n",
    "experiment_config = {\n",
    "    'NAME': \"DOE_v2\",            # Experiment name\n",
    "    'RANDOM_SEED': 42,                             # Seed for reproducibility\n",
    "    'PROBLEM_TYPE': 'Multi-Output',                # Problem type: Binary, Multi-Class, Multi-Output, Multi-Label\n",
    "}\n",
    "\n",
    "model_config = {\n",
    "    'IMG_SIZE': 224,                               # Image input size\n",
    "    'BATCH_SIZE': 16,                              # Batch size for training\n",
    "    'TRAIN_SIZE': 0.8,                             # Fraction of data to use for training\n",
    "    'VAL_SIZE': 0.5,                               # Fraction of data to use for validation\n",
    "    'EPOCHS': 100,                                 # Number of training epochs\n",
    "    'LEARNING_RATE': 0.001,                        # Learning rate 1e-3\n",
    "    'EARLY_STOPPING_PATIENCE': 50,                 # Early stopping patience\n",
    "    'REDUCE_LR_PATIENCE': 3,                       # Reduce learning rate on plateau patience\n",
    "    'MIN_LR': 1e-6,                                # Minimum learning rate\n",
    "}\n",
    "\n",
    "label_mappings = {\n",
    "    'Focus_Label': {'SharpFocus': 0, 'SlightlyBlurred': 1, 'HighlyBlurred': 2},\n",
    "    'StigX_Label': {'OptimalStig_X': 0, 'ModerateStig_X': 1, 'SevereStig_X': 2},\n",
    "    'StigY_Label': {'OptimalStig_Y': 0, 'ModerateStig_Y': 1, 'SevereStig_Y': 2},\n",
    "}\n",
    "\n",
    "augmentation_config = {\n",
    "    'rotation_factor': 0.002,  # Specifies the rotation range applied to the data (in radians).\n",
    "    'height_factor': (-0.18, 0.18),  # Specifies the range of random vertical shifts applied to the data.\n",
    "    'width_factor': (-0.18, 0.18),  # Specifies the range of random horizontal shifts applied to the data.\n",
    "    'contrast_factor': 0.5,  # Specifies the range of random contrast adjustments applied to the data.\n",
    "}\n",
    "\n",
    "# Combine Experiment, Model, Labels, and Augmentation Configurations\n",
    "config = {\n",
    "    'Experiment': experiment_config,\n",
    "    'Model': model_config,\n",
    "    'Labels': {'MAPPINGS': label_mappings},\n",
    "    'Augmentation': augmentation_config\n",
    "}\n",
    "\n",
    "# Dataset Creation Configuration\n",
    "csv_config = {\n",
    "    'CSV': {\n",
    "        'COLUMNS_TO_READ': ['ImageFile', 'Focus_Offset (V)', 'Stig_Offset_X (V)', 'Stig_Offset_Y (V)']\n",
    "    },\n",
    "    'Thresholds': {\n",
    "        'FOCUS_LOW': 30,                              # Lower focus threshold\n",
    "        'FOCUS_HIGH': 60,                             # Upper focus threshold\n",
    "        \n",
    "        'STIGX_LOW': 1,                               # Lower astigmatism threshold\n",
    "        'STIGX_HIGH': 2,                              # Upper astigmatism threshold\n",
    "        \n",
    "        'STIGY_LOW': 1,                               # Lower astigmatism threshold\n",
    "        'STIGY_HIGH': 2,                              # Upper astigmatism threshold\n",
    "    },\n",
    "    'Paths': {\n",
    "        'OLD_BASE_PATH': \"D:\\\\DOE\\\\\",\n",
    "        \n",
    "        # On Simulation Computer\n",
    "        # 'DATA_FILE': \"combined_output.csv\",\n",
    "        # 'NEW_BASE_PATH': \"Y:\\\\User\\\\Aaron-HX38\\\\DOE\\\\\", \n",
    "        \n",
    "        # On Laptop\n",
    "        'DATA_FILE': \"combined_output_cleaned.csv\",\n",
    "        'NEW_BASE_PATH': \"C:\\\\Users\\\\aaron.woods\\\\OneDrive - Thermo Fisher Scientific\\\\Desktop\\\\Dec 24\\\\\",\n",
    "    },\n",
    "    'SAMPLE_FRAC': 1,                                # Fraction of the data for quicker prototyping (1.0 means use all data)\n",
    "}\n",
    "\n",
    "# Update the main configuration dictionary with the dataset configuration\n",
    "config.update(csv_config)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(config['Experiment']['RANDOM_SEED'])\n",
    "tf.random.set_seed(config['Experiment']['RANDOM_SEED'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions for Preparation of CSV\n",
    "\n",
    "def read_csv(config: Dict):\n",
    "    # Functionality to read the data\n",
    "    data_file_path = os.path.join(config['Paths']['NEW_BASE_PATH'], config['Paths']['DATA_FILE'])\n",
    "    if not os.path.exists(data_file_path):\n",
    "        raise FileNotFoundError(f\"Error: File does not exist - {data_file_path}\")\n",
    "    try:\n",
    "        data = pd.read_csv(data_file_path, usecols=config['CSV']['COLUMNS_TO_READ'])\n",
    "        print(\"---> Data read successfully.\")\n",
    "        sample_frac = config.get('SAMPLE_FRAC', 1.0)\n",
    "        if 0 < sample_frac < 1.0:\n",
    "            data = data.sample(frac=sample_frac).reset_index(drop=True)\n",
    "            print(f\"---> Data sampled: Using {sample_frac * 100}% of the available data.\")\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error: Could not read data - {e}\") from e\n",
    "    return data\n",
    "\n",
    "def update_image_paths(df):\n",
    "    old_base_path = config['Paths']['OLD_BASE_PATH']\n",
    "    new_base_path = config['Paths']['NEW_BASE_PATH']\n",
    "    df['ImageFile'] = df['ImageFile'].str.replace(old_base_path, new_base_path, regex=False)\n",
    "    print(\"---> Image paths updated.\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def clean_csv(df: pd.DataFrame, save_cleaned: bool = False) -> pd.DataFrame:\n",
    "    def is_valid_string(image_path) -> bool:\n",
    "        return isinstance(image_path, str)\n",
    "    \n",
    "    def does_file_exist(image_path) -> bool:\n",
    "        return os.path.exists(image_path)\n",
    "    \n",
    "    def can_image_be_read(image_path) -> bool:\n",
    "        img = cv2.imread(image_path)\n",
    "        return img is not None\n",
    "    \n",
    "    removal_reasons = defaultdict(list)\n",
    "    total_rows = len(df)\n",
    "    csv_file_path = os.path.join(config['Paths']['NEW_BASE_PATH'], config['Paths']['DATA_FILE'])\n",
    "    print(\"Cleaning CSV file...\")\n",
    "    for index, row in enumerate(df.itertuples()):\n",
    "        progress = (index + 1) / total_rows * 100\n",
    "        print(f\"\\rProgress: {progress:.2f}%\", end=\"\")\n",
    "        \n",
    "        image_path = row.ImageFile\n",
    "        reason = None\n",
    "        \n",
    "        if not is_valid_string(image_path):\n",
    "            reason = \"Invalid ImageFile value - not a string\"\n",
    "        elif not does_file_exist(image_path):\n",
    "            reason = \"File does not exist\"\n",
    "        elif not can_image_be_read(image_path):\n",
    "            reason = \"Image can't be read\"\n",
    "        \n",
    "        if reason:\n",
    "            removal_reasons[reason].append(index)\n",
    "    \n",
    "    invalid_rows = [index for indices in removal_reasons.values() for index in indices]\n",
    "    df.drop(index=invalid_rows, inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    print(\"\\n\\nSummary of row removals:\")\n",
    "    for reason, indices in removal_reasons.items():\n",
    "        print(f\"{len(indices)} rows removed due to: {reason}\")\n",
    "        print(f\"Row indices: {indices}\")\n",
    "    \n",
    "    if save_cleaned and csv_file_path:\n",
    "        cleaned_csv_file_path = f\"{os.path.splitext(csv_file_path)[0]}_cleaned.csv\"\n",
    "        df.to_csv(cleaned_csv_file_path, index=False)\n",
    "        print(f\"Cleaned CSV saved to: {cleaned_csv_file_path}\")\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generating labels\n",
    "\n",
    "def generate_thresholds(label_key):\n",
    "    low_key = f\"{label_key.split('_')[0].upper()}_LOW\"\n",
    "    high_key = f\"{label_key.split('_')[0].upper()}_HIGH\"\n",
    "    return config.get('Thresholds', {}).get(low_key, 0), config.get('Thresholds', {}).get(high_key, 0)\n",
    "\n",
    "def generate_single_label(df_copy, label_key, offset_column, choices_dict):\n",
    "    low_threshold, high_threshold = generate_thresholds(label_key)\n",
    "    conditions = [\n",
    "        (df_copy[offset_column].abs() <= low_threshold),\n",
    "        (df_copy[offset_column].abs() > low_threshold) & (df_copy[offset_column].abs() <= high_threshold),\n",
    "        (df_copy[offset_column].abs() > high_threshold)\n",
    "    ]\n",
    "    choices = list(choices_dict.keys())\n",
    "    df_copy[label_key] = np.select(conditions, choices, default='Unknown')\n",
    "    le = LabelEncoder()\n",
    "    df_copy[label_key] = le.fit_transform(df_copy[label_key])\n",
    "    return le\n",
    "\n",
    "def generate_labels(df: pd.DataFrame):\n",
    "    print(\"---> Generating labels for Focus, StigX, and StigY...\")\n",
    "    labels_config = config.get('Labels', {}).get('MAPPINGS', {})\n",
    "    offset_column_mapping = {'Focus_Label': 'Focus_Offset (V)', 'StigX_Label': 'Stig_Offset_X (V)', 'StigY_Label': 'Stig_Offset_Y (V)'}\n",
    "\n",
    "    df_copy = df.copy()\n",
    "    label_encoders = {}\n",
    "\n",
    "    for label_key, choices_dict in labels_config.items():\n",
    "        offset_column = offset_column_mapping.get(label_key)\n",
    "        if not offset_column:\n",
    "            print(f\"Warning: No offset column mapping found for '{label_key}'. Skipping label generation.\")\n",
    "            continue\n",
    "        if offset_column not in df.columns:\n",
    "            print(f\"Warning: Column '{offset_column}' not found in DataFrame. Skipping label generation for '{label_key}'.\")\n",
    "            continue\n",
    "        label_encoders[label_key] = generate_single_label(df_copy, label_key, offset_column, choices_dict)\n",
    "        print(f\"---> Labels generated for {label_key}\")\n",
    "\n",
    "    if config.get('Experiment', {}).get('PROBLEM_TYPE') == 'Multi-Output':\n",
    "        df_copy['Multi_Output_Labels'] = df_copy.apply(lambda row: [row[key] for key in labels_config.keys()], axis=1)\n",
    "        print(\"---> Multi-Output Labels generated.\")\n",
    "        \n",
    "    return df_copy, label_encoders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Shuffling and Splitting the Data\n",
    "\n",
    "def shuffle_and_reset_index(data):\n",
    "    print(\"---> Shuffling and resetting index...\")\n",
    "    shuffled_df = data.sample(frac=1, random_state=config['Experiment']['RANDOM_SEED']).reset_index(drop=True)\n",
    "    print(\"---> Data shuffled and index reset.\")\n",
    "    return shuffled_df\n",
    "\n",
    "def prepare_datasets(df: pd.DataFrame):\n",
    "    \"\"\"Prepare training, validation, and test datasets.\"\"\"\n",
    "    # Check if DataFrame is empty\n",
    "    if df is None or df.empty:\n",
    "        print(\"Warning: DataFrame is empty. Cannot proceed with data preparation.\")\n",
    "        return {'train': None, 'valid': None, 'test': None}\n",
    "    # Split Data\n",
    "    try:\n",
    "        train_df, temp_df = train_test_split(df, test_size=1 - config['Model']['TRAIN_SIZE'], random_state=config['Experiment']['RANDOM_SEED'])\n",
    "        val_df, test_df = train_test_split(temp_df, test_size=1 - config['Model']['VAL_SIZE'], random_state=config['Experiment']['RANDOM_SEED'])\n",
    "    except ValueError:\n",
    "        print(\"Not enough data to split into training, validation, and test sets.\")\n",
    "        return {'train': None, 'valid': None, 'test': None}\n",
    "    print(\"---> Data split into training, validation, and test sets.\")\n",
    "    return {'train': train_df, 'valid': val_df, 'test': test_df}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Computting Class Weights\n",
    "\n",
    "def compute_class_weights_for_label(split: str, df: pd.DataFrame, label: str, label_encoders: Dict[str, LabelEncoder], all_records: List[Dict], is_multi_label: bool = False) -> None:\n",
    "    y_data = df[label].values if is_multi_label else df[label]\n",
    "    unique_labels = np.unique(y_data)\n",
    "    class_weights = compute_class_weight('balanced', classes=unique_labels, y=y_data)\n",
    "    class_weights_dict = dict(zip(unique_labels, class_weights))\n",
    "    \n",
    "    for cls, weight in class_weights_dict.items():\n",
    "        cnt = Counter(y_data)[cls]\n",
    "        original_class = label_encoders[label].inverse_transform([cls])[0]\n",
    "        all_records.append({\n",
    "            'split': split,\n",
    "            'label': label,\n",
    "            'class': original_class,\n",
    "            'Count': cnt,\n",
    "            'Weight': weight\n",
    "        })\n",
    "\n",
    "def compute_and_store_class_weights(datasets: Dict[str, pd.DataFrame], label_encoders: Dict[str, LabelEncoder]) -> pd.DataFrame:\n",
    "    problem_type = config.get('Experiment', {}).get('PROBLEM_TYPE', 'Binary')\n",
    "    all_records = []\n",
    "    \n",
    "    for split, df in datasets.items():\n",
    "        if df is None:\n",
    "            continue\n",
    "        for label in config['Labels']['MAPPINGS']:\n",
    "            compute_class_weights_for_label(\n",
    "                split, df, label, label_encoders, all_records, \n",
    "                is_multi_label=(problem_type == 'Multi-label')\n",
    "            )\n",
    "                \n",
    "    df_class_weights = pd.DataFrame.from_records(all_records)\n",
    "    df_class_weights.set_index(['split', 'label', 'class'], inplace=True)\n",
    "    return df_class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating Tensorflow Datasets\n",
    "\n",
    "def create_tf_datasets_from_dfs(dfs: Dict[str, pd.DataFrame], include_offset: bool = False) -> Dict[str, Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Create TensorFlow datasets from DataFrames for training, validation, and testing.\n",
    "    \"\"\"\n",
    "    problem_type = config.get('Experiment', {}).get('PROBLEM_TYPE')\n",
    "    batch_size = config.get('Model', {}).get('BATCH_SIZE', 32)\n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "    \n",
    "    preprocessing_layers = create_preprocessing_layers()\n",
    "    augmentation_layers = create_augmentation_layers()\n",
    "    \n",
    "    def load_and_preprocess_image(file_path: tf.Tensor, label: tf.Tensor, offset: Optional[tf.Tensor], augment: bool = False) -> Tuple:\n",
    "        file_path_str = file_path.numpy().decode('utf-8')\n",
    "        image = read_and_convert_image(file_path_str)\n",
    "        image = preprocessing_layers(image)\n",
    "        if augment:\n",
    "            image = augmentation_layers(image)\n",
    "            image = tf.clip_by_value(image, 0.0, 1.0)\n",
    "        label = tf.cast(label, tf.int32)\n",
    "        offset = tf.cast(offset, tf.float32) if offset is not None else None\n",
    "        return (image, label, offset) if include_offset else (image, label)\n",
    "\n",
    "    def prepare_dataset(file_paths, labels, offsets, augment):\n",
    "        ds = tf.data.Dataset.from_tensor_slices((file_paths, labels, offsets))\n",
    "        ds = ds.map(lambda file_path, label, offset: tf.py_function(\n",
    "            func=load_and_preprocess_image,\n",
    "            inp=[file_path, label, offset if offset is not None else tf.constant([], dtype=tf.float32), augment],\n",
    "            Tout=[tf.float32, label.dtype, tf.float32] if include_offset else [tf.float32, label.dtype]\n",
    "        ))\n",
    "        return ds.batch(batch_size).prefetch(buffer_size=AUTOTUNE) # If I have a lot of memory, I can use cache() here.\n",
    "\n",
    "    tf_datasets = {'train': {}, 'valid': {}, 'test': {}}\n",
    "    offset_column_mapping = {\n",
    "        'Focus_Label': 'Focus_Offset (V)',\n",
    "        'StigX_Label': 'Stig_Offset_X (V)',\n",
    "        'StigY_Label': 'Stig_Offset_Y (V)'\n",
    "    }\n",
    "\n",
    "    for split, df in dfs.items():\n",
    "        augment_data = (split == 'train')\n",
    "        if problem_type in ['Multi-Class', 'Binary']:\n",
    "            for label in ['Focus_Label', 'StigX_Label', 'StigY_Label']:\n",
    "                offset_column = offset_column_mapping.get(label)\n",
    "                offsets = df[offset_column].values if include_offset else None\n",
    "                tf_datasets[split][label] = prepare_dataset(df['ImageFile'].values, df[label].values, offsets, augment_data)\n",
    "        \n",
    "        elif problem_type == 'Multi-Output':\n",
    "            labels = df[['Focus_Label', 'StigX_Label', 'StigY_Label']].values\n",
    "            offsets = df[['Focus_Offset (V)', 'Stig_Offset_X (V)', 'Stig_Offset_Y (V)']].values if include_offset else None\n",
    "            tf_datasets[split]['Multi_Output'] = prepare_dataset(df['ImageFile'].values, labels, offsets, augment_data)\n",
    "        \n",
    "        else:\n",
    "            print(\"Unknown problem type specified in config. Please check.\")\n",
    "\n",
    "    return tf_datasets\n",
    "\n",
    "### Image Augmentation and Preprocessing\n",
    "\n",
    "def create_preprocessing_layers() -> keras.Sequential:\n",
    "    \"\"\"Create preprocessing layers for resizing and rescaling images.\"\"\"\n",
    "    img_size = config['Model']['IMG_SIZE']\n",
    "    return keras.Sequential([\n",
    "        layers.Resizing(img_size, img_size),\n",
    "        layers.Rescaling(1./255)\n",
    "    ])\n",
    "\n",
    "def create_augmentation_layers() -> keras.Sequential:\n",
    "    \"\"\"Create data augmentation layers.\"\"\"\n",
    "    aug_config = config['Augmentation']\n",
    "    try:\n",
    "        return keras.Sequential([\n",
    "            layers.RandomFlip(\"horizontal\"),\n",
    "            layers.RandomFlip(\"vertical\"),\n",
    "            layers.RandomRotation(aug_config['rotation_factor']),\n",
    "            layers.RandomTranslation(\n",
    "                height_factor=aug_config['height_factor'],\n",
    "                width_factor=aug_config['width_factor'],\n",
    "                fill_mode=\"reflect\"\n",
    "            ),\n",
    "            layers.RandomContrast(aug_config['contrast_factor']),\n",
    "        ])\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while creating augmentation layers: {e}\")\n",
    "        return None\n",
    "\n",
    "def read_and_convert_image(file_path: str) -> tf.Tensor:\n",
    "    \"\"\"Read an image from a file and convert it to a 3-channel tensor.\"\"\"\n",
    "    image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if image is None:\n",
    "        print(\"Failed to read the image.\")\n",
    "        return None\n",
    "    image = tf.convert_to_tensor(image, dtype=tf.float32)\n",
    "    image = tf.expand_dims(image, axis=-1)\n",
    "    return tf.image.grayscale_to_rgb(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Resample Datasets to deal with Imbalances (Optional)\n",
    "\n",
    "def validate_inputs(datasets: Dict[str, pd.DataFrame], resample_label: str, resample_strategy: str) -> None:\n",
    "    if not isinstance(datasets, dict):\n",
    "        raise ValueError(\"Input datasets should be a dictionary.\")\n",
    "    if resample_strategy not in [\"upsample\", \"downsample\", \"combined\"]:\n",
    "        raise ValueError(\"Invalid resample_strategy. Choose from 'upsample', 'downsample', or 'combined'.\")\n",
    "    for key, df in datasets.items():\n",
    "        if resample_label not in df.columns:\n",
    "            raise ValueError(f\"'{resample_label}' is not a valid column in the {key} dataset.\")\n",
    "\n",
    "def target_count_for_strategy(label_counts: pd.Series, strategy: str) -> int:\n",
    "    if strategy == \"downsample\":\n",
    "        return label_counts.min()\n",
    "    elif strategy == \"upsample\":\n",
    "        return label_counts.max()\n",
    "    return int(label_counts.median())\n",
    "\n",
    "def iterative_resampling(df: pd.DataFrame, resample_strategy: str, resample_label: str) -> pd.DataFrame:\n",
    "    label_counts = df[resample_label].apply(tuple).value_counts()\n",
    "    target_count = target_count_for_strategy(label_counts, resample_strategy)\n",
    "    subsets = [\n",
    "        resample(\n",
    "            df[df[resample_label].apply(tuple) == unique_label],\n",
    "            replace=(label_counts[unique_label] < target_count),\n",
    "            n_samples=target_count\n",
    "        )\n",
    "        for unique_label in label_counts.keys()\n",
    "    ]\n",
    "    return pd.concat(subsets).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "def resample_datasets(datasets: Dict[str, pd.DataFrame], resample_label='Multi_Output_Labels', resample_strategy=\"downsample\") -> Dict[str, pd.DataFrame]:\n",
    "    validate_inputs(datasets, resample_label, resample_strategy)\n",
    "    \n",
    "    int32_columns = [col for col, dtype in datasets.get('train', pd.DataFrame()).dtypes.items() if dtype == 'int32']\n",
    "    \n",
    "    def process_dataset(key: str, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        if key != 'train':\n",
    "            return df\n",
    "        resampled_data = iterative_resampling(df, resample_strategy, resample_label)\n",
    "        for col in int32_columns:\n",
    "            resampled_data[col] = resampled_data[col].astype('int32')\n",
    "        return resampled_data\n",
    "    \n",
    "    return {key: process_dataset(key, df) for key, df in datasets.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸš€ Enhanced Data Loading and Preprocessing Workflow\n",
    "\n",
    "print(\"\\nðŸ” [START] Preprocessing CSV Data...\")\n",
    "data = read_csv(config)\n",
    "data = update_image_paths(data)\n",
    "# Uncomment the below line if you want to clean the CSV\n",
    "# data = clean_csv(data, save_cleaned=False)\n",
    "data, label_encoders = generate_labels(data)\n",
    "data = shuffle_and_reset_index(data)\n",
    "\n",
    "print(\"\\nðŸ“Š [LOAD] Preparing TensorFlow Datasets...\")\n",
    "datasets = prepare_datasets(data)\n",
    "print(\"  ðŸ‹ï¸â€â™‚ï¸ Computing class weights for original datasets...\")\n",
    "df_class_weights = compute_and_store_class_weights(datasets, label_encoders)\n",
    "\n",
    "print(\"\\n  ðŸ” Resampling datasets... (Optional)\")\n",
    "resampled_datasets = resample_datasets(datasets, resample_label='Multi_Output_Labels', resample_strategy=\"upsample\")\n",
    "print(\"  ðŸ‹ï¸â€â™€ï¸ Computing class weights for resampled datasets...\")\n",
    "rdf_class_weights = compute_and_store_class_weights(resampled_datasets, label_encoders)\n",
    "\n",
    "print(\"\\nðŸ”§ [BUILD] Creating TensorFlow datasets from DataFrames...\")\n",
    "datasets = create_tf_datasets_from_dfs(datasets, include_offset=True)\n",
    "resampled_datasets = create_tf_datasets_from_dfs(resampled_datasets, include_offset=True)\n",
    "\n",
    "print(\"\\nâœ… [DONE] Preprocessing Complete!\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label_encoders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Class Distributions\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def add_annotations(ax, bars, sub_df):\n",
    "    \"\"\"\n",
    "    Adds annotations to the bars.\n",
    "    \"\"\"\n",
    "    for bar, (_, row) in zip(bars, sub_df.iterrows()):\n",
    "        x = bar.get_x() + bar.get_width() / 2.0\n",
    "        y = bar.get_height() + 0.5  # Shift annotation slightly above the bar for clarity\n",
    "        ax.annotate(f\"C: {int(row['Count'])}\\nW: {row['Weight']:.2f}\", \n",
    "                    (x, y), \n",
    "                    ha='center', \n",
    "                    va='bottom', \n",
    "                    fontsize=8)\n",
    "\n",
    "def plot_single_split(ax, df, split):\n",
    "    \"\"\"\n",
    "    Plots the class distribution for a single split (train/test/valid).\n",
    "    \"\"\"\n",
    "    filtered_df = df.loc[split]\n",
    "    x_ticks = []\n",
    "    x_tick_locs = []\n",
    "    current_x = 0  # Keep track of the current x-location for ticks\n",
    "    \n",
    "    labels = filtered_df.index.get_level_values('label').unique()\n",
    "    for label in labels:\n",
    "        sub_df = filtered_df.loc[label]\n",
    "        bars = ax.bar(sub_df.index, sub_df['Count'], label=f\"{label}\")\n",
    "        add_annotations(ax, bars, sub_df)\n",
    "        \n",
    "        x_ticks.extend([f\"{label}_{cls}\" for cls in sub_df.index])\n",
    "        x_tick_locs.extend([current_x + i for i in range(len(sub_df.index))])\n",
    "        current_x += len(sub_df.index)  # Update the x-location for the next set of bars\n",
    "    \n",
    "    ax.legend()\n",
    "    ax.set_xticks(x_tick_locs)  # Set tick locations\n",
    "    ax.set_xticklabels(x_ticks, rotation=90, fontsize=8)  # Set tick labels\n",
    "    ax.set_title(f\"{split.capitalize()} Data\")\n",
    "    ax.set_ylabel(\"Count\")  # Indicate that the bars represent counts\n",
    "\n",
    "\n",
    "def plot_dataset_info(df):\n",
    "    \"\"\"\n",
    "    Plots the class distribution for train, valid, and test splits.\n",
    "    \"\"\"\n",
    "    splits = ['train', 'valid', 'test']\n",
    "    fig, axs = plt.subplots(1, len(splits), figsize=(20, 8))\n",
    "    \n",
    "    for i, split in enumerate(splits):\n",
    "        plot_single_split(axs[i], df, split)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "plot_dataset_info(df_class_weights)\n",
    "plot_dataset_info(rdf_class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot Images from Dataset\n",
    "\n",
    "import textwrap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_single_image(ax, image, label_names, offsets):\n",
    "    \"\"\"\n",
    "    Plots a single image with associated labels and offsets.\n",
    "    \"\"\"\n",
    "    ax.imshow(image)\n",
    "    title_text = \", \".join(f\"{name} ({offset})\" for name, offset in zip(label_names, offsets))\n",
    "    ax.set_title(\"\\n\".join(textwrap.wrap(title_text, 30)))  # Wrap text to fit into the subplot\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "def extract_and_transform_labels(labels, label_keys, label_encoders):\n",
    "    \"\"\"\n",
    "    Extracts and transforms labels using label encoders.\n",
    "    \"\"\"\n",
    "    label_names = []\n",
    "    for label_value, label_key in zip(labels, label_keys):\n",
    "        label_encoder = label_encoders.get(label_key, None)\n",
    "        if label_encoder:\n",
    "            label_names.append(label_encoder.inverse_transform([label_value])[0])\n",
    "        else:\n",
    "            label_names.append(str(label_value))\n",
    "    return label_names\n",
    "\n",
    "def plot_images_from_dataset(label_encoders, config, datasets):\n",
    "    \"\"\"\n",
    "    Plots images, labels, and offsets (if available) from the provided datasets.\n",
    "    \n",
    "    Args:\n",
    "        label_encoders (dict): Dictionary of label encoders for each label key.\n",
    "        config (dict): Configuration dictionary containing problem type and other parameters.\n",
    "        datasets (dict): Dictionary of datasets, containing training data for each label key.\n",
    "    \"\"\"\n",
    "    label_keys = ['Focus_Label', 'StigX_Label', 'StigY_Label']\n",
    "    problem_type = config['Experiment']['PROBLEM_TYPE']\n",
    "\n",
    "    plt.rcParams.update({'font.size': 8})\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(12, 12))\n",
    "\n",
    "    # Helper function to get relevant dataset based on problem type\n",
    "    def get_relevant_dataset(problem_type, label_key):\n",
    "        return datasets['train'][label_key if problem_type in ['Multi-Class', 'Binary'] else 'Multi_Output']\n",
    "\n",
    "    # If problem type is not Multi-Output, re-use the same logic for both Binary and Multi-Class\n",
    "    relevant_datasets = [label_keys] if problem_type != \"Multi-Output\" else [\"Multi_Output\"]\n",
    "\n",
    "    for label_key in relevant_datasets:\n",
    "        label_encoder = label_encoders.get(label_key, None)\n",
    "        fig.suptitle(f\"Images for {label_key}\")\n",
    "\n",
    "        for data in get_relevant_dataset(problem_type, label_key).take(1):\n",
    "            images, labels = data[:2]\n",
    "            offsets = data[2] if len(data) > 2 else None\n",
    "\n",
    "            for i in range(min(len(images), 9)):\n",
    "                ax = axes[i // 3, i % 3]\n",
    "                current_labels = labels[i].numpy() if problem_type == \"Multi-Output\" else [labels[i].numpy()]\n",
    "                current_offsets = offsets[i].numpy() if offsets is not None else [\"N/A\"] * len(label_keys)\n",
    "                # Round offsets to 2 decimal places\n",
    "                current_offsets = [f\"{offset:.2f}\" for offset in current_offsets]\n",
    "\n",
    "                label_names = extract_and_transform_labels(current_labels, label_keys, label_encoders)\n",
    "                plot_single_image(ax, images[i].numpy(), label_names, current_offsets)\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "        plt.show()\n",
    "\n",
    "    if problem_type not in [\"Multi-Class\", \"Binary\", \"Multi-Output\"]:\n",
    "        print(\"Unknown problem type specified in config. Please check.\")\n",
    "\n",
    "# Example usage (assuming label_encoders, config, and datasets are defined elsewhere)\n",
    "plot_images_from_dataset(label_encoders, config, datasets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Removing Offset Labels from the Dataset and Splitting (Doesn't Incorporate Changes from SIMv9)\n",
    "\n",
    "def inspect_dataset_content(dataset, name, num_batches=3):\n",
    "    \"\"\"\n",
    "    Inspect the content of the dataset to determine the nature of the tensors.\n",
    "    \"\"\"\n",
    "    print(f\"Inspecting first few records of {name} dataset...\")\n",
    "    \n",
    "    for i, record in enumerate(dataset.take(num_batches)):\n",
    "        summary = {k: (v.shape, v.dtype) for k, v in record.items()}\n",
    "        print(f\"{name} record {i + 1}: {summary}\")\n",
    "        \n",
    "    print(f\"Inspecting unique values in {name} dataset...\")\n",
    "    \n",
    "    for i, batch in enumerate(dataset.take(num_batches)):\n",
    "        print(f\"Batch {i + 1} content:\")\n",
    "        \n",
    "        for tensor_name, tensor in batch.items():\n",
    "            unique_values = tf.unique(tf.reshape(tensor, [-1])).y.numpy()\n",
    "            print(f\"Unique values in {tensor_name}: {unique_values}\")\n",
    "        \n",
    "        print(\"------\")\n",
    "\n",
    "def select_tensors(*tensors):\n",
    "    return tensors[0], tensors[1]  # Return only the image and label tensors\n",
    "    # return tensors[0], tensors[1], tensors[2]  # Return image, label, and offset tensors\n",
    "\n",
    "def get_dataset(raw_datasets, dataset_type):\n",
    "    \"\"\"Retrieve specific dataset type (train, valid, test) from the raw datasets dictionary.\"\"\"\n",
    "    return raw_datasets.get(dataset_type, {}).get('Multi_Output')\n",
    "\n",
    "def prepare_and_inspect_dataset(dataset, dataset_name):\n",
    "    \"\"\"Apply transformations and inspect a dataset.\"\"\"\n",
    "    if dataset is None:\n",
    "        print(f\"{dataset_name} dataset is None. Skipping.\")\n",
    "        return None\n",
    "\n",
    "    dataset = dataset.map(select_tensors)\n",
    "    # inspect_dataset_content(dataset, dataset_name)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def prepare_datasets_for_training(raw_datasets):\n",
    "    \"\"\"\n",
    "    Prepare and inspect datasets for training.\n",
    "\n",
    "    Returns:\n",
    "    - A tuple containing prepared TensorFlow datasets for training, validation, and testing.\n",
    "    \"\"\"\n",
    "    if raw_datasets is None:\n",
    "        print(\"Datasets dictionary is None. Exiting.\")\n",
    "        return None, None, None\n",
    "\n",
    "    train_dataset = prepare_and_inspect_dataset(get_dataset(raw_datasets, 'train'), 'Train')\n",
    "    valid_dataset = prepare_and_inspect_dataset(get_dataset(raw_datasets, 'valid'), 'Validation')\n",
    "    test_dataset = prepare_and_inspect_dataset(get_dataset(raw_datasets, 'test'), 'Test')\n",
    "    \n",
    "    return train_dataset, valid_dataset, test_dataset\n",
    "\n",
    "# Uncomment this line to run the function with your datasets\n",
    "train_dataset, valid_dataset, test_dataset = prepare_datasets_for_training(datasets)\n",
    "# train_dataset, valid_dataset, test_dataset = prepare_datasets_for_training(resampled_datasets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model Building (Define the Model)\n",
    "\n",
    "def add_multi_output_heads(base_layer, num_classes: int, output_names: List[str]) -> List[keras.layers.Layer]:\n",
    "    \"\"\"Creates multiple output heads for a given base layer.\"\"\"\n",
    "    outputs = []\n",
    "    for i in range(num_classes):\n",
    "        x = layers.Dense(128, activation=\"relu\")(base_layer)\n",
    "        x = layers.Dropout(0.5)(x)\n",
    "        x = layers.Dense(3, activation=\"softmax\", name=output_names[i])(x)  # Naming each output layer\n",
    "        outputs.append(x)\n",
    "    return outputs\n",
    "\n",
    "def determine_activation_and_units(num_classes: int) -> Tuple[List[str], List[int]]:\n",
    "    \"\"\"Determines the activation functions and units based on the number of classes and config settings.\"\"\"\n",
    "    problem_type = config.get('Experiment').get('PROBLEM_TYPE')\n",
    "    if problem_type in ['Multi-Label', 'Binary', 'Multi-Class', 'Multi-Output']:\n",
    "        return {\n",
    "            'Multi-Label': ([\"sigmoid\"] * num_classes, [1] * num_classes),\n",
    "            'Binary': ([\"sigmoid\"], [1]),\n",
    "            'Multi-Class': ([\"softmax\"], [num_classes]),\n",
    "            'Multi-Output': ([\"softmax\"] * num_classes, [3] * num_classes)  # Assuming each output has 3 classes\n",
    "        }[problem_type]\n",
    "    raise ValueError(f\"Invalid problem_type: {problem_type}\")\n",
    "\n",
    "def create_transfer_model(base_model, input_shape: Tuple[int, int, int], num_classes: int, hidden_units: List[int], dropout_rate: float, regularizer_rate: float, output_names: List[str] = None) -> keras.Model:\n",
    "    \"\"\"Creates a transfer learning model based on the provided base model.\"\"\"\n",
    "    base_model.trainable = False\n",
    "    model = keras.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D()\n",
    "    ])\n",
    "    for units in hidden_units:\n",
    "        model.add(layers.Dense(units, kernel_regularizer=keras.regularizers.l2(regularizer_rate), bias_regularizer=keras.regularizers.l2(regularizer_rate)))\n",
    "        model.add(layers.LeakyReLU())\n",
    "        model.add(layers.Dropout(dropout_rate))\n",
    "    \n",
    "    activations, units_list = determine_activation_and_units(num_classes)\n",
    "    if len(activations) == 1:\n",
    "        model.add(layers.Dense(units_list[0], activation=activations[0]))\n",
    "        return model\n",
    "    \n",
    "    # output_names = output_names or list(config['Labels']['MAPPINGS'].keys())\n",
    "    output_names = list(config['Labels']['MAPPINGS'].keys())\n",
    "\n",
    "    outputs = add_multi_output_heads(model.layers[-1].output, num_classes, output_names)\n",
    "    return keras.Model(inputs=model.input, outputs=outputs)\n",
    "\n",
    "def create_specific_transfer_model(base_model_class, input_shape: Tuple[int, int, int], num_classes: int) -> keras.Model:\n",
    "    \"\"\"Helper function to create specific transfer models.\"\"\"\n",
    "    base_model = base_model_class(input_shape=input_shape, include_top=False, weights='imagenet')\n",
    "    return create_transfer_model(base_model, input_shape, num_classes, [128, 64], 0.5, 0.001, output_names=config['Labels']['MAPPINGS'].keys())\n",
    "\n",
    "def create_mobilenetv2_transfer_model(input_shape: Tuple[int, int, int], num_classes: int) -> keras.Model:\n",
    "    return create_specific_transfer_model(tf.keras.applications.MobileNetV2, input_shape, num_classes)\n",
    "\n",
    "def create_inceptionv3_transfer_model(input_shape: Tuple[int, int, int], num_classes: int) -> keras.Model:\n",
    "    return create_specific_transfer_model(tf.keras.applications.InceptionV3, input_shape, num_classes)\n",
    "\n",
    "def create_resnet50_transfer_model(input_shape: Tuple[int, int, int], num_classes: int) -> keras.Model:\n",
    "    return create_specific_transfer_model(tf.keras.applications.ResNet50, input_shape, num_classes)\n",
    "\n",
    "# Define the function to create a basic CNN model\n",
    "def create_basic_cnn_model(input_shape, num_classes):\n",
    "    conv2d_filter_size = (3, 3)\n",
    "    conv2d_activation = 'relu'\n",
    "    dense_activation = 'relu'\n",
    "    num_conv_blocks = 3\n",
    "\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    x = inputs\n",
    "\n",
    "    for _ in range(num_conv_blocks):\n",
    "        x = layers.Conv2D(32 * (2**_), conv2d_filter_size, activation=conv2d_activation, padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(128, activation=dense_activation)(x)\n",
    "\n",
    "    activations, units_list = determine_activation_and_units(num_classes)\n",
    "    if len(activations) == 1:\n",
    "        # Single output\n",
    "        x = layers.Dense(units_list[0], activation=activations[0])(x)\n",
    "        return keras.Model(inputs=inputs, outputs=x)\n",
    "    else:\n",
    "        # Multiple outputs\n",
    "        outputs = add_multi_output_heads(x, num_classes, output_names=list(config['Labels']['MAPPINGS'].keys()))\n",
    "        return keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Define the function to create a small version of the Xception network\n",
    "def create_small_xception_model(input_shape, num_classes):\n",
    "    # Input layer\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    # Entry block: Initial Convolution and BatchNormalization\n",
    "    x = layers.Rescaling(1.0 / 255)(inputs)\n",
    "    x = layers.Conv2D(128, 3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    previous_block_activation = x  # Set aside residual for later use\n",
    "\n",
    "    # Middle flow: Stacking Separable Convolution blocks\n",
    "    for size in [256, 512, 728]:\n",
    "        # ReLU activation\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        # Separable Convolution\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        # ReLU activation\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        # Separable Convolution\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        # Max Pooling\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual from previous block and add it to the current block\n",
    "        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(previous_block_activation)\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    # Exit flow: Final Separable Convolution, BatchNormalization, and Global Average Pooling\n",
    "    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "    activations, units_list = determine_activation_and_units(num_classes)\n",
    "    if len(activations) == 1:\n",
    "        # Single output\n",
    "        x = layers.Dense(units_list[0], activation=activations[0])(x)\n",
    "        return keras.Model(inputs=inputs, outputs=x)\n",
    "    else:\n",
    "        # Multiple outputs\n",
    "        outputs = add_multi_output_heads(x, num_classes, output_names=list(config['Labels']['MAPPINGS'].keys()))\n",
    "        return keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Model Selection function to select which model to use\n",
    "def select_model(model_name: str, input_shape: Tuple[int, int, int], num_classes: int) -> keras.Model:\n",
    "    \"\"\"Selects a model to use based on the given model name.\"\"\"\n",
    "    model_map = {\n",
    "        \"mobilenetv2\": create_mobilenetv2_transfer_model,\n",
    "        \"inceptionv3\": create_inceptionv3_transfer_model,\n",
    "        \"resnet50\": create_resnet50_transfer_model,\n",
    "        \"small_xception\": create_small_xception_model,\n",
    "        \"basic_cnn\": create_basic_cnn_model\n",
    "    }\n",
    "    if model_name not in model_map:\n",
    "        raise ValueError(\"Invalid model name\")\n",
    "\n",
    "    return model_map[model_name](input_shape, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model Initialization (Compile the Model)\n",
    "\n",
    "# # Constants & Configurations\n",
    "LOSS_CONFIG = {\n",
    "    'Binary': 'binary_crossentropy',\n",
    "    'Multi-Class': 'categorical_crossentropy',\n",
    "    'Multi-Output': ['categorical_crossentropy'] * len(config['Labels']['MAPPINGS']),\n",
    "    'Multi-Label': 'binary_crossentropy'\n",
    "}\n",
    "\n",
    "RECOMMENDED_METRICS = {\n",
    "    'Binary': ['accuracy', 'binary_crossentropy', 'mean_squared_error'],\n",
    "    'Multi-Class': ['categorical_accuracy', 'categorical_crossentropy', 'mean_squared_error'],\n",
    "    'Multi-Output': ['categorical_accuracy'] * len(config['Labels']['MAPPINGS']) + \n",
    "                    ['categorical_crossentropy'] * len(config['Labels']['MAPPINGS']) + \n",
    "                    ['mean_squared_error'] * len(config['Labels']['MAPPINGS']),\n",
    "    'Multi-Label': ['binary_accuracy', 'binary_crossentropy', 'mean_squared_error']\n",
    "}\n",
    "\n",
    "# Helper Functions\n",
    "def get_accuracy_metric(problem_type: str) -> str:\n",
    "    \"\"\"Determine the accuracy metric based on the problem type.\"\"\"\n",
    "    return {'Binary': \"accuracy\", 'Multi-Label': \"binary_accuracy\"}.get(problem_type, \"categorical_accuracy\")\n",
    "\n",
    "def create_directory(path: str):\n",
    "    \"\"\"Create a directory if it doesn't exist.\"\"\"\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "# Callback Setup Functions\n",
    "def setup_common_callbacks() -> List[callbacks.Callback]:\n",
    "    \"\"\"Set up common callbacks.\"\"\"\n",
    "    return [\n",
    "        callbacks.EarlyStopping(patience=config['Model']['EARLY_STOPPING_PATIENCE'], restore_best_weights=True),\n",
    "        callbacks.ReduceLROnPlateau(patience=config['Model']['REDUCE_LR_PATIENCE'], min_lr=config['Model']['MIN_LR'])\n",
    "    ]\n",
    "\n",
    "def setup_specific_callbacks(model_name: str, model_dir: str, problem_type: str) -> List[callbacks.Callback]:\n",
    "    \"\"\"Set up model-specific callbacks.\"\"\"\n",
    "    datetime_str = datetime.now().strftime(\"%Y%m%d-%I%M%S%p\")\n",
    "    acc_metric = get_accuracy_metric(problem_type)\n",
    "    checkpoint_path = os.path.join(model_dir, f\"saved_model_{datetime_str}_epoch_{{epoch}}_val_loss_{{val_loss:.2f}}_{acc_metric}_{{{{val_{acc_metric}:.2f}}}}.h5\")\n",
    "    return [\n",
    "        callbacks.ModelCheckpoint(checkpoint_path, save_best_only=True),\n",
    "        callbacks.TensorBoard(log_dir=os.path.join(model_dir, \"logs\", datetime_str))\n",
    "    ]\n",
    "\n",
    "# Model Compilation Functions\n",
    "def compile_model(model_name: str, input_shape: tuple, num_classes: int, problem_type: str) -> tf.keras.Model:\n",
    "    \"\"\"Compile and return a model.\"\"\"\n",
    "    model = select_model(model_name, input_shape, num_classes)\n",
    "    \n",
    "    if problem_type == 'Multi-Output':\n",
    "        # Create dictionaries for loss and metrics with keys corresponding to output layer names\n",
    "        loss_to_use = {output_name: 'categorical_crossentropy' for output_name in ['Focus_Label', 'StigX_Label', 'StigY_Label']}\n",
    "        metrics_to_use = {output_name: ['categorical_accuracy', 'categorical_crossentropy', 'mean_squared_error'] for output_name in ['Focus_Label', 'StigX_Label', 'StigY_Label']}\n",
    "    else:\n",
    "        metrics_to_use = list(set(RECOMMENDED_METRICS.get(problem_type, ['accuracy'])))\n",
    "        loss_to_use = LOSS_CONFIG.get(problem_type, 'categorical_crossentropy')\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(config['Model']['LEARNING_RATE']), \n",
    "        loss=loss_to_use, \n",
    "        metrics=metrics_to_use\n",
    "    )\n",
    "    # model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def compile_and_initialize_models() -> Dict[str, Dict[str, tf.keras.Model]]:\n",
    "    \"\"\"Main function to compile and initialize models.\"\"\"\n",
    "    input_shape = (config['Model']['IMG_SIZE'], config['Model']['IMG_SIZE'], 3)\n",
    "    num_classes = 3\n",
    "    problem_type = config['Experiment']['PROBLEM_TYPE']\n",
    "\n",
    "    experiment_name = config['Experiment']['NAME']\n",
    "    base_dir = f\"./{experiment_name}\"\n",
    "    create_directory(base_dir)\n",
    "\n",
    "    common_callbacks = setup_common_callbacks()\n",
    "    label_names = config['Labels']['MAPPINGS'].keys() if problem_type in ['Multi-Class', 'Multi-Output'] else ['']\n",
    "\n",
    "    compiled_models = {}\n",
    "    for label_name in label_names:\n",
    "        label_dir = os.path.join(base_dir, label_name)\n",
    "        create_directory(label_dir)\n",
    "\n",
    "        for model_name in ['mobilenetv2', 'inceptionv3', 'resnet50', 'small_xception', 'basic_cnn']:\n",
    "            model_dir = os.path.join(label_dir, model_name)\n",
    "            create_directory(model_dir)\n",
    "            \n",
    "            specific_callbacks = setup_specific_callbacks(model_name, model_dir, problem_type)\n",
    "            all_callbacks = common_callbacks + specific_callbacks\n",
    "            \n",
    "            model = compile_model(model_name, input_shape, num_classes, problem_type)\n",
    "            compiled_models[model_name] = {'model': model, 'callbacks': all_callbacks}\n",
    "    \n",
    "    return compiled_models\n",
    "\n",
    "# Execution\n",
    "compiled_models = compile_and_initialize_models()\n",
    "print(\"Models compiled and initialized successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Investigating Model Outputs\n",
    "\n",
    "\n",
    "for label_category, encoder in label_encoders.items():\n",
    "    print(f'Mapping for {label_category}:')\n",
    "    for index, class_label in enumerate(encoder.classes_):\n",
    "        print(f'{index}: {class_label}')\n",
    "    print()  # print a blank line between categories\n",
    "\n",
    "\n",
    "\n",
    "def analyze_model_outputs(compiled_models, train_dataset):\n",
    "    model_output_details = []\n",
    "    \n",
    "    # Assuming train_dataset is an iterable that yields batches of data,\n",
    "    # We'll take the first batch of images from the training dataset for analysis.\n",
    "    for images, labels in train_dataset.take(1):\n",
    "        image_batch = images.numpy()  # Convert tensors to numpy arrays if necessary\n",
    "\n",
    "    # Order of label encoders corresponding to the outputs\n",
    "    encoder_order = ['Focus_Label', 'StigX_Label', 'StigY_Label']\n",
    "    \n",
    "    for model_name, model_details in compiled_models.items():\n",
    "        model = model_details['model']\n",
    "        output = model.predict(image_batch)\n",
    "        \n",
    "        if not isinstance(output, list):\n",
    "            output = [output]  # Ensure output is a list for consistency\n",
    "        \n",
    "        for i, output_to_check in enumerate(output):\n",
    "            one_hot_encoded = all((np.sum(row) > 0.99 and np.sum(row) < 1.01) for row in output_to_check)\n",
    "            suggested_loss = 'categorical_crossentropy' if one_hot_encoded else 'sparse_categorical_crossentropy'\n",
    "            max_prob_class = np.argmax(output_to_check, axis=-1)\n",
    "            \n",
    "            # Get the label encoder for the current output\n",
    "            encoder_key = encoder_order[i] if i < len(encoder_order) else None\n",
    "            label_encoder = label_encoders[encoder_key] if encoder_key else None\n",
    "            \n",
    "            # Decode the sample output\n",
    "            sample_output = output_to_check[0] if len(output_to_check) > 0 else \"No Output\"\n",
    "            sample_output_decoded = label_encoder.inverse_transform([np.argmax(sample_output)])[0] if label_encoder else \"No Decoder\"\n",
    "            \n",
    "            model_output_details.append({\n",
    "                \"Model Name\": model_name,\n",
    "                # Include Output Layer Name \n",
    "                \"Output Layer Name\": model.output_names[i],\n",
    "                \"Output\": f'Output {i+1}',\n",
    "                \"Input Shape\": model.input_shape,\n",
    "                \"Output Shape\": output_to_check.shape,\n",
    "                \"Output Type\": type(output).__name__,\n",
    "                \"Is One-Hot Encoded\": one_hot_encoded,\n",
    "                \"Suggested Loss\": suggested_loss,\n",
    "                \"Max Probability Class\": max_prob_class,\n",
    "                \"Sample Output\": sample_output,\n",
    "                \"Sample Output (Decoded)\": sample_output_decoded\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(model_output_details).style.set_table_styles(\n",
    "        [{\"selector\": \"th\", \"props\": [(\"font-size\", \"100%\"), (\"text-align\", \"center\")]},\n",
    "         {\"selector\": \"td\", \"props\": [(\"font-size\", \"100%\"), (\"text-align\", \"center\")]}]\n",
    "    )\n",
    "\n",
    "# Assuming train_dataset is already defined and loaded with your training data\n",
    "# Display the analysis\n",
    "analyze_model_outputs(compiled_models, train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Compute Sample Weights for Multi-Output Problems (Untested)\n",
    "\n",
    "# def compute_sample_weights_for_batch(labels_batch, class_weights):\n",
    "#     \"\"\"\n",
    "#     Compute sample weights for a given batch of labels.\n",
    "\n",
    "#     Args:\n",
    "#     - labels_batch (dict): Dictionary containing batched labels for each output.\n",
    "#                            Keys are output names, and values are numpy arrays of labels.\n",
    "#     - class_weights (dict): Dictionary containing class weights for each output.\n",
    "#                             Keys are output names, and values are dictionaries mapping class labels to weights.\n",
    "\n",
    "#     Returns:\n",
    "#     - sample_weights (dict): Dictionary containing computed sample weights for each output.\n",
    "#                              Keys are output names, and values are numpy arrays of sample weights.\n",
    "#     \"\"\"\n",
    "#     sample_weights = {}\n",
    "#     for output_name, labels in labels_batch.items():\n",
    "#         weights_for_output = class_weights[output_name]\n",
    "#         sample_weights_for_output = np.array([weights_for_output[label] for label in labels])\n",
    "#         sample_weights[output_name] = sample_weights_for_output\n",
    "#     return sample_weights\n",
    "\n",
    "# # Test the function with a sample batch (for demonstration purposes)\n",
    "# sample_labels_batch = {\n",
    "#     'Focus_Label': np.array([0, 1, 2, 0]),\n",
    "#     'StigX_Label': np.array([1, 1, 0, 2]),\n",
    "#     'StigY_Label': np.array([2, 0, 1, 1])\n",
    "# }\n",
    "\n",
    "# # sample_weights_batch = compute_sample_weights_for_batch(sample_labels_batch, prepared_class_weights)\n",
    "# # sample_weights_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Excel Metrics Saver\n",
    "\n",
    "class ExcelMetricsSaver(Callback):\n",
    "    def __init__(self, writer, sheet_name):\n",
    "        super().__init__()\n",
    "        self.writer = writer\n",
    "        self.sheet_name = sheet_name\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        logs['epoch'] = epoch + 1  # Add epoch number to logs\n",
    "        epoch_df = pd.DataFrame([logs])\n",
    "        if epoch == 0:\n",
    "            epoch_df.to_excel(self.writer, sheet_name=self.sheet_name, index=False)\n",
    "        else:\n",
    "            book = self.writer.book\n",
    "            writer_sheets = self.writer.sheets\n",
    "            worksheet = writer_sheets[self.sheet_name]\n",
    "            start_row = worksheet.max_row\n",
    "            epoch_df.to_excel(self.writer, sheet_name=self.sheet_name, startrow=start_row, header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare class weights for multi-output problems (Optional)\n",
    "\n",
    "def prepare_class_weights_for_multi_output(info: pd.DataFrame) -> Union[Dict[str, Dict[int, float]], None]:\n",
    "    \"\"\"\n",
    "    Prepare class weights for multi-output problems for Keras and TensorFlow.\n",
    "    \n",
    "    Parameters:\n",
    "    - info: DataFrame containing the class weights information\n",
    "    - config: Configuration dictionary.\n",
    "    \n",
    "    Returns:\n",
    "    - Dictionary mapping output layer names to their respective class weight dictionaries or None\n",
    "    \"\"\"\n",
    "    if not config.get('USE_CLASS_WEIGHTS', True):\n",
    "        print(\"Configuration says not to use class weights. Returning None.\")\n",
    "        return None\n",
    "\n",
    "    class_weights = {}\n",
    "    for label in info.index.get_level_values('label').unique():\n",
    "        class_weights[label] = {}\n",
    "        sub_df = info.loc[(slice(None), label), :]\n",
    "        for idx, row in sub_df.iterrows():\n",
    "            class_idx = label_encoders[label].transform([idx[2]])[0]  # Transforming class name to class index\n",
    "            class_weights[label][class_idx] = row['Weight']\n",
    "    return class_weights\n",
    "\n",
    "# Additions to the config\n",
    "config['USE_CLASS_WEIGHTS'] = True  # Decide whether to use class weights or not\n",
    "prepared_class_weights = prepare_class_weights_for_multi_output(df_class_weights)\n",
    "print(prepared_class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mobilenetv2 for multi-output...\n",
      "Epoch 1/100\n",
      " 68/511 [==>...........................] - ETA: 3:36 - loss: 10.0796 - Focus_Label_loss: 3.2804 - StigX_Label_loss: 3.2569 - StigY_Label_loss: 3.2353 - Focus_Label_categorical_accuracy: 0.4017 - Focus_Label_categorical_crossentropy: 3.2804 - Focus_Label_mean_squared_error: 0.6480 - StigX_Label_categorical_accuracy: 0.4256 - StigX_Label_categorical_crossentropy: 3.2569 - StigX_Label_mean_squared_error: 0.6474 - StigY_Label_categorical_accuracy: 0.3511 - StigY_Label_categorical_crossentropy: 3.2353 - StigY_Label_mean_squared_error: 0.6486"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\aaron.woods\\OneDrive - Thermo Fisher Scientific\\Documents\\GitHub\\Image-Classification\\DOE_Fiduciary_Classifier.ipynb Cell 30\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aaron.woods/OneDrive%20-%20Thermo%20Fisher%20Scientific/Documents/GitHub/Image-Classification/DOE_Fiduciary_Classifier.ipynb#Y160sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aaron.woods/OneDrive%20-%20Thermo%20Fisher%20Scientific/Documents/GitHub/Image-Classification/DOE_Fiduciary_Classifier.ipynb#Y160sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mAn error occurred: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m) \n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/aaron.woods/OneDrive%20-%20Thermo%20Fisher%20Scientific/Documents/GitHub/Image-Classification/DOE_Fiduciary_Classifier.ipynb#Y160sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m train_and_save_metrics(train_dataset, valid_dataset, test_dataset, compiled_models, prepared_class_weights)\n",
      "\u001b[1;32mc:\\Users\\aaron.woods\\OneDrive - Thermo Fisher Scientific\\Documents\\GitHub\\Image-Classification\\DOE_Fiduciary_Classifier.ipynb Cell 30\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aaron.woods/OneDrive%20-%20Thermo%20Fisher%20Scientific/Documents/GitHub/Image-Classification/DOE_Fiduciary_Classifier.ipynb#Y160sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m         model_output_names \u001b[39m=\u001b[39m [layer\u001b[39m.\u001b[39mname \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39moutput\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m layer\u001b[39m.\u001b[39mname]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aaron.woods/OneDrive%20-%20Thermo%20Fisher%20Scientific/Documents/GitHub/Image-Classification/DOE_Fiduciary_Classifier.ipynb#Y160sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m         current_class_weights \u001b[39m=\u001b[39m {name: prepared_class_weights[name] \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m model_output_names}\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/aaron.woods/OneDrive%20-%20Thermo%20Fisher%20Scientific/Documents/GitHub/Image-Classification/DOE_Fiduciary_Classifier.ipynb#Y160sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m         history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aaron.woods/OneDrive%20-%20Thermo%20Fisher%20Scientific/Documents/GitHub/Image-Classification/DOE_Fiduciary_Classifier.ipynb#Y160sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m             train_dataset,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aaron.woods/OneDrive%20-%20Thermo%20Fisher%20Scientific/Documents/GitHub/Image-Classification/DOE_Fiduciary_Classifier.ipynb#Y160sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m             validation_data\u001b[39m=\u001b[39;49mvalid_dataset,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aaron.woods/OneDrive%20-%20Thermo%20Fisher%20Scientific/Documents/GitHub/Image-Classification/DOE_Fiduciary_Classifier.ipynb#Y160sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m             epochs\u001b[39m=\u001b[39;49mconfig[\u001b[39m'\u001b[39;49m\u001b[39mModel\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mEPOCHS\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aaron.woods/OneDrive%20-%20Thermo%20Fisher%20Scientific/Documents/GitHub/Image-Classification/DOE_Fiduciary_Classifier.ipynb#Y160sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m             callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aaron.woods/OneDrive%20-%20Thermo%20Fisher%20Scientific/Documents/GitHub/Image-Classification/DOE_Fiduciary_Classifier.ipynb#Y160sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m             class_weight\u001b[39m=\u001b[39;49mcurrent_class_weights  \u001b[39m# Specify class weights here\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aaron.woods/OneDrive%20-%20Thermo%20Fisher%20Scientific/Documents/GitHub/Image-Classification/DOE_Fiduciary_Classifier.ipynb#Y160sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m         )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aaron.woods/OneDrive%20-%20Thermo%20Fisher%20Scientific/Documents/GitHub/Image-Classification/DOE_Fiduciary_Classifier.ipynb#Y160sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mTraining for \u001b[39m\u001b[39m{\u001b[39;00mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m completed.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aaron.woods/OneDrive%20-%20Thermo%20Fisher%20Scientific/Documents/GitHub/Image-Classification/DOE_Fiduciary_Classifier.ipynb#Y160sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mSaved all metrics to \u001b[39m\u001b[39m{\u001b[39;00mexcel_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\aaron.woods\\AppData\\Local\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\aaron.woods\\AppData\\Local\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Training the Classifiers (Main Function)\n",
    "\n",
    "def train_and_save_metrics(train_dataset, valid_dataset, test_dataset, compiled_models, prepared_class_weights):\n",
    "    try:\n",
    "        if train_dataset is None or valid_dataset is None or test_dataset is None:\n",
    "            print(\"One or more datasets are None. Exiting.\")\n",
    "            return\n",
    "\n",
    "        excel_filename = f\"{config['Experiment']['NAME']}.xlsx\"\n",
    "        excel_path = os.path.join(\"./\", excel_filename)\n",
    "\n",
    "        with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:\n",
    "            pd.DataFrame().to_excel(writer, sheet_name=\"InitializationSheet\")\n",
    "\n",
    "            for model_name, model_info in compiled_models.items():\n",
    "                model = model_info.get('model')\n",
    "                callbacks = model_info.get('callbacks')\n",
    "\n",
    "                if model is None or callbacks is None:\n",
    "                    print(f\"Model or callbacks for {model_name} are None. Skipping.\")\n",
    "                    continue\n",
    "\n",
    "                print(f\"Training {model_name} for multi-output...\")\n",
    "                \n",
    "                excel_saver = ExcelMetricsSaver(writer, sheet_name=f\"{model_name}\")\n",
    "                callbacks.append(excel_saver)\n",
    "\n",
    "                # Assuming the names of the outputs in prepared_class_weights match the names in the model\n",
    "                # and that the model has been structured in a way that allows this.\n",
    "                # If not, additional logic will be needed to map between the two.\n",
    "                model_output_names = [layer.name for layer in model.layers if 'output' in layer.name]\n",
    "                current_class_weights = {name: prepared_class_weights[name] for name in model_output_names}\n",
    "\n",
    "                history = model.fit(\n",
    "                    train_dataset,\n",
    "                    validation_data=valid_dataset,\n",
    "                    epochs=config['Model']['EPOCHS'],\n",
    "                    callbacks=callbacks,\n",
    "                    class_weight=current_class_weights  # Specify class weights here\n",
    "                )\n",
    "\n",
    "                print(f\"\\nTraining for {model_name} completed.\")\n",
    "\n",
    "        print(f\"\\nSaved all metrics to {excel_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn error occurred: {e}\") \n",
    "\n",
    "train_and_save_metrics(train_dataset, valid_dataset, test_dataset, compiled_models, prepared_class_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plotting Training Metrics (Metrics per Epoch) for each Model\n",
    "\n",
    "class HandlerTupleVertical(HandlerTuple):\n",
    "    def create_artists(self, legend, orig_handle, xdescent, ydescent, width, height, fontsize, trans):\n",
    "        numlines = len(orig_handle)\n",
    "        handler_map = legend.get_legend_handler_map()\n",
    "        height_y = (height / numlines)\n",
    "        leglines = []\n",
    "        for i, handle in enumerate(orig_handle):\n",
    "            handler = legend.get_legend_handler(handler_map, handle)\n",
    "            legline = handler.create_artists(legend, handle, xdescent, (2*i + 1)*height_y, width, 2*height, fontsize, trans)\n",
    "            leglines.extend(legline)\n",
    "        return leglines\n",
    "\n",
    "def get_dataframes_from_excel(xls):\n",
    "    \"\"\"Load DataFrames from the Excel file.\"\"\"\n",
    "    model_names = xls.sheet_names\n",
    "    return {model_name: pd.read_excel(xls, model_name) for model_name in model_names}\n",
    "\n",
    "def plot_metrics(ax, dfs, metric, readable_metric, color_dict):\n",
    "    \"\"\"Plot metrics for all models on a single graph.\"\"\"\n",
    "    for model_name, cleaned_name in zip(dfs.keys(), color_dict.keys()):\n",
    "        epochs = dfs[model_name]['epoch']\n",
    "        ax.plot(epochs, dfs[model_name][f'{metric}'], '--', color=color_dict[cleaned_name], label=f\"{cleaned_name}\") #Training\n",
    "        ax.plot(epochs, dfs[model_name][f'val_{metric}'], '-', color=color_dict[cleaned_name], label=f\"{cleaned_name}\") #Validation\n",
    "    ax.set_title(f\"{readable_metric} vs Epoch\")\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel(readable_metric)\n",
    "    \n",
    "model_name_mapping = {\n",
    "    \"mobilenetv2\": \"MobileNetV2 Transfer\",\n",
    "    \"inceptionv3\": \"InceptionV3 Transfer\",\n",
    "    \"resnet50\": \"ResNet50 Transfer\",\n",
    "    \"small_xception\": \"Small Xception\",\n",
    "    \"basic_cnn\": \"Basic CNN\"\n",
    "}\n",
    "def plot_metrics_from_excel(excel_path):\n",
    "    # Load the Excel file and get DataFrames\n",
    "    xls = pd.ExcelFile(excel_path)\n",
    "    model_names = xls.sheet_names\n",
    "    dfs = get_dataframes_from_excel(xls)\n",
    "    readable_model_names = [model_name_mapping.get(name, name) for name in model_names]\n",
    "    \n",
    "    # Metrics mapping and Seaborn style\n",
    "    metric_mapping = {\n",
    "        'loss': 'Loss',\n",
    "        'categorical_accuracy': 'Categorical Accuracy',\n",
    "        'categorical_crossentropy': 'Categorical Crossentropy',\n",
    "        'mean_squared_error': 'Mean Squared Error'\n",
    "    }\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    palette = sns.color_palette(\"tab10\", len(model_names))\n",
    "    color_dict = {readable_name: palette[i] for i, readable_name in enumerate(readable_model_names)}\n",
    "    \n",
    "    # Plotting\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(18, 10))\n",
    "    axes_flat = axes.ravel()\n",
    "    for i, (metric, readable_metric) in enumerate(metric_mapping.items()):\n",
    "        plot_metrics(axes_flat[i], dfs, metric, readable_metric, color_dict)\n",
    "        # Add legend to each subplot\n",
    "        handles, labels = axes_flat[i].get_legend_handles_labels()\n",
    "        new_handles = [(handles[j], handles[j + 1]) for j in range(0, len(handles), 2)]\n",
    "        axes_flat[i].legend(new_handles, labels[::2], handler_map={tuple: HandlerTupleVertical()})\n",
    "    \n",
    "    # Add main title\n",
    "    experiment_name = os.path.basename(excel_path).replace(\".xlsx\", \"\")\n",
    "    fig.suptitle(f\"Metrics for {experiment_name}\", fontsize=20, y=1.08)\n",
    "    \n",
    "    # Add informational note below the subplots\n",
    "    note_text = r\"$\\bf{Models}$\" + \"\\nTraining (Dashed) | Validation (Solid)\"\n",
    "    fig.text(0.5, -0.02, note_text, ha='center', fontsize=10, transform=fig.transFigure)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    \n",
    "    # Save and display\n",
    "    base_dir = os.path.dirname(excel_path)\n",
    "    output_dir = os.path.join(base_dir, f\"Plots/{experiment_name}\")\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    save_path = os.path.join(output_dir, \"Metrics_vs_Epoch.png\")\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    return save_path\n",
    "\n",
    "# Mocking the actual plot as the excel_path is not available\n",
    "# excel_path = 'SIM_Unbalanced.xlsx'\n",
    "# improved_save_path = plot_metrics_from_excel(excel_path)\n",
    "# improved_save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Comparing Experiment Results\n",
    "\n",
    "def extract_key_metrics_updated(excel_path):\n",
    "    \"\"\"Extract key metrics from the provided Excel file without using determine_engine.\"\"\"\n",
    "    # Load the Excel file and get DataFrames\n",
    "    xls = pd.ExcelFile(excel_path, engine=\"openpyxl\")\n",
    "    dfs = get_dataframes_from_excel(xls)\n",
    "\n",
    "    return {\n",
    "        model_name: {\n",
    "            \"Min Validation Loss\": df[\"val_loss\"].min(),\n",
    "            \"Epoch at Min Validation Loss\": df[\"epoch\"].iloc[\n",
    "                df[\"val_loss\"].idxmin()\n",
    "            ],\n",
    "            \"Max Validation Categorical Accuracy\": df[\n",
    "                \"val_categorical_accuracy\"\n",
    "            ].max(),\n",
    "            \"Epoch at Max Validation Categorical Accuracy\": df[\"epoch\"].iloc[\n",
    "                df[\"val_categorical_accuracy\"].idxmax()\n",
    "            ],\n",
    "            \"Min Validation Categorical Crossentropy\": df[\n",
    "                \"val_categorical_crossentropy\"\n",
    "            ].min(),\n",
    "            \"Epoch at Min Validation Categorical Crossentropy\": df[\n",
    "                \"epoch\"\n",
    "            ].iloc[df[\"val_categorical_crossentropy\"].idxmin()],\n",
    "            \"Min Validation Mean Squared Error\": df[\n",
    "                \"val_mean_squared_error\"\n",
    "            ].min(),\n",
    "            \"Epoch at Min Validation Mean Squared Error\": df[\"epoch\"].iloc[\n",
    "                df[\"val_mean_squared_error\"].idxmin()\n",
    "            ],\n",
    "        }\n",
    "        for model_name, df in dfs.items()\n",
    "    }\n",
    "\n",
    "\n",
    "def visualize_metric_comparison_with_mapping_annotated(file_paths, name_mapping, metric_key, metric_title, epoch_key):\n",
    "    \"\"\"Visualize a specific metric across experiments using a name mapping and annotate bars with epoch numbers.\"\"\"\n",
    "    metric_data = {}\n",
    "    epoch_data = {}\n",
    "    \n",
    "    # Extract specific metric and epoch data\n",
    "    for excel_path in file_paths:\n",
    "        experiment_name = os.path.basename(excel_path).replace(\".xlsx\", \"\")\n",
    "        metrics = extract_key_metrics_updated(excel_path)\n",
    "        \n",
    "        # Use the model_name_mapping to rename models\n",
    "        mapped_metric_values = {name_mapping.get(model, model): data[metric_key] for model, data in metrics.items()}\n",
    "        mapped_epoch_values = {name_mapping.get(model, model): data[epoch_key] for model, data in metrics.items()}\n",
    "        \n",
    "        metric_data[experiment_name] = mapped_metric_values\n",
    "        epoch_data[experiment_name] = mapped_epoch_values\n",
    "    \n",
    "    # Convert to DataFrame for easy plotting\n",
    "    metric_df = pd.DataFrame(metric_data).transpose()\n",
    "    \n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    ax = metric_df.plot(kind=\"bar\", ax=plt.gca(), colormap=\"viridis\")\n",
    "    plt.title(metric_title, fontsize=18)\n",
    "    plt.ylabel(metric_key, fontsize=16)\n",
    "    plt.xlabel(\"Experiment\", fontsize=16)\n",
    "    plt.legend(title=\"Models\", bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=12, title_fontsize=14)\n",
    "    plt.xticks(rotation=45, fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    ax.grid(axis='y')\n",
    "    \n",
    "    # Annotate bars with epoch numbers\n",
    "    for idx, rect in enumerate(ax.patches):\n",
    "        experiment_idx = idx // len(metric_df.columns)\n",
    "        model_idx = idx % len(metric_df.columns)\n",
    "        experiment_name = metric_df.index[experiment_idx]\n",
    "        model_name = metric_df.columns[model_idx]\n",
    "        epoch_value = epoch_data[experiment_name][model_name]\n",
    "        ax.text(rect.get_x() + rect.get_width() / 2, rect.get_height(), f'Ep {epoch_value}', ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Visualize all the key metrics with annotations\n",
    "metric_visualization_keys_with_epochs = [\n",
    "    (\"Max Validation Categorical Accuracy\", \"Max Validation Categorical Accuracy Across Experiments\", \"Epoch at Max Validation Categorical Accuracy\"),\n",
    "    (\"Min Validation Loss\", \"Min Validation Loss Across Experiments\", \"Epoch at Min Validation Loss\"),\n",
    "    (\"Min Validation Categorical Crossentropy\", \"Min Validation Categorical Crossentropy Across Experiments\", \"Epoch at Min Validation Categorical Crossentropy\"),\n",
    "    (\"Min Validation Mean Squared Error\", \"Min Validation Mean Squared Error Across Experiments\", \"Epoch at Min Validation Mean Squared Error\")\n",
    "]\n",
    "\n",
    "for metric_key, metric_title, epoch_key in metric_visualization_keys_with_epochs:\n",
    "    visualize_metric_comparison_with_mapping_annotated(\n",
    "        [\"SIM_Unbalanced.xlsx\", \"V9_Laptop - Multi-Output.xlsx\", \"V9.1_Laptop - Multi-Output.xlsx\"],\n",
    "        model_name_mapping,\n",
    "        metric_key,\n",
    "        metric_title,\n",
    "        epoch_key\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Testing Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading the Best Model from Directories\n",
    "\n",
    "def get_best_model_filename(directory):\n",
    "    \"\"\"Identify the best model filename based on the minimum validation loss from the directory.\"\"\"\n",
    "    model_files = [f for f in os.listdir(directory) if f.endswith('.h5')]\n",
    "    if not model_files:\n",
    "        print(f\"No model files found in {directory}\")\n",
    "        return None\n",
    "    return min(model_files, key=lambda x: float(x.split('val_loss_')[1].split('_')[0]))\n",
    "\n",
    "def load_best_model(directory):\n",
    "    \"\"\"Loads the best model from the specified directory.\"\"\"\n",
    "    best_model_file = get_best_model_filename(directory)\n",
    "    if not best_model_file:\n",
    "        return None\n",
    "    best_model_path = os.path.join(directory, best_model_file)\n",
    "    # return load_model(best_model_path)\n",
    "    return load_model(best_model_path, compile=False)\n",
    "\n",
    "def get_label_directories(experiment_directory):\n",
    "    \"\"\"Determine label directories or just model directories in the experiment directory.\"\"\"\n",
    "    first_level_dirs = [os.path.join(experiment_directory, d) for d in os.listdir(experiment_directory) \n",
    "                        if os.path.isdir(os.path.join(experiment_directory, d))]\n",
    "    if any('mobilenetv2' in dir_name for dir_name in first_level_dirs):\n",
    "        return [experiment_directory]\n",
    "    return first_level_dirs\n",
    "\n",
    "def load_all_best_models(experiment_directory):\n",
    "    \"\"\"Load the best model for each model type within the experiment directory.\"\"\"\n",
    "    best_models = {}\n",
    "    label_dirs = get_label_directories(experiment_directory)\n",
    "    for label_dir in label_dirs:\n",
    "        for model_name in ['mobilenetv2', 'inceptionv3', 'resnet50', 'small_xception', 'basic_cnn']:\n",
    "            model_dir = os.path.join(label_dir, model_name)\n",
    "            best_model = load_best_model(model_dir)\n",
    "            if best_model:\n",
    "                key_name = f\"{os.path.basename(label_dir)}_{model_name}\"\n",
    "                best_models[key_name] = best_model\n",
    "    return best_models\n",
    "\n",
    "# Example Usage\n",
    "experiment_directory = \"SIM_Unbalanced\"\n",
    "all_best_models = load_all_best_models(experiment_directory)\n",
    "print(all_best_models.keys())  # This will display the keys of the loaded models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beta Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function for Confusion Matrix\n",
    "\n",
    "def make_confusion_matrix_multi_output(y_true, y_preds, classes=None, figsize=(10, 10), text_size=15, norm=False, savefig=False): \n",
    "    \"\"\"\n",
    "    Makes a labelled confusion matrix comparing predictions and ground truth labels for multi-output models.\n",
    "\n",
    "    Args:\n",
    "    y_true: List of arrays of truth labels (must be same shape as y_preds).\n",
    "    y_preds: List of arrays of predicted labels (must be same shape as y_true).\n",
    "    classes: List of arrays of class labels (e.g. string form). If `None`, integer labels are used.\n",
    "    ... (other arguments as before)\n",
    "\n",
    "    Returns:\n",
    "    A list of labelled confusion matrix plots comparing y_true and y_preds for each output.\n",
    "    \"\"\"\n",
    "    # Check if y_true and y_preds are lists, if not, convert them to lists (for single-output compatibility)\n",
    "    if not isinstance(y_true, list):\n",
    "        y_true = [y_true]\n",
    "    if not isinstance(y_preds, list):\n",
    "        y_preds = [y_preds]\n",
    "    \n",
    "    for i, (true, pred) in enumerate(zip(y_true, y_preds)):\n",
    "        print(f\"Output {i + 1}:\")\n",
    "        make_confusion_matrix(true, pred, classes[i] if classes else None, figsize, text_size, norm, savefig)\n",
    "        plt.show()\n",
    "\n",
    "def make_confusion_matrix(y_true, y_pred, classes=None, figsize=(10, 10), text_size=15, norm=False, savefig=False):\n",
    "    # (The function content remains the same as you provided)\n",
    "\n",
    "    # Create the confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]  # normalize it\n",
    "    n_classes = cm.shape[0]  # find the number of classes we're dealing with\n",
    "\n",
    "    # Plot the figure and make it pretty\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    cax = ax.matshow(cm, cmap=plt.cm.Blues)  # colors will represent how 'correct' a class is, darker == better\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Are there a list of classes?\n",
    "    labels = classes if classes else np.arange(cm.shape[0])\n",
    "    \n",
    "    # Label the axes\n",
    "    ax.set(title=\"Confusion Matrix\",\n",
    "           xlabel=\"Predicted label\",\n",
    "           ylabel=\"True label\",\n",
    "           xticks=np.arange(n_classes),\n",
    "           yticks=np.arange(n_classes),\n",
    "           xticklabels=labels,\n",
    "           yticklabels=labels)\n",
    "\n",
    "    # Make x-axis labels appear on bottom\n",
    "    ax.xaxis.set_label_position(\"bottom\")\n",
    "    ax.xaxis.tick_bottom()\n",
    "\n",
    "    # Set the threshold for different colors\n",
    "    threshold = (cm.max() + cm.min()) / 2.\n",
    "\n",
    "    # Plot the text on each cell\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if norm:\n",
    "            plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)\",\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > threshold else \"black\",\n",
    "                     size=text_size)\n",
    "        else:\n",
    "            plt.text(j, i, f\"{cm[i, j]}\",\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > threshold else \"black\",\n",
    "                     size=text_size)\n",
    "\n",
    "    # Save the figure to the current working directory\n",
    "    if savefig:\n",
    "        fig.savefig(f\"confusion_matrix_output_{i + 1}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Attempt at Using the Confusion Matrix Function\n",
    "\n",
    "def extract_labels_from_dataset(dataset, problem_type):\n",
    "    \"\"\"\n",
    "    Extract labels from a TensorFlow dataset based on the problem type.\n",
    "    \n",
    "    Args:\n",
    "    - dataset (tf.data.Dataset): The TensorFlow dataset to extract labels from.\n",
    "    - problem_type (str): The type of problem ('Multi-Output', 'Multi-Class', or 'Binary').\n",
    "    \n",
    "    Returns:\n",
    "    - numpy array or dict: If 'Multi-Output', returns a numpy array with shape (num_samples, num_outputs).\n",
    "                           If 'Multi-Class' or 'Binary', returns a dictionary with label types as keys and \n",
    "                           arrays of labels as values.\n",
    "    \"\"\"\n",
    "    \n",
    "    if problem_type == 'Multi-Output':\n",
    "        labels_list = [labels for _, labels in dataset]\n",
    "        return np.array(labels_list).squeeze()\n",
    "\n",
    "    elif problem_type in ['Multi-Class', 'Binary']:\n",
    "        labels_dict = {}\n",
    "        for label_type in ['Focus_Label', 'StigX_Label', 'StigY_Label']:\n",
    "            label_data = []\n",
    "            for _, labels in dataset[label_type]:\n",
    "                label_data.extend(labels.numpy())\n",
    "            labels_dict[label_type] = np.array(label_data)\n",
    "        return labels_dict\n",
    "\n",
    "    else:\n",
    "        print(f\"Unknown problem type: {problem_type}\")\n",
    "        return None\n",
    "\n",
    "# Usage\n",
    "problem_type = config['Experiment']['PROBLEM_TYPE']\n",
    "test_labels = extract_labels_from_dataset(test_dataset, problem_type)\n",
    "\n",
    "# Choose a specific model (replace 'specific_model_name' with the actual model name you're interested in)\n",
    "model_name = 'specific_model_name'\n",
    "model = all_best_models[model_name]\n",
    "\n",
    "if not model:\n",
    "    print(f\"No model found for {model_name}\")\n",
    "    exit()\n",
    "\n",
    "# 1. Predict on the test data\n",
    "predictions = model.predict(test_dataset)\n",
    "\n",
    "\n",
    "# 2. Get true labels and predictions for each output\n",
    "# Assuming test_labels is a list where each item is an array of true labels for a given output\n",
    "true_labels = [test_labels[i] for i in range(len(predictions))]\n",
    "predicted_labels = [np.argmax(predictions[i], axis=1) for i in range(len(predictions))]\n",
    "\n",
    "# List of class names for each output, assuming they are the same for all outputs in this example\n",
    "classes_list = [list(range(3)) for _ in range(len(predictions))]\n",
    "\n",
    "# 3. Generate confusion matrices\n",
    "make_confusion_matrix_multi_output(true_labels, predicted_labels, classes_list)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
