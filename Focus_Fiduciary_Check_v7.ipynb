{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUp_gOf2wQqG"
      },
      "source": [
        "## Focus Fiduciary Check\n",
        "**Author:** [Aaron Woods](https://aaronwoods.info)<br>\n",
        "**Date created:** 2023/09/11<br>\n",
        "**Description:** This script demonstrates how to build a binary classifier model for the task of classifying images as \"In Focus\" or \"Out of Focus\".\n",
        "https://insiders.vscode.dev/tunnel/midnightsim/c:/Users/User/Desktop/Image-Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koUD8kO-RN5I"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrZQSCRMY84q",
        "outputId": "8fc891c5-8037-4a2f-bccb-61b84472be8c"
      },
      "outputs": [],
      "source": [
        "# !pip install tensorflow-gpu numpy pandas matplotlib protobuf seaborn scikit-learn tensorflow > /dev/null 2>&1\n",
        "# To suprress the output we use > /dev/null 2>&1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tqiz9envy2mP",
        "outputId": "02b80156-7bc5-4ab5-c41c-3aef08e13c54"
      },
      "outputs": [],
      "source": [
        "# Standard Libraries\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "import math\n",
        "from datetime import datetime\n",
        "import logging\n",
        "import glob \n",
        "\n",
        "# Third-Party Libraries\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from IPython.display import clear_output\n",
        "from collections import defaultdict\n",
        "\n",
        "# TensorFlow and Keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
        "from tensorflow.keras.callbacks import TensorBoard, Callback\n",
        "from tensorflow.keras.applications import InceptionV3, ResNet50\n",
        "from keras.models import load_model\n",
        "import pickle\n",
        "\n",
        "# Type Annotations\n",
        "from typing import List, Dict, Tuple, Union, Any, Optional\n",
        "\n",
        "# Check for GPU support\n",
        "if not tf.config.list_physical_devices('GPU'):\n",
        "    print(\"No GPU was detected. Neural nets can be very slow without a GPU.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Platform: Windows-10-10.0.17763-SP0\n",
            "Python Version: 3.9.18\n",
            "TensorFlow Version: 2.10.1\n",
            "Num GPUs Available: 1\n",
            "Instructions: You're all set to run your model on a GPU.\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries and initialize an empty dictionary for system info\n",
        "import platform\n",
        "system_info = {\"Platform\": platform.platform(), \"Python Version\": platform.python_version()}\n",
        "\n",
        "# Try to import TensorFlow and gather related information\n",
        "try:\n",
        "    import tensorflow as tf\n",
        "    system_info.update({\n",
        "        \"TensorFlow Version\": tf.__version__,\n",
        "        \"Num GPUs Available\": len(tf.config.list_physical_devices('GPU'))\n",
        "    })\n",
        "    system_info['Instructions'] = \"You're all set to run your model on a GPU.\" if system_info['Num GPUs Available'] else (\n",
        "        \"No GPUs found. To use a GPU, follow these steps:\\n\"\n",
        "        \"  1. Install NVIDIA drivers for your GPU.\\n\"\n",
        "        \"  2. Install a compatible CUDA toolkit.\\n\"\n",
        "        \"  3. Install the cuDNN library.\\n\"\n",
        "        \"  4. Make sure to install the GPU version of TensorFlow.\"\n",
        "    )\n",
        "except ModuleNotFoundError:\n",
        "    system_info['Instructions'] = \"TensorFlow is not installed. Install it using pip by running: !pip install tensorflow\"\n",
        "\n",
        "# Format and display the information\n",
        "formatted_info = \"\\n\".join(f\"{key}: {value}\" for key, value in system_info.items())\n",
        "print(formatted_info)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "xZjbPVw1U5Mt"
      },
      "outputs": [],
      "source": [
        "# @title Configuration\n",
        "\n",
        "# Configuration dictionary\n",
        "config = {\n",
        "    'Experiment': {\n",
        "        'NAME': \"Multi-Class_Thresholds-30-60-1-2\",\n",
        "        'RANDOM_SEED': 42,\n",
        "    },\n",
        "    'Model': {\n",
        "        'IMG_SIZE': 224,\n",
        "        'BATCH_SIZE': 32,\n",
        "        'EPOCHS': 100,\n",
        "        'LEARNING_RATE': 1e-3,\n",
        "        'EARLY_STOPPING_PATIENCE': 5,\n",
        "        'REDUCE_LR_PATIENCE': 3,\n",
        "        'MIN_LR': 1e-6,\n",
        "        'LOSS': \"categorical_crossentropy\",  # Updated for multi-class\n",
        "        'TRAIN_SIZE': 0.8,\n",
        "        'VAL_SIZE': 0.5,\n",
        "    },\n",
        "    'Thresholds': {\n",
        "        'FOCUS_LOW': 30,\n",
        "        'FOCUS_HIGH': 60,\n",
        "        'STIG_LOW': 1,\n",
        "        'STIG_HIGH': 2,\n",
        "    },\n",
        "    'Labels': {\n",
        "        'MAPPINGS': {\n",
        "            'Focus_Label': {'SharpFocus': 0, 'SlightlyBlurred': 1, 'HighlyBlurred': 2},\n",
        "            'StigX_Label': {'OptimalStig_X': 0, 'ModerateStig_X': 1, 'SevereStig_X': 2},\n",
        "            'StigY_Label': {'OptimalStig_Y': 0, 'ModerateStig_Y': 1, 'SevereStig_Y': 2},\n",
        "        }\n",
        "    },\n",
        "    'Paths': {\n",
        "        'BASE_DIR': \"Y:\\\\User\\\\Aaron-HX38\\\\DOE\\\\\",\n",
        "        'DATA_FILE': \"combined_output.csv\",\n",
        "        'OLD_BASE_PATH': \"D:\\\\DOE\\\\\",\n",
        "        'NEW_BASE_PATH': \"Y:\\\\User\\\\Aaron-HX38\\\\DOE\\\\\",\n",
        "    },\n",
        "    'Augmentation': {\n",
        "        'rotation_factor': 0.002,\n",
        "        'height_factor': (-0.18, 0.18),\n",
        "        'width_factor': (-0.18, 0.18),\n",
        "        'contrast_factor': 0.5,\n",
        "    }\n",
        "}\n",
        "\n",
        "# Random seed for reproducibility\n",
        "np.random.seed(config['Experiment']['RANDOM_SEED'])\n",
        "tf.random.set_seed(config['Experiment']['RANDOM_SEED'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5fVaBWTjbUp"
      },
      "source": [
        "## Defining the Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "cellView": "form",
        "id": "e5n2ZL4tfrPF"
      },
      "outputs": [],
      "source": [
        "# Transfer learning models\n",
        "def create_transfer_model(base_model, input_shape: tuple, num_classes: int, hidden_units: list, dropout_rate: float, regularizer_rate: float) -> keras.Model:\n",
        "    \"\"\"Creates a transfer learning model based on a given base model.\"\"\"\n",
        "    base_model.trainable = False\n",
        "\n",
        "    model = keras.Sequential([\n",
        "        base_model,\n",
        "        layers.GlobalAveragePooling2D()\n",
        "    ])\n",
        "\n",
        "    for units in hidden_units:\n",
        "        model.add(layers.Dense(units, kernel_regularizer=keras.regularizers.l2(regularizer_rate), bias_regularizer=keras.regularizers.l2(regularizer_rate)))\n",
        "        model.add(layers.LeakyReLU())\n",
        "        model.add(layers.Dropout(dropout_rate))\n",
        "\n",
        "    activation, units = (\"sigmoid\", 1) if num_classes == 2 else (\"softmax\", num_classes)\n",
        "    model.add(layers.Dense(units, activation=activation))\n",
        "\n",
        "    return model\n",
        "\n",
        "def create_mobilenetv2_transfer_model(input_shape: tuple, num_classes: int) -> keras.Model:\n",
        "    \"\"\"Creates a MobileNetV2 based transfer learning model.\"\"\"\n",
        "    base_model = tf.keras.applications.MobileNetV2(input_shape=input_shape, include_top=False, weights='imagenet')\n",
        "    return create_transfer_model(base_model, input_shape, num_classes, [128, 64], 0.5, 0.001)\n",
        "\n",
        "def create_inceptionv3_transfer_model(input_shape: tuple, num_classes: int) -> keras.Model:\n",
        "    \"\"\"Creates an InceptionV3 based transfer learning model.\"\"\"\n",
        "    base_model = tf.keras.applications.InceptionV3(input_shape=input_shape, include_top=False, weights='imagenet')\n",
        "    return create_transfer_model(base_model, input_shape, num_classes, [128, 64], 0.5, 0.001)\n",
        "\n",
        "def create_resnet50_transfer_model(input_shape: tuple, num_classes: int) -> keras.Model:\n",
        "    \"\"\"Creates a ResNet50 based transfer learning model.\"\"\"\n",
        "    base_model = tf.keras.applications.ResNet50(input_shape=input_shape, include_top=False, weights='imagenet')\n",
        "    return create_transfer_model(base_model, input_shape, num_classes, [256, 128], 0.5, 0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "cellView": "form",
        "id": "UODux7HGfoke"
      },
      "outputs": [],
      "source": [
        "# Define the function to create a small version of the Xception network\n",
        "def create_small_xception_model(input_shape, num_classes):\n",
        "    # Input layer\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "\n",
        "    # Entry block: Initial Convolution and BatchNormalization\n",
        "    x = layers.Rescaling(1.0 / 255)(inputs)\n",
        "    x = layers.Conv2D(128, 3, strides=2, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "    previous_block_activation = x  # Set aside residual for later use\n",
        "\n",
        "    # Middle flow: Stacking Separable Convolution blocks\n",
        "    for size in [256, 512, 728]:\n",
        "        # ReLU activation\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        # Separable Convolution\n",
        "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        # ReLU activation\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        # Separable Convolution\n",
        "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        # Max Pooling\n",
        "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "\n",
        "        # Project residual from previous block and add it to the current block\n",
        "        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(previous_block_activation)\n",
        "        x = layers.add([x, residual])  # Add back residual\n",
        "        previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "    # Exit flow: Final Separable Convolution, BatchNormalization, and Global Average Pooling\n",
        "    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "    # Determine activation and units based on the number of classes\n",
        "    if num_classes == 2:\n",
        "        activation = \"sigmoid\"\n",
        "        units = 1\n",
        "    else:\n",
        "        activation = \"softmax\"\n",
        "        units = num_classes\n",
        "\n",
        "    # Dropout and Dense output layer\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(units, activation=activation)(x)\n",
        "\n",
        "    return keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "cellView": "form",
        "id": "qQKfbNT_fmEh"
      },
      "outputs": [],
      "source": [
        "# Define the function to create a basic CNN model\n",
        "def create_basic_cnn_model(input_shape, num_classes):\n",
        "    conv2d_filter_size = (3, 3)\n",
        "    conv2d_activation = 'relu'\n",
        "    dense_activation = 'relu'\n",
        "    num_conv_blocks = 3\n",
        "\n",
        "    model = tf.keras.models.Sequential()\n",
        "\n",
        "    # Explicitly define the input shape\n",
        "    model.add(tf.keras.layers.Input(shape=input_shape))\n",
        "\n",
        "    for _ in range(num_conv_blocks):\n",
        "        model.add(tf.keras.layers.Conv2D(32 * (2**_), conv2d_filter_size, activation=conv2d_activation, padding='same'))\n",
        "        model.add(tf.keras.layers.BatchNormalization())\n",
        "        model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
        "    model.add(tf.keras.layers.Dense(128, activation=dense_activation))\n",
        "\n",
        "    # Determine activation and units based on the number of classes\n",
        "    if num_classes == 2:\n",
        "        activation = \"sigmoid\"\n",
        "        units = 1\n",
        "    else:\n",
        "        activation = \"softmax\"\n",
        "        units = num_classes\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(units, activation=activation))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "cellView": "form",
        "id": "qXCZWQbwfjQN"
      },
      "outputs": [],
      "source": [
        "# Model Selection function to select which model to use\n",
        "def select_model(model_name: str, input_shape: tuple, num_classes: int) -> keras.Model:\n",
        "    \"\"\"Selects a model to use based on the given model name.\"\"\"\n",
        "    model_map = {\n",
        "        \"mobilenetv2\": create_mobilenetv2_transfer_model,\n",
        "        \"inceptionv3\": create_inceptionv3_transfer_model,\n",
        "        \"resnet50\": create_resnet50_transfer_model,\n",
        "        \"small_xception\": create_small_xception_model,\n",
        "        \"basic_cnn\": create_basic_cnn_model\n",
        "    }\n",
        "    if model_name not in model_map:\n",
        "        raise ValueError(\"Invalid model name\")\n",
        "\n",
        "    return model_map[model_name](input_shape, num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxgo-pN6b7d3"
      },
      "source": [
        "## Load and Preprocess the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Image Processing Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from typing import Tuple\n",
        "\n",
        "def create_preprocessing_layers(img_width: int, img_height: int, rescale_factor: float) -> keras.Sequential:\n",
        "    \"\"\"Create preprocessing layers for resizing and rescaling images.\"\"\"\n",
        "    return keras.Sequential([\n",
        "        layers.Resizing(img_width, img_height),\n",
        "        layers.Rescaling(rescale_factor)\n",
        "    ])\n",
        "\n",
        "\n",
        "def create_augmentation_layers(augmentation_config: dict) -> keras.Sequential:\n",
        "    \"\"\"Create data augmentation layers.\"\"\"\n",
        "    try:\n",
        "        augmentation_layers = tf.keras.Sequential([\n",
        "            layers.RandomFlip(\"horizontal\"),\n",
        "            layers.RandomFlip(\"vertical\"),\n",
        "            layers.RandomRotation(augmentation_config['rotation_factor']),\n",
        "            layers.RandomTranslation(\n",
        "                height_factor=augmentation_config['height_factor'],\n",
        "                width_factor=augmentation_config['width_factor'],\n",
        "                fill_mode=\"reflect\"\n",
        "            ),\n",
        "            layers.RandomContrast(augmentation_config['contrast_factor']),\n",
        "        ])\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while creating augmentation layers: {e}\")\n",
        "    \n",
        "    return augmentation_layers\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def read_and_convert_image(file_path: str) -> tf.Tensor:\n",
        "    \"\"\"Read an image from a file and convert it to a 3-channel tensor.\"\"\"\n",
        "    image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
        "    image = tf.convert_to_tensor(image, dtype=tf.float32)\n",
        "    image = tf.expand_dims(image, axis=-1)\n",
        "    return tf.image.grayscale_to_rgb(image)\n",
        "\n",
        "def preprocess_image(file_path, label, augment, config: dict) -> Tuple[tf.Tensor, tf.Tensor]:\n",
        "    \"\"\"Preprocess an image by applying resizing, rescaling, and optional data augmentation.\"\"\"\n",
        "    file_path = file_path.numpy().decode(\"utf-8\")\n",
        "    \n",
        "    preprocess_seq = create_preprocessing_layers(\n",
        "        img_width=config['Model']['IMG_SIZE'], \n",
        "        img_height=config['Model']['IMG_SIZE'], \n",
        "        rescale_factor=1./255\n",
        "    )\n",
        "    augment_seq = create_augmentation_layers(config['Augmentation'])\n",
        "    \n",
        "    image = read_and_convert_image(file_path)\n",
        "    image = preprocess_seq(image)\n",
        "    \n",
        "    if augment:\n",
        "        image = augment_seq(image)\n",
        "        image = tf.clip_by_value(image, 0, 1)  # Clip values after augmentation\n",
        "        \n",
        "    return image, label\n",
        "\n",
        "def preprocess_wrapper(file_path, label, augment, config: dict) -> Tuple[tf.Tensor, tf.Tensor]:\n",
        "    \"\"\"Wrapper function for TensorFlow's map function.\"\"\"\n",
        "    image, label = tf.py_function(\n",
        "        func=lambda file_path, label, augment: preprocess_image(file_path, label, augment, config),\n",
        "        inp=[file_path, label, augment], \n",
        "        Tout=[tf.float32, tf.int64]  # Keep this as tf.int64 for now\n",
        "    )\n",
        "    label.set_shape(())\n",
        "    label = tf.cast(label, tf.int32)  # Explicitly cast label to tf.int32\n",
        "    return image, label\n",
        "\n",
        "\n",
        "def preprocess_images(train_ds, valid_ds, test_ds, config: dict):\n",
        "    \"\"\"Apply preprocessing to training, validation, and test datasets.\"\"\"\n",
        "    train_ds = train_ds.map(lambda file_path, label: preprocess_wrapper(file_path, label, True, config))\n",
        "    valid_ds = valid_ds.map(lambda file_path, label: preprocess_wrapper(file_path, label, False, config))\n",
        "    test_ds = test_ds.map(lambda file_path, label: preprocess_wrapper(file_path, label, False, config))\n",
        "    \n",
        "    return train_ds, valid_ds, test_ds\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Functions for Preparation of CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===== Preprocessing CSV Data =====\n",
            "---> Reading data from: Y:\\User\\Aaron - HX38\\DOE\\combined_output.csv\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "Error: File does not exist - Y:\\User\\Aaron - HX38\\DOE\\combined_output.csv",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\User\\Desktop\\Image-Classification\\Focus_Fiduciary_Check_v7.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/Image-Classification/Focus_Fiduciary_Check_v7.ipynb#X22sZmlsZQ%3D%3D?line=134'>135</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m datasets\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/Image-Classification/Focus_Fiduciary_Check_v7.ipynb#X22sZmlsZQ%3D%3D?line=136'>137</a>\u001b[0m \u001b[39m# Preprocess and prepare datasets\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/Image-Classification/Focus_Fiduciary_Check_v7.ipynb#X22sZmlsZQ%3D%3D?line=137'>138</a>\u001b[0m datasets \u001b[39m=\u001b[39m preprocess_and_prepare_tf_datasets(config)\n",
            "\u001b[1;32mc:\\Users\\User\\Desktop\\Image-Classification\\Focus_Fiduciary_Check_v7.ipynb Cell 17\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/Image-Classification/Focus_Fiduciary_Check_v7.ipynb#X22sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m---> Reading data from: \u001b[39m\u001b[39m{\u001b[39;00mdata_file_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/Image-Classification/Focus_Fiduciary_Check_v7.ipynb#X22sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(data_file_path):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/Image-Classification/Focus_Fiduciary_Check_v7.ipynb#X22sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError: File does not exist - \u001b[39m\u001b[39m{\u001b[39;00mdata_file_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/Image-Classification/Focus_Fiduciary_Check_v7.ipynb#X22sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/Image-Classification/Focus_Fiduciary_Check_v7.ipynb#X22sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(data_file_path)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: Error: File does not exist - Y:\\User\\Aaron - HX38\\DOE\\combined_output.csv"
          ]
        }
      ],
      "source": [
        "# Data Preprocessing and Dataset Preparation\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.data import Dataset\n",
        "import tensorflow as tf\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "def preprocess_and_prepare_tf_datasets(config: dict) -> dict:\n",
        "    \"\"\"Preprocess a CSV data file and prepare TensorFlow datasets.\"\"\"\n",
        "    \n",
        "    print(\"===== Preprocessing CSV Data =====\")\n",
        "    \n",
        "    # Functionality to read the data\n",
        "    data_file_path = os.path.join(config['Paths']['BASE_DIR'], config['Paths']['DATA_FILE'])\n",
        "    print(f\"---> Reading data from: {data_file_path}\")\n",
        "    \n",
        "    if not os.path.exists(data_file_path):\n",
        "        raise FileNotFoundError(f\"Error: File does not exist - {data_file_path}\")\n",
        "    \n",
        "    try:\n",
        "        data = pd.read_csv(data_file_path)\n",
        "        print(\"---> Data read successfully.\")\n",
        "    except Exception as e:\n",
        "        raise ValueError(f\"Error: Could not read data - {e}\") from e\n",
        "    \n",
        "    # Functionality to update image paths\n",
        "    print(\"---> Updating image file paths...\")\n",
        "    data['ImageFile'] = data['ImageFile'].str.replace(config['Paths']['OLD_BASE_PATH'], config['Paths']['NEW_BASE_PATH'], regex=False)\n",
        "    print(\"---> Image paths updated.\")\n",
        "    \n",
        "    # Functionality to generate labels for Focus, StigX, and StigY\n",
        "    print(\"---> Generating labels for Focus, StigX, and StigY...\")\n",
        "    focus_conditions = [\n",
        "        (data['Focus_Offset (V)'].abs() <= config['Thresholds']['FOCUS_LOW']),\n",
        "        (data['Focus_Offset (V)'].abs() <= config['Thresholds']['FOCUS_HIGH']),\n",
        "        (data['Focus_Offset (V)'].abs() > config['Thresholds']['FOCUS_HIGH'])]\n",
        "    stig_x_conditions = [\n",
        "        (data['Stig_Offset_X (V)'].abs() <= config['Thresholds']['STIG_LOW']),\n",
        "        (data['Stig_Offset_X (V)'].abs() <= config['Thresholds']['STIG_HIGH']),\n",
        "        (data['Stig_Offset_X (V)'].abs() > config['Thresholds']['STIG_HIGH'])]\n",
        "    stig_y_conditions = [\n",
        "        (data['Stig_Offset_Y (V)'].abs() <= config['Thresholds']['STIG_LOW']),\n",
        "        (data['Stig_Offset_Y (V)'].abs() <= config['Thresholds']['STIG_HIGH']),\n",
        "        (data['Stig_Offset_Y (V)'].abs() > config['Thresholds']['STIG_HIGH'])]\n",
        "    focus_choices = list(config['Labels']['MAPPINGS']['Focus_Label'].keys())\n",
        "    stig_x_choices = list(config['Labels']['MAPPINGS']['StigX_Label'].keys())\n",
        "    stig_y_choices = list(config['Labels']['MAPPINGS']['StigY_Label'].keys())\n",
        "    data['Focus_Label'] = np.select(focus_conditions, focus_choices)\n",
        "    data['StigX_Label'] = np.select(stig_x_conditions, stig_x_choices)\n",
        "    data['StigY_Label'] = np.select(stig_y_conditions, stig_y_choices)\n",
        "    print(\"---> Labels generated.\")\n",
        "\n",
        "    # # Generate One-Hot Encoded Labels for Focus, StigX, and StigY\n",
        "    # print(\"---> Generating one-hot encoded labels for Focus, StigX, and StigY...\")\n",
        "    # # One-hot encode the labels\n",
        "    # focus_one_hot = pd.get_dummies(data['Focus_Label'], prefix='Focus')\n",
        "    # stig_x_one_hot = pd.get_dummies(data['StigX_Label'], prefix='StigX')\n",
        "    # stig_y_one_hot = pd.get_dummies(data['StigY_Label'], prefix='StigY')\n",
        "    # # Concatenate one-hot columns to the dataframe\n",
        "    # data = pd.concat([data, focus_one_hot, stig_x_one_hot, stig_y_one_hot], axis=1)\n",
        "    # print(\"---> One-hot encoded labels generated.\")\n",
        "    \n",
        "    print(\"===== Preparing TensorFlow Datasets =====\")\n",
        "    \n",
        "    labeled_df = data\n",
        "    datasets = {}\n",
        "    labels = list(config['Labels']['MAPPINGS'].keys())\n",
        "\n",
        "    # Shuffle and Reset Index\n",
        "    print(\"---> Shuffling and resetting index...\")\n",
        "    labeled_df = labeled_df.sample(frac=1, random_state=config['Experiment']['RANDOM_SEED']).reset_index(drop=True)\n",
        "    print(\"---> Data shuffled and index reset.\")\n",
        "    \n",
        "    for label in labels:\n",
        "        \n",
        "        print(f\"---> Preparing datasets for label: {label}\")\n",
        "        datasets[label] = {'train': None, 'valid': None, 'test': None, 'info': {}}\n",
        "        \n",
        "        # Split Data\n",
        "        train_df, temp_df = train_test_split(labeled_df, test_size=1 - config['Model']['TRAIN_SIZE'], random_state=config['Experiment']['RANDOM_SEED'])\n",
        "        val_df, test_df = train_test_split(temp_df, test_size=1 - config['Model']['VAL_SIZE'], random_state=config['Experiment']['RANDOM_SEED'])\n",
        "\n",
        "        # Create TensorFlow Datasets (without one-hot encoded labels)\n",
        "        train_ds = Dataset.from_tensor_slices((train_df['ImageFile'].values, train_df[label].map(config['Labels']['MAPPINGS'][label]).values))\n",
        "        val_ds = Dataset.from_tensor_slices((val_df['ImageFile'].values, val_df[label].map(config['Labels']['MAPPINGS'][label]).values))\n",
        "        test_ds = Dataset.from_tensor_slices((test_df['ImageFile'].values, test_df[label].map(config['Labels']['MAPPINGS'][label]).values))\n",
        "\n",
        "        # one_hot_columns = [col for col in data.columns if label in col]  # Find the corresponding one-hot columns\n",
        "        # # Create TensorFlow Datasets with one-hot encoded labels\n",
        "        # train_ds = Dataset.from_tensor_slices((train_df['ImageFile'].values, train_df[one_hot_columns].values))\n",
        "        # val_ds = Dataset.from_tensor_slices((val_df['ImageFile'].values, val_df[one_hot_columns].values))\n",
        "        # test_ds = Dataset.from_tensor_slices((test_df['ImageFile'].values, test_df[one_hot_columns].values))\n",
        "\n",
        "        # Apply Preprocessing using your preprocessing functions\n",
        "        train_ds, val_ds, test_ds = preprocess_images(train_ds, val_ds, test_ds, config)\n",
        "        \n",
        "        # # Debug/Check Statement\n",
        "        # print(\"---> Debug Check: Verifying the first element of the train_ds after preprocessing\")\n",
        "        # for img, lbl in train_ds.take(1):\n",
        "        #     print(f\"Image shape: {img.shape}, Label: {lbl.numpy()}\")\n",
        "\n",
        "\n",
        "        # Configure for Performance\n",
        "        AUTOTUNE = tf.data.AUTOTUNE\n",
        "        train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "        val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "        test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "        # Store Datasets\n",
        "        datasets[label]['train'] = train_ds\n",
        "        datasets[label]['valid'] = val_ds\n",
        "        datasets[label]['test'] = test_ds\n",
        "\n",
        "        # Compute and Store Class Weights and Info for each split\n",
        "        for split, df in zip(['Training', 'Validation', 'Test'], [train_df, val_df, test_df]):\n",
        "            unique_labels = df[label].unique()\n",
        "            class_weights = compute_class_weight('balanced', classes=unique_labels, y=df[label])\n",
        "            class_weights_dict = dict(zip(unique_labels, class_weights))\n",
        "\n",
        "            datasets[label]['info'][split] = {\n",
        "                'Total': len(df),\n",
        "                'ClassInfo': {cls: {'Count': cnt, 'Weight': class_weights_dict[cls]} for cls, cnt in Counter(df[label]).items()}\n",
        "            }\n",
        "        print(f\"---> Datasets prepared for label: {label}\")\n",
        "\n",
        "    print(\"===== Preprocessing and Dataset Preparation Complete =====\")\n",
        "   \n",
        "\n",
        "    return datasets\n",
        "\n",
        "# Preprocess and prepare datasets\n",
        "datasets = preprocess_and_prepare_tf_datasets(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#  Print in a pretty format\n",
        "def print_datasets_info(datasets: dict) -> None:\n",
        "    \"\"\"Print out datasets info in a pretty format.\"\"\"\n",
        "    for label in datasets:\n",
        "        print(f\"Label: {label}\")\n",
        "        for key in datasets[label]['info'].keys():\n",
        "            print(f\"\\t{key}:\")\n",
        "            for class_label in datasets[label]['info'][key]['ClassInfo'].keys():\n",
        "                print(f\"\\t\\t{class_label}: {datasets[label]['info'][key]['ClassInfo'][class_label]}\")\n",
        "            print(f\"\\t\\tTotal: {datasets[label]['info'][key]['Total']}\")\n",
        "        print()\n",
        "\n",
        "# Usage\n",
        "print_datasets_info(datasets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Class Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        },
        "id": "MzAbLvQFFDZk",
        "outputId": "7c4f3eea-d3a4-49a6-9e9b-fe0b5d1b11a7"
      },
      "outputs": [],
      "source": [
        "from typing import Dict\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def annotate_bars(ax, labels, counts, weights):\n",
        "    \"\"\"Annotate the bars with counts and weights.\"\"\"\n",
        "    for i, (count, weight) in enumerate(zip(counts, weights)):\n",
        "        ax.text(i, count, f\"Count: {count}\\nWeight: {round(weight, 2)}\", ha='center', va='bottom')\n",
        "\n",
        "def plot_single_split(ax, split_data: Dict, label_column: str, split: str, sorted_labels: list) -> None:\n",
        "    \n",
        "    # Sort based on preferred order\n",
        "    counts = [split_data['ClassInfo'].get(label, {'Count': 0})['Count'] for label in sorted_labels]\n",
        "    weights = [split_data['ClassInfo'].get(label, {'Weight': 0})['Weight'] for label in sorted_labels]\n",
        "    \n",
        "    sns.barplot(x=sorted_labels, y=counts, ax=ax, palette=\"coolwarm\")\n",
        "    annotate_bars(ax, sorted_labels, counts, weights)\n",
        "\n",
        "    ax.set_title(f\"{label_column} - {split} (Total: {split_data['Total']})\", fontsize=16)\n",
        "    ax.set_xlabel('Labels', fontsize=14)\n",
        "    ax.set_ylabel('Count', fontsize=14)\n",
        "    ax.tick_params(labelsize=12)\n",
        "\n",
        "def plot_academic_dataset_info(datasets: Dict) -> None:\n",
        "    \"\"\"Enhance the plots for a more academic/scientific look using seaborn.\"\"\"\n",
        "    sns.set(style=\"whitegrid\")\n",
        "\n",
        "    # Define the preferred label order\n",
        "    focus_labels_order = ['SharpFocus', 'SlightlyBlurred', 'HighlyBlurred']\n",
        "    stig_labels_order = ['OptimalStig', 'ModerateStig', 'SevereStig']\n",
        "\n",
        "    for label_column, data in datasets.items():\n",
        "\n",
        "        # Choose the preferred label order based on the label_column\n",
        "        if 'Focus' in label_column:\n",
        "            sorted_labels = focus_labels_order\n",
        "        else:  # For 'StigX' and 'StigY'\n",
        "            sorted_labels = [\n",
        "                f'{label}_X' if 'X' in label_column else f'{label}_Y'\n",
        "                for label in stig_labels_order\n",
        "            ]\n",
        "\n",
        "        fig, axs = plt.subplots(1, 3, figsize=(20, 6))\n",
        "\n",
        "        for i, split in enumerate(['Training', 'Validation', 'Test']):\n",
        "            plot_single_split(axs[i], data['info'][split], label_column, split, sorted_labels)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "# Call the function\n",
        "# Assuming 'datasets' is your prepared dataset dictionary\n",
        "plot_academic_dataset_info(datasets)  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### See Batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np  # Added this line to import numpy\n",
        "import tensorflow as tf  # Make sure tensorflow is imported\n",
        "\n",
        "def visualize_and_show_batch(datasets: dict, rows: int = 3, cols: int = 3) -> None:\n",
        "    \"\"\"Visualize samples from the datasets.\"\"\"\n",
        "    for label_column, dataset_info in datasets.items():\n",
        "        \n",
        "        plt.figure(figsize=(15, 5 * rows))\n",
        "        \n",
        "        # Take only the first rows*cols samples\n",
        "        for idx, (image, label) in enumerate(dataset_info['train'].take(rows * cols)):\n",
        "            row = idx // cols\n",
        "            col = idx % cols\n",
        "            \n",
        "            ax = plt.subplot(rows, cols, row * cols + col + 1)\n",
        "            plt.imshow(image.numpy(), cmap=\"gray\")\n",
        "\n",
        "            # Handle both integer and one-hot encoded labels\n",
        "            if label.dtype == tf.string:\n",
        "                label_str = label.numpy().decode(\"utf-8\")  # Convert bytes to string if it's a string label\n",
        "            else:\n",
        "                label_str = str(np.argmax(label.numpy()))  # Convert one-hot encoded label to integer label\n",
        "            \n",
        "            ax.set_title(f\"{label_column}: {label_str}\", fontsize=10)\n",
        "            \n",
        "            plt.axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# Example usage\n",
        "# Make sure 'datasets' variable is defined before calling this function\n",
        "visualize_and_show_batch(datasets, rows=3, cols=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Visualize Training Batches for Multiple Labels\n",
        "def show_batch(image_batch, label_batch_dict, rows=1, cols=5):\n",
        "    \"\"\"\n",
        "    Display a batch of images in a grid format.\n",
        "\n",
        "    Args:\n",
        "    - image_batch (List[Any]): Batch of images to display.\n",
        "    - label_batch_dict (Dict): Dictionary containing corresponding labels for the images for multiple tasks.\n",
        "    - rows (int, optional): Number of rows in the grid. Defaults to 5.\n",
        "    - cols (int, optional): Number of columns in the grid. Defaults to 5.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(15, 15))\n",
        "\n",
        "    for n in range(rows * cols):\n",
        "        ax = plt.subplot(rows, cols, n + 1)\n",
        "        plt.imshow(image_batch[n])\n",
        "        # label_text = \"\\n\".join([f\"{key}: {val[n]}\" for key, val in label_batch_dict.items()]) Include mpping\n",
        "        label_text = \"\\n\".join([f\"{key}: {val[n]}\" for key, val in label_batch_dict.items()])\n",
        "        plt.title(label_text)  # Convert labels to string just in case\n",
        "        plt.axis('off')\n",
        "\n",
        "# @title Print Batch and Label Shapes and Other Diagnostics\n",
        "def print_diagnostics(image_batch, label_batch_dict):\n",
        "    print(f\"Image batch shape: {image_batch.shape}\")\n",
        "    for label, label_batch in label_batch_dict.items():\n",
        "        print(f\"{label} batch shape: {label_batch.shape}\")\n",
        "\n",
        "# @title Iterate Over Batches for All Labels\n",
        "label_columns = ['Focus_Label', 'StigX_Label', 'StigY_Label'] #might not be needed\n",
        "\n",
        "for label_column in label_columns:\n",
        "    print(f\"------ {label_column} ------\")\n",
        "    for image_batch, label_batch in datasets[label_column]['train'].batch(25).take(1):\n",
        "        label_batch_dict = {label_column: label_batch.numpy()}\n",
        "        print_diagnostics(image_batch.numpy(), label_batch_dict)\n",
        "        show_batch(image_batch.numpy(), label_batch_dict)\n",
        "        break  # Show only one batch per label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6n711h5dEdh"
      },
      "source": [
        "## Define the Callbacks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Defining Models and Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.metrics import (\n",
        "    TruePositives, FalsePositives, TrueNegatives, FalseNegatives,\n",
        "    Precision, Recall, AUC\n",
        ")\n",
        "from typing import List, Tuple\n",
        "from datetime import datetime\n",
        "from tensorflow.keras import callbacks as keras_callbacks\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "import os\n",
        "\n",
        "# Metrics Configuration\n",
        "def get_per_class_metrics(num_classes: int) -> List[str]:\n",
        "    \"\"\"Generate a list of metrics for each class.\"\"\"\n",
        "    metrics = [\"accuracy\"]\n",
        "    \n",
        "    for i in range(num_classes):\n",
        "        metrics.extend([\n",
        "            TruePositives(name=f\"true_positives_class_{i}\"),\n",
        "            FalsePositives(name=f\"false_positives_class_{i}\"),\n",
        "            TrueNegatives(name=f\"true_negatives_class_{i}\"),\n",
        "            FalseNegatives(name=f\"false_negatives_class_{i}\"),\n",
        "            Precision(name=f\"precision_class_{i}\"),\n",
        "            Recall(name=f\"recall_class_{i}\"),\n",
        "            AUC(name=f\"auc_class_{i}\")\n",
        "        ])\n",
        "        \n",
        "    return metrics\n",
        "\n",
        "\n",
        "# Constants and Directories\n",
        "BASE_DIR = os.path.expanduser(\"~\")\n",
        "MODELS_DIR_NAME = \"models\"\n",
        "LOG_DIR_NAME = \"logs/fit\"\n",
        "DEFAULT_INPUT_SHAPE = (config['Model']['IMG_SIZE'], config['Model']['IMG_SIZE'], 3)\n",
        "DEFAULT_NUM_CLASSES = 3\n",
        "\n",
        "\n",
        "# Model Configurations\n",
        "MODEL_CONFIGS = {\n",
        "    'mobilenetv2': {'model_fn': create_mobilenetv2_transfer_model},\n",
        "    'small_xception': {'model_fn': create_small_xception_model},\n",
        "    'basic_cnn': {'model_fn': create_basic_cnn_model},\n",
        "    'inceptionv3': {'model_fn': create_inceptionv3_transfer_model},\n",
        "    'resnet50': {'model_fn': create_resnet50_transfer_model}\n",
        "}\n",
        "\n",
        "# Initialize model configs with default values\n",
        "for config_name in MODEL_CONFIGS:\n",
        "    MODEL_CONFIGS[config_name].setdefault('input_shape', DEFAULT_INPUT_SHAPE)\n",
        "    MODEL_CONFIGS[config_name].setdefault('num_classes', DEFAULT_NUM_CLASSES)\n",
        "\n",
        "\n",
        "# Helper Functions\n",
        "def create_directory(path: str) -> None:\n",
        "    \"\"\"Create directory if it doesn't exist.\"\"\"\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "def generate_log_and_checkpoint_dirs(model_name: str, label_column: str) -> Tuple[str, str]:\n",
        "    \"\"\"Generate directories for logs and checkpoints based on the experiment name.\"\"\"\n",
        "    \n",
        "    # Retrieve experiment name from the config dictionary\n",
        "    experiment_name = config['Experiment']['NAME']\n",
        "    \n",
        "    # Create the model directory path\n",
        "    model_dir = os.path.join(BASE_DIR, MODELS_DIR_NAME, experiment_name, f\"{label_column}_models\", f\"{model_name}_models\")\n",
        "    \n",
        "    # Create the directory if it doesn't exist\n",
        "    create_directory(model_dir)\n",
        "\n",
        "    # Create the log directory path\n",
        "    log_dir = os.path.join(model_dir, LOG_DIR_NAME, f\"{model_name}_{datetime.now().strftime('%Y%m%d-%I%M%S%p')}\")\n",
        "    \n",
        "    # Create the directory if it doesn't exist\n",
        "    create_directory(log_dir)\n",
        "\n",
        "    # Generate the checkpoint file name\n",
        "    checkpoint_filename = f'model-{datetime.now().strftime(\"%Y%m%d-%I%M%S%p\")}-{{epoch:02d}}-loss{{val_loss:.2f}}-acc{{val_accuracy:.2f}}.h5'\n",
        "    checkpoint_path = os.path.join(model_dir, checkpoint_filename)\n",
        "\n",
        "    return log_dir, checkpoint_path\n",
        "\n",
        "\n",
        "\n",
        "# Callbacks\n",
        "def define_callbacks(model_name: str, label_column: str) -> List[keras_callbacks.Callback]:\n",
        "    \"\"\"Define a list of callbacks for model training.\"\"\"\n",
        "    log_dir, checkpoint_path = generate_log_and_checkpoint_dirs(model_name, label_column)\n",
        "\n",
        "    return [\n",
        "        keras_callbacks.ModelCheckpoint(filepath=checkpoint_path, save_best_only=True, monitor='val_loss', mode='min', verbose=1),\n",
        "        keras_callbacks.EarlyStopping(monitor='val_loss', patience=config['Model']['EARLY_STOPPING_PATIENCE']),\n",
        "        keras_callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=config['Model']['REDUCE_LR_PATIENCE'], min_lr=config['Model']['MIN_LR']),\n",
        "        TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "    ]\n",
        "\n",
        "\n",
        "# Model Initialization\n",
        "callbacks = {}\n",
        "models = {}\n",
        "label_columns = config['Labels']['MAPPINGS'].keys()\n",
        "\n",
        "num_classes = len(config['Labels']['MAPPINGS']['Focus_Label'])\n",
        "config['Model']['METRICS'] = get_per_class_metrics(num_classes)\n",
        "\n",
        "# Initialize and compile models\n",
        "for model_name, model_config in MODEL_CONFIGS.items():\n",
        "    model = select_model(model_name, model_config['input_shape'], model_config['num_classes'])\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(config['Model']['LEARNING_RATE']),\n",
        "        loss=config['Model']['LOSS'],\n",
        "        metrics=config['Model']['METRICS']\n",
        "    )\n",
        "\n",
        "    for label_column in label_columns:\n",
        "        callbacks_key = f\"{model_name}_{label_column}\"\n",
        "        callbacks[callbacks_key] = define_callbacks(model_name, label_column)\n",
        "\n",
        "    models[model_name] = model\n",
        "\n",
        "# Display model summaries\n",
        "for model_name, model in models.items():\n",
        "    print(f\"Model: {model_name}\")\n",
        "    model.summary()\n",
        "    print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73pk57YocyyO"
      },
      "source": [
        "## Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmNeDIb0gLml",
        "outputId": "1ec346ed-b7c5-4c67-f37b-c48158ad265d"
      },
      "outputs": [],
      "source": [
        "from typing import List, Dict, Any, Optional\n",
        "from tensorflow.keras import Model, layers\n",
        "import logging\n",
        "import os\n",
        "import pickle\n",
        "import glob\n",
        "import tensorflow as tf\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "\n",
        "\n",
        "# Helper Functions\n",
        "\n",
        "def process_history(history: Any, phase: str, num_classes: Optional[int] = None) -> Dict[str, Any]:\n",
        "    \"\"\"Process training or validation history.\"\"\"\n",
        "    basic_metrics = ['loss', 'accuracy']\n",
        "    class_metrics = ['precision', 'recall', 'auc']\n",
        "    prefix = 'val_' if phase == 'validation' else ''\n",
        "    \n",
        "    processed_metrics = {\n",
        "        metric: history.history.get(f\"{prefix}{metric}\", []) \n",
        "        for metric in basic_metrics\n",
        "    }\n",
        "    \n",
        "    if num_classes:\n",
        "        for metric_base in class_metrics:\n",
        "            for i in range(num_classes):\n",
        "                metric_name = f\"{metric_base}_class_{i}\"\n",
        "                processed_metrics[metric_name] = history.history.get(f\"{prefix}{metric_name}\", [])\n",
        "    \n",
        "    return processed_metrics\n",
        "\n",
        "\n",
        "def update_callback_keys(label_column: str, model_name: str) -> Tuple[str, str, str]:\n",
        "    \"\"\"Update keys for training, validation, and test callbacks.\"\"\"\n",
        "    return f\"{model_name}_{label_column}\", f\"{model_name}_{label_column}_valid\", f\"{model_name}_{label_column}_test\"\n",
        "\n",
        "\n",
        "def train_model(\n",
        "    model: Model, train_ds: Any, valid_ds: Any, config: Dict[str, Any],\n",
        "    train_weights_dict: Dict[int, float], callbacks: Any, initial_epoch: int = 0\n",
        ") -> Any:\n",
        "    \"\"\"Train the model.\"\"\"\n",
        "    try:\n",
        "        batch_size = config['Model']['BATCH_SIZE']\n",
        "        return model.fit(\n",
        "            train_ds.batch(batch_size).cache().prefetch(buffer_size=tf.data.AUTOTUNE),\n",
        "            epochs=config['Model']['EPOCHS'],\n",
        "            initial_epoch=initial_epoch,\n",
        "            validation_data=valid_ds.batch(batch_size).cache().prefetch(buffer_size=tf.data.AUTOTUNE),\n",
        "            class_weight=train_weights_dict,\n",
        "            callbacks=callbacks\n",
        "        )\n",
        "    except KeyError as e:\n",
        "        logging.error(f\"KeyError: {e}. Full config: {config}\")\n",
        "\n",
        "def evaluate_model(model: Model, test_ds: Any, config: Dict[str, Any]) -> Any:\n",
        "    \"\"\"Evaluate the model.\"\"\"\n",
        "    batch_size = config['Model']['BATCH_SIZE']\n",
        "    return model.evaluate(test_ds.batch(batch_size))\n",
        "\n",
        "def get_latest_checkpoint(model_dirs: List[str]) -> Optional[str]:\n",
        "    \"\"\"\n",
        "    Return the latest checkpoint file from the given model directories.\n",
        "    \n",
        "    Parameters:\n",
        "    - model_dirs (List[str]): A list of directories where the model checkpoint files are stored.\n",
        "    \n",
        "    Returns:\n",
        "    - Optional[str]: The path of the latest checkpoint file, or None if no checkpoint files are found.\n",
        "    \"\"\"\n",
        "    for model_dir in model_dirs:\n",
        "        checkpoint_pattern = os.path.join(model_dir, '*.h5')\n",
        "        list_of_files = glob.glob(checkpoint_pattern)\n",
        "        \n",
        "        if not list_of_files:\n",
        "            print(f\"No checkpoint files found in {model_dir}.\")\n",
        "            continue  # Skip to the next directory\n",
        "        \n",
        "        latest_checkpoint = max(list_of_files, key=os.path.getctime)\n",
        "        print(f\"Found {len(list_of_files)} checkpoint files in {model_dir}.\")\n",
        "        print(f\"Resuming from the latest checkpoint: {latest_checkpoint}.\")\n",
        "        \n",
        "        return latest_checkpoint\n",
        "    \n",
        "    print(\"No checkpoints found in any of the specified directories.\")\n",
        "    return None\n",
        "\n",
        "def load_or_adapt_model(initialized_model, latest_checkpoint, expected_output_units):\n",
        "    try:\n",
        "        # Try to load the full model\n",
        "        model = load_model(latest_checkpoint)\n",
        "        last_layer_units = model.layers[-1].units\n",
        "        if last_layer_units == expected_output_units:\n",
        "            return model, True\n",
        "        else:\n",
        "            # Remove last layer and add a new one\n",
        "            new_output = layers.Dense(expected_output_units, activation='softmax')(model.layers[-2].output)\n",
        "            model = Model(inputs=model.inputs, outputs=new_output)\n",
        "            return model, False\n",
        "    except Exception as e:\n",
        "        print(f\"Exception: {e}\")\n",
        "        print(\"Could not load the full model. Using initialized model and loading its weights.\")\n",
        "        \n",
        "        # Create a new model based on the initialized_model but with expected_output_units\n",
        "        new_output = layers.Dense(expected_output_units, activation='softmax')(initialized_model.layers[-2].output)\n",
        "        initialized_model = Model(inputs=initialized_model.inputs, outputs=new_output)\n",
        "        \n",
        "        # Try to load the weights\n",
        "        binary_model = load_model(latest_checkpoint)\n",
        "        binary_model = Model(inputs=binary_model.inputs, outputs=binary_model.layers[-2].output)\n",
        "        \n",
        "        initialized_model.set_weights(binary_model.get_weights())\n",
        "        return initialized_model, False\n",
        "\n",
        "def defaultdict_to_dict(d):\n",
        "    if isinstance(d, defaultdict):\n",
        "        d = {k: defaultdict_to_dict(v) for k, v in d.items()}\n",
        "    return dict(d)\n",
        "\n",
        "\n",
        "def train_and_evaluate_all_models(\n",
        "    model_names: List[str],\n",
        "    label_columns: List[str],\n",
        "    datasets: Dict[str, Any],\n",
        "    models: Dict[str, Any],\n",
        "    config: Dict[str, Any],\n",
        "    callbacks: Dict[str, Any],\n",
        "    results: Optional[Dict] = None\n",
        "):\n",
        "    \"\"\"Train and evaluate multiple machine learning models.\"\"\"\n",
        "    \n",
        "    # Initialize results dictionary if not provided\n",
        "    if results is None:\n",
        "        results = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(dict))))\n",
        "\n",
        "    initial_epoch = 0\n",
        "    for label_column in label_columns:\n",
        "        # Fetch class weights from the datasets dictionary\n",
        "        train_weights = datasets[label_column]['info']['Training']['ClassInfo']\n",
        "\n",
        "        for model_name in model_names:\n",
        "            model = models[model_name]\n",
        "            train_ds = datasets[label_column]['train']\n",
        "            valid_ds = datasets[label_column]['valid']\n",
        "            test_ds = datasets[label_column]['test']\n",
        "\n",
        "            # Convert scalar labels to one-hot encoding\n",
        "            train_ds = train_ds.map(lambda x, y: (x, tf.one_hot(y, depth=3)))\n",
        "            valid_ds = valid_ds.map(lambda x, y: (x, tf.one_hot(y, depth=3)))\n",
        "            test_ds = test_ds.map(lambda x, y: (x, tf.one_hot(y, depth=3)))\n",
        "\n",
        "            # Define the directories to look for checkpoints\n",
        "            base_model_dir = os.path.join(BASE_DIR, MODELS_DIR_NAME)\n",
        "\n",
        "            # List of experiment names\n",
        "            experiment_names = [\"default_experiment\", \"binary_classification_v1\"]\n",
        "\n",
        "            # Generate the full paths for each experiment\n",
        "            model_dirs = [\n",
        "                os.path.join(base_model_dir, exp_name, f\"{label_column}_models\", f\"{model_name}_models\")\n",
        "                for exp_name in experiment_names\n",
        "            ]\n",
        "\n",
        "\n",
        "            # Get the latest checkpoint\n",
        "            # latest_checkpoint = get_latest_checkpoint(model_dirs)\n",
        "\n",
        "            # Load or initialize results based on the presence of checkpoints\n",
        "            # if latest_checkpoint:\n",
        "            #     print(f\"Resuming from {latest_checkpoint}\")\n",
        "                \n",
        "            #     # Try to load the results corresponding to this checkpoint\n",
        "            #     results_pickle = latest_checkpoint.replace('.h5', '_results.pkl')\n",
        "            #     if os.path.exists(results_pickle):\n",
        "            #         with open(results_pickle, 'rb') as f:\n",
        "            #             results = pickle.load(f)\n",
        "            #         print(\"Successfully loaded previous results.\")\n",
        "            #     else:\n",
        "            #         print(\"No previous results found, initializing new results dictionary.\")\n",
        "            #         results = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(dict))))\n",
        "                \n",
        "            #     # Load the model and other state from the checkpoint\n",
        "            #     initialized_model = models[model_name]\n",
        "            #     model, full_model_loaded = load_or_adapt_model(initialized_model, latest_checkpoint, expected_output_units=3)\n",
        "                \n",
        "            #     if not full_model_loaded:\n",
        "            #         # Optionally recompile the model if only the weights were loaded\n",
        "            #         model.compile(\n",
        "            #             optimizer=keras.optimizers.Adam(config['Model']['LEARNING_RATE']),\n",
        "            #             loss=config['Model']['LOSS'],\n",
        "            #             metrics=config['METRICS']\n",
        "            #         )\n",
        "                \n",
        "            #     filename = os.path.basename(latest_checkpoint)\n",
        "            #     # initial_epoch = int(filename.split(\"-\")[3])\n",
        "            # else:\n",
        "            #     print(\"No checkpoint found, starting fresh.\")\n",
        "            #     results = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(dict))))\n",
        "            #     initial_epoch = 0  # Reset to the first epoch\n",
        "\n",
        "            print(f\"Training {model_name} on train dataset for {label_column}...\")\n",
        "\n",
        "            # Convert class weights to a dictionary with numerical labels\n",
        "            train_weights_dict = {config['Labels']['MAPPINGS'][label_column][key]: value['Weight'] for key, value in train_weights.items()}\n",
        "            train_cb_key, valid_cb_key, test_cb_key = update_callback_keys(label_column, model_name)\n",
        "\n",
        "\n",
        "\n",
        "            try:\n",
        "                history = train_model(\n",
        "                    model, \n",
        "                    train_ds, \n",
        "                    valid_ds, \n",
        "                    config, \n",
        "                    train_weights_dict, \n",
        "                    callbacks[train_cb_key], \n",
        "                    initial_epoch=initial_epoch\n",
        "                )\n",
        "                # New way\n",
        "                results[model_name][label_column]['training'] = process_history(history, 'training')\n",
        "                results[model_name][label_column]['validation'] = process_history(history, 'validation')\n",
        "            except KeyError as e:\n",
        "                logging.error(f\"KeyError: {e}. Callback or class weight for {model_name} and {label_column} not found.\")\n",
        "                continue\n",
        "\n",
        "            # Print training summary\n",
        "            print(f\"Training summary for {model_name} - {label_column}: {results[model_name][label_column]['training']}\")\n",
        "\n",
        "            evaluation_results = evaluate_model(model, test_ds, config)\n",
        "            print(f'{model_name} on train - Test Loss: {evaluation_results[0]:.4f}, Test Accuracy: {evaluation_results[1]*100:.2f}%')\n",
        "\n",
        "    # Save the results dictionary to a pickle file\n",
        "    results_dict = defaultdict_to_dict(results)\n",
        "    results_pickle_path = f'training_results_{datetime.now().strftime(\"%Y%m%d%H%M%S\")}.pkl'\n",
        "    with open(results_pickle_path, 'wb') as f:\n",
        "        pickle.dump(results_dict, f)\n",
        "    print(f\"Results saved to {results_pickle_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title Main Training Loop\n",
        "results = None  # Or initialize it with some existing data if you have any.\n",
        "\n",
        "# Specify model names and label columns\n",
        "model_names = [\"mobilenetv2\", \"small_xception\", \"basic_cnn\", \"inceptionv3\", \"resnet50\"]\n",
        "label_columns = list(datasets.keys()) \n",
        "\n",
        "train_and_evaluate_all_models(\n",
        "    model_names,\n",
        "    label_columns,\n",
        "    datasets,\n",
        "    models,\n",
        "    config,\n",
        "    callbacks,\n",
        "    results=results\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Function to convert defaultdict to regular dict\n",
        "# def defaultdict_to_dict(d):\n",
        "#     if isinstance(d, defaultdict):\n",
        "#         d = {k: defaultdict_to_dict(v) for k, v in d.items()}\n",
        "#     return dict(d)\n",
        "\n",
        "# # Convert results to regular dictionary\n",
        "# results_dict = defaultdict_to_dict(results)\n",
        "\n",
        "# # Save the results with a unique timestamp\n",
        "# with open(f'training_results_{datetime.now().strftime(\"%Y%m%d%H%M%S\")}.pkl', 'wb') as f:\n",
        "#     pickle.dump(results_dict, f)\n",
        "\n",
        "# This saving is not necessary if you use the new training loop above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# # Load the pickled results dictionary\n",
        "# with open(\"training_results_20230905103528.pkl\", 'rb') as f:\n",
        "#     loaded_results = pickle.load(f)\n",
        "\n",
        "# # Initialize a new dictionary to hold the restructured results\n",
        "# new_results = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(dict))))\n",
        "\n",
        "# # Loop through the existing results dictionary to populate the new one\n",
        "# for model_name, model_data in loaded_results.items():\n",
        "#     for dataset_type, dataset_data in model_data.items():  # Loop over 'train' (and any other keys)\n",
        "#         for label_column, label_data in dataset_data.items():\n",
        "#             for data_type, metrics in label_data.items():  # Loop over 'training' and 'validation'\n",
        "#                 new_results[model_name][label_column][data_type] = metrics\n",
        "\n",
        "# # Convert the new_results defaultdict to a regular dictionary\n",
        "# new_results_dict = defaultdict_to_dict(new_results)\n",
        "\n",
        "# # Save the new_results dictionary to a pickle file with a unique timestamp\n",
        "# with open(f'training_results_restructured_{datetime.now().strftime(\"%Y%m%d%H%M%S\")}.pkl', 'wb') as f:\n",
        "#     pickle.dump(new_results_dict, f)\n",
        "\n",
        "# # This restructuring is not necessary if you use the new training loop above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Search for all pickled files in the current directory\n",
        "pickled_files = glob.glob(\"training_results_*.pkl\")\n",
        "\n",
        "# Print out the list of found files along with their sizes\n",
        "print(\"Found pickled files:\")\n",
        "for i, file in enumerate(pickled_files):\n",
        "    file_size = os.path.getsize(file) // 1024  # File size in KB\n",
        "    print(f\"{i+1}. {file} (Size: {file_size} KB)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Loading Pickled Files\n",
        "\n",
        "def load_results(filename):\n",
        "    \"\"\"Load results from a pickle file.\"\"\"\n",
        "    try:\n",
        "        with open(filename, 'rb') as f:\n",
        "            return pickle.load(f)\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to load {filename}: {e}\")\n",
        "        return None\n",
        "\n",
        "from pprint import pprint\n",
        "def pretty_print_structure(d, indent=0):\n",
        "    \"\"\"Pretty print the structure of dictionary keys.\"\"\"\n",
        "    for key, value in d.items():\n",
        "        print('  ' * indent + str(key))\n",
        "        if isinstance(value, dict):\n",
        "            pretty_print_structure(value, indent+1)\n",
        "\n",
        "filename = 'training_results_restructured_20230905111356.pkl'\n",
        "loaded_results = load_results(filename)\n",
        "# pretty_print_structure(loaded_results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ZVDLgh__YL7I"
      },
      "outputs": [],
      "source": [
        "# Creating Plots for Multiple Labels\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "from collections import defaultdict\n",
        "from matplotlib.legend_handler import HandlerTuple\n",
        "\n",
        "# --- Helper Functions and Classes ---\n",
        "\n",
        "def create_save_directory(dir_name):\n",
        "    \"\"\"Create save directory if it doesn't exist.\"\"\"\n",
        "    if not os.path.exists(dir_name):\n",
        "        os.makedirs(dir_name)\n",
        "\n",
        "class HandlerTupleVertical(HandlerTuple):\n",
        "    \"\"\"Custom handler for vertical alignment of legend lines.\"\"\"\n",
        "    def create_artists(self, legend, orig_handle,\n",
        "                       xdescent, ydescent, width, height, fontsize, trans):\n",
        "        numlines = len(orig_handle)\n",
        "        handler_map = legend.get_legend_handler_map()\n",
        "        height_y = (height / numlines)\n",
        "        leglines = []\n",
        "        for i, handle in enumerate(orig_handle):\n",
        "            handler = legend.get_legend_handler(handler_map, handle)\n",
        "            legline = handler.create_artists(legend, handle,\n",
        "                                             xdescent,\n",
        "                                             (2*i + 1)*height_y,\n",
        "                                             width,\n",
        "                                             2*height,\n",
        "                                             fontsize, trans)\n",
        "            leglines.extend(legline)\n",
        "        return leglines\n",
        "\n",
        "\n",
        "# --- Plotting Setup ---\n",
        "\n",
        "# Set Seaborn style\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "# Generate a color palette\n",
        "palette = sns.color_palette(\"husl\", len(model_names))\n",
        "color_dict = {model: palette[i] for i, model in enumerate(model_names)}\n",
        "\n",
        "# Mapping from technical to readable names\n",
        "model_name_mapping = {\n",
        "    \"mobilenetv2\": \"MobileNet V2\",\n",
        "    \"small_xception\": \"Small Xception\",\n",
        "    \"basic_cnn\": \"Basic CNN\",\n",
        "    \"inceptionv3\": \"Inception V3\",\n",
        "    \"resnet50\": \"ResNet-50\"\n",
        "}\n",
        "\n",
        "metric_name_mapping = {\n",
        "    'loss': 'Loss',\n",
        "    'accuracy': 'Accuracy',\n",
        "    'precision': 'Precision',\n",
        "    'recall': 'Recall',\n",
        "    'auc_roc': 'AUC-ROC',\n",
        "    'auc_pr': 'AUC-PR'\n",
        "}\n",
        "\n",
        "\n",
        "# --- Data Preprocessing ---\n",
        "\n",
        "# Load your restructured results\n",
        "results = loaded_results\n",
        "\n",
        "# Get unique datasets (Labels in your case)\n",
        "sample_model = next(iter(results.keys()))\n",
        "unique_datasets = list(results[sample_model].keys())\n",
        "\n",
        "# Initialize dictionaries to store max epochs, max losses, and min metrics per label\n",
        "max_epochs_per_label = {label: 0 for label in unique_datasets}\n",
        "max_loss_per_label = {label: 0 for label in unique_datasets}\n",
        "min_metrics_per_label = {label: {metric: float('inf') for metric in metrics} for label in unique_datasets}\n",
        "\n",
        "# Calculate max epochs, max losses, and min metrics per label\n",
        "for model in results:\n",
        "    for dataset in results[model]:\n",
        "        for train_valid in results[model][dataset]:\n",
        "            for metric in results[model][dataset][train_valid]:\n",
        "                max_epochs_per_label[dataset] = max(max_epochs_per_label[dataset], len(results[model][dataset][train_valid][metric]))\n",
        "                if metric == 'loss':\n",
        "                    max_loss_per_label[dataset] = max(max_loss_per_label[dataset], max(results[model][dataset][train_valid][metric]))\n",
        "                else:\n",
        "                    min_metrics_per_label[dataset][metric] = min(min_metrics_per_label[dataset][metric], min(results[model][dataset][train_valid][metric]))\n",
        "\n",
        "\n",
        "# --- Plotting ---\n",
        "\n",
        "for metric in metrics:\n",
        "    ylabel = metric_name_mapping[metric]\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    plt.suptitle(f'{ylabel} vs Epoch', fontsize=16, y=1.1)\n",
        "\n",
        "    for idx, dataset_name in enumerate(unique_datasets):\n",
        "        plt.subplot(1, len(unique_datasets), idx+1)\n",
        "        \n",
        "        # Plot data\n",
        "        for model_name in model_names:\n",
        "            if dataset_name not in results[model_name]:\n",
        "                continue\n",
        "            epochs = range(1, len(results[model_name][dataset_name]['training'][metric]) + 1)\n",
        "            plt.plot(epochs, results[model_name][dataset_name]['training'][metric], '--', color=color_dict[model_name], label=f'{model_name_mapping[model_name]} Training')\n",
        "            plt.plot(epochs, results[model_name][dataset_name]['validation'][metric], '-', color=color_dict[model_name], label=f'{model_name_mapping[model_name]} Validation')\n",
        "\n",
        "        # Styling\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel(ylabel)\n",
        "        plt.title(dataset_name)\n",
        "        plt.xlim(1, max_epochs_per_label[dataset_name])\n",
        "        if metric == 'loss':\n",
        "            plt.ylim(0, max_loss_per_label[dataset_name])\n",
        "        else:\n",
        "            plt.ylim(min_metrics_per_label[dataset_name][metric], 1)\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Create legend\n",
        "        if idx == len(unique_datasets) - 1:\n",
        "            handles, labels = plt.gca().get_legend_handles_labels()\n",
        "            new_handles = [(handles[i], handles[i + 1]) for i in range(0, len(handles), 2)]\n",
        "            plt.legend(new_handles, labels[::2], handler_map={tuple: HandlerTupleVertical()}, loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "\n",
        "\n",
        "    # Save plots\n",
        "    create_save_directory(os.path.expanduser('~\\label_plots'))\n",
        "    save_path = os.path.join(os.path.expanduser('~\\label_plots'), f\"{ylabel}_vs_Epoch.png\")\n",
        "    plt.savefig(save_path, bbox_inches='tight')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creating Plots for Multiple Models\n",
        "\n",
        "# Initialize a nested dictionary to store max epochs per label and model\n",
        "max_epochs_per_model = {label: {model_name: 0 for model_name in model_names} for label in unique_datasets}\n",
        "\n",
        "# Calculate max epochs per label and model\n",
        "for model_name in model_names:\n",
        "    for dataset_name in unique_datasets:\n",
        "        if dataset_name in results[model_name]:\n",
        "            for train_valid in results[model_name][dataset_name]:\n",
        "                for metric in results[model_name][dataset_name][train_valid]:\n",
        "                    max_epochs_per_model[dataset_name][model_name] = max(\n",
        "                        max_epochs_per_model[dataset_name][model_name],\n",
        "                        len(results[model_name][dataset_name][train_valid][metric])\n",
        "                    )\n",
        "\n",
        "# Initialize a nested dictionary to store min metrics per label and model\n",
        "min_metrics_per_model = {label: {model_name: {metric: float('inf') for metric in metrics} for model_name in model_names} for label in unique_datasets}\n",
        "\n",
        "# Calculate min metrics per label and model\n",
        "for model_name in model_names:\n",
        "    for dataset_name in unique_datasets:\n",
        "        if dataset_name in results[model_name]:\n",
        "            for train_valid in results[model_name][dataset_name]:\n",
        "                for metric in results[model_name][dataset_name][train_valid]:\n",
        "                    min_metrics_per_model[dataset_name][model_name][metric] = min(\n",
        "                        min_metrics_per_model[dataset_name][model_name][metric],\n",
        "                        min(results[model_name][dataset_name][train_valid][metric])\n",
        "                    )\n",
        "# --- Plotting ---\n",
        "\n",
        "# Improve coloring using a palette for each dataset\n",
        "palette = sns.color_palette(\"husl\", len(unique_datasets))\n",
        "\n",
        "for metric in metrics:\n",
        "    ylabel = metric_name_mapping[metric]\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    plt.suptitle(f'{ylabel} vs Epoch', fontsize=16, y=1.1)\n",
        "\n",
        "    for idx, model_name in enumerate(model_names):\n",
        "        plt.subplot(1, len(model_names), idx+1)\n",
        "\n",
        "        # Plot data\n",
        "        for i, dataset_name in enumerate(unique_datasets):\n",
        "            if dataset_name not in results[model_name]:\n",
        "                continue\n",
        "            epochs = range(1, len(results[model_name][dataset_name]['training'][metric]) + 1)\n",
        "            color = palette[i]  # Use a unique color for each dataset\n",
        "            plt.plot(epochs, results[model_name][dataset_name]['training'][metric], '--', color=color, label=f'{dataset_name} Training')\n",
        "            plt.plot(epochs, results[model_name][dataset_name]['validation'][metric], '-', color=color, label=f'{dataset_name} Validation')\n",
        "\n",
        "\n",
        "\n",
        "        # Styling\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel(ylabel)\n",
        "        plt.title(model_name_mapping[model_name])\n",
        "        plt.xlim(1, max(max_epochs_per_model[dataset_name][model_name] for dataset_name in unique_datasets))  # Use the maximum epoch range across all datasets and models\n",
        "        \n",
        "        if metric == 'loss':\n",
        "            plt.ylim(0, max(max_loss_per_label.values()))  # Use the maximum loss range across all datasets\n",
        "        else:\n",
        "            # Set y-axis limit based on the minimum metric value for the specific model\n",
        "            plt.ylim(min(min_metrics_per_model[dataset_name][model_name][metric] for dataset_name in unique_datasets), 1)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "\n",
        "\n",
        "\n",
        "        # Create legend\n",
        "        if idx == len(model_names) - 1:\n",
        "            handles, labels = plt.gca().get_legend_handles_labels()\n",
        "            new_handles = [(handles[i], handles[i + 1]) for i in range(0, len(handles), 2)]\n",
        "            plt.legend(new_handles, labels[::2], handler_map={tuple: HandlerTupleVertical()}, loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "        \n",
        "    # Save plots\n",
        "    create_save_directory(os.path.expanduser('~\\model_plots'))\n",
        "    save_path = os.path.join(os.path.expanduser('~\\model_plots'), f\"{ylabel}_vs_Epoch.png\")\n",
        "    plt.savefig(save_path, bbox_inches='tight')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77GQ1NWOAWBq"
      },
      "source": [
        "## Evaluation Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDWUpbDBbxzk"
      },
      "outputs": [],
      "source": [
        "# Bar Charts of Best Models per Label\n",
        "# Directory Configuration dictionary\n",
        "dir_config = {\n",
        "    'BASE_DIR': \"C:/Users/User/models\",\n",
        "    'LABELS': ['focus', 'stigx', 'stigy'],\n",
        "    'LABEL_DIR_SUFFIX': \"_Label_models\",\n",
        "    'MODEL_DIR_SUFFIX': \"_models\",\n",
        "}\n",
        "\n",
        "# def construct_model_dir(base_dir, label, model_name, label_dir_suffix, model_dir_suffix):\n",
        "#     return os.path.join(base_dir, f\"{label.capitalize()}{label_dir_suffix}\", f\"{model_name}{model_dir_suffix}\")\n",
        "\n",
        "def construct_model_dir(base_dir, label, model_name, label_dir_suffix, model_dir_suffix):\n",
        "    experiment_name = config.get('EXPERIMENT_NAME', 'default_experiment')  # Get experiment name from config\n",
        "    return os.path.join(base_dir, experiment_name, f\"{label.capitalize()}{label_dir_suffix}\", f\"{model_name}{model_dir_suffix}\")\n",
        "\n",
        "def select_best_model_for_name(model_name, dataset_name, models_dir):\n",
        "    best_accuracy = 0.0\n",
        "    best_model_path = None\n",
        "\n",
        "    # Get the list of saved models for the current model_name\n",
        "    # Instead of filtering by the dataset and model name, we simply check if it starts with \"model-\"\n",
        "    saved_models = [file for file in os.listdir(models_dir) if file.startswith(\"model-\")]\n",
        "\n",
        "    # Check if there are saved models for the current model_name\n",
        "    if not saved_models:\n",
        "        print(f\"No saved models found for {model_name} in dataset {dataset_name}.\")\n",
        "        return None\n",
        "\n",
        "    # Sort the models based on the validation accuracy in the filename\n",
        "    try:\n",
        "        saved_models.sort(key=lambda x: float(x.split('-acc')[-1][:-3]))\n",
        "    except ValueError:\n",
        "        print(f\"Error parsing accuracy from filename for {model_name} in dataset {dataset_name}.\")\n",
        "        return None\n",
        "\n",
        "    # Select the model with the highest validation accuracy\n",
        "    best_model_for_current_name = saved_models[-1]\n",
        "    best_model_path = os.path.join(models_dir, best_model_for_current_name)\n",
        "    best_accuracy_for_current_name = float(best_model_for_current_name.split('-acc')[-1][:-3])\n",
        "\n",
        "    print(f\"Best accuracy for {model_name} in dataset {dataset_name}: {best_accuracy_for_current_name:.4f}\")\n",
        "    return best_model_path\n",
        "\n",
        "\n",
        "best_models = {}\n",
        "\n",
        "for label in dir_config['LABELS']:\n",
        "    for model_name in MODEL_CONFIGS.keys():  # Assuming MODEL_CONFIGS is defined elsewhere\n",
        "        models_dir = construct_model_dir(\n",
        "            dir_config['BASE_DIR'], label, model_name, \n",
        "            dir_config['LABEL_DIR_SUFFIX'], dir_config['MODEL_DIR_SUFFIX']\n",
        "        )\n",
        "        best_model_path = select_best_model_for_name(model_name, label, models_dir)\n",
        "\n",
        "        if best_model_path:\n",
        "            best_model = load_model(best_model_path)\n",
        "            best_models[f\"{model_name}_{label}\"] = best_model\n",
        "\n",
        "\n",
        "# Now you have the best models for each model name and dataset in the best_models dictionary\n",
        "# Mapping from technical to readable dataset (label) names\n",
        "dataset_name_mapping = {\n",
        "    \"focus\": \"Focus\",\n",
        "    \"stigx\": \"Astigmatism (X)\",\n",
        "    \"stigy\": \"Astigmatism (Y)\"\n",
        "}\n",
        "\n",
        "# Using 'model_name_mapping' to map technical model names to readable ones\n",
        "# Using 'dataset_name_mapping' to map technical dataset names to readable ones (which you called Labels)\n",
        "data = []\n",
        "for dataset, model_data in best_models.items():\n",
        "    data.extend(\n",
        "        [model_name_mapping.get(model, model), dataset_name_mapping.get(dataset, dataset), accuracy] \n",
        "        for model, accuracy in model_data.items()\n",
        "    )\n",
        "df = pd.DataFrame(data, columns=['Model', 'Labels', 'Accuracy'])\n",
        "\n",
        "# Plot with Models on the X-axis using academic-style Seaborn settings\n",
        "sns.set(style=\"whitegrid\", font_scale=1.2, rc={\"lines.linewidth\": 2.5})\n",
        "plt.figure(figsize=(12, 8))\n",
        "palette = sns.color_palette(\"coolwarm_r\", n_colors=len(dataset_name_mapping))\n",
        "ax = sns.barplot(x='Model', y='Accuracy', hue='Labels', data=df, palette=palette, edgecolor=\".2\")\n",
        "ax.set_title('Top Accuracy of Models on Different Labels', fontweight='bold', fontsize=18)\n",
        "ax.set_xlabel('Model Names', fontweight='bold', fontsize=16)\n",
        "ax.set_ylabel('Accuracy', fontweight='bold', fontsize=16)\n",
        "plt.xticks(fontsize=14)\n",
        "plt.yticks(fontsize=14)\n",
        "plt.legend(title='Labels', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plot with Labels on the X-axis using academic-style Seaborn settings\n",
        "sns.set(style=\"whitegrid\", font_scale=1.2, rc={\"lines.linewidth\": 2.5})\n",
        "plt.figure(figsize=(12, 8))\n",
        "ax = sns.barplot(x='Labels', y='Accuracy', hue='Model', data=df, palette='coolwarm', edgecolor=\".2\")\n",
        "ax.set_title('Top Accuracy of Different Labels on Models', fontweight='bold', fontsize=18)\n",
        "ax.set_xlabel('Label Names', fontweight='bold', fontsize=16)\n",
        "ax.set_ylabel('Accuracy', fontweight='bold', fontsize=16)\n",
        "plt.xticks(fontsize=14)\n",
        "plt.yticks(fontsize=14)\n",
        "plt.legend(title='Model', bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, average\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "# Assuming you have a dictionary called best_models containing your best models\n",
        "# best_models = {\"model1_label1\": model1, \"model2_label1\": model2, ...}\n",
        "\n",
        "# Assuming you have loaded your test data into X_test and y_test\n",
        "# X_test, y_test = load_your_test_data()\n",
        "\n",
        "# Create an ensemble model\n",
        "def create_ensemble(models, model_input):\n",
        "    outputs = [model(model_input) for model in models.values()]\n",
        "    avg = average(outputs)\n",
        "    model = Model(inputs=model_input, outputs=avg, name='ensemble')\n",
        "    return model\n",
        "\n",
        "# Assuming all your models have the same input shape\n",
        "model_input_shape = list(best_models.values())[0].input_shape[1:]  # e.g., (224, 224, 3)\n",
        "\n",
        "# Create ensemble model\n",
        "model_input = Input(shape=model_input_shape)\n",
        "ensemble_model = create_ensemble(best_models, model_input)\n",
        "\n",
        "# Compile the ensemble model\n",
        "ensemble_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Evaluate the ensemble model\n",
        "# Retrieve test datasets from your datasets dictionary\n",
        "test_datasets = {label: datasets[label]['test'] for label in datasets}\n",
        "\n",
        "# Assuming you have your ensemble model created and compiled as ensemble_model\n",
        "# ensemble_model = ...\n",
        "\n",
        "# Evaluate the ensemble model on each test dataset\n",
        "ensemble_evaluations = {}\n",
        "\n",
        "for label, test_ds in test_datasets.items():\n",
        "    print(f\"Evaluating ensemble model on test dataset for label: {label}\")\n",
        "    \n",
        "    # Assuming the test dataset yields batches of images and integer labels, we convert integer labels to one-hot encoding\n",
        "    test_ds_one_hot = test_ds.map(lambda x, y: (x, tf.one_hot(y, depth=num_classes)))  # Replace num_classes with the number of classes for each label\n",
        "    \n",
        "    evaluation = ensemble_model.evaluate(test_ds_one_hot)\n",
        "    ensemble_evaluations[label] = {\n",
        "        'Loss': evaluation[0],\n",
        "        'Accuracy': evaluation[1]\n",
        "    }\n",
        "    print(f\"Ensemble Model - Loss for {label}: {evaluation[0]:.4f}, Accuracy: {evaluation[1]*100:.2f}%\")\n",
        "\n",
        "print(\"All evaluations done.\")\n",
        "\n",
        "# Dictionary to store the evaluations for individual models\n",
        "individual_evaluations = {}\n",
        "\n",
        "# Evaluate individual models on each test dataset\n",
        "for model_name, model in best_models.items():\n",
        "    label = model_name.split(\"_\")[-1]  # Assuming the model names are in the format \"modelX_labelY\"\n",
        "    test_ds = test_datasets[label]\n",
        "    \n",
        "    # Convert integer labels to one-hot encoding\n",
        "    test_ds_one_hot = test_ds.map(lambda x, y: (x, tf.one_hot(y, depth=num_classes)))  # Replace num_classes with the number of classes for each label\n",
        "    \n",
        "    print(f\"Evaluating individual model {model_name} on test dataset for label: {label}\")\n",
        "    \n",
        "    evaluation = model.evaluate(test_ds_one_hot)\n",
        "    individual_evaluations[model_name] = {\n",
        "        'Loss': evaluation[0],\n",
        "        'Accuracy': evaluation[1]\n",
        "    }\n",
        "    \n",
        "    print(f\"Individual Model ({model_name}) - Loss for {label}: {evaluation[0]:.4f}, Accuracy: {evaluation[1]*100:.2f}%\")\n",
        "\n",
        "# Compare with ensemble model\n",
        "for label, ensemble_eval in ensemble_evaluations.items():\n",
        "    print(f\"\\n=== Comparison for Label: {label} ===\")\n",
        "    print(f\"Ensemble Model - Loss: {ensemble_eval['Loss']:.4f}, Accuracy: {ensemble_eval['Accuracy']*100:.2f}%\")\n",
        "    \n",
        "    for model_name, individual_eval in individual_evaluations.items():\n",
        "        if label in model_name:  # Check if the model corresponds to the current label\n",
        "            print(f\"Individual Model ({model_name}) - Loss: {individual_eval['Loss']:.4f}, Accuracy: {individual_eval['Accuracy']*100:.2f}%\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Investigating the 'datasets' variable\n",
        "# def investigate_datasets(datasets):\n",
        "#     if not isinstance(datasets, dict):\n",
        "#         print(f\"The 'datasets' variable is not a dictionary. It is of type {type(datasets)}.\")\n",
        "#         return\n",
        "\n",
        "#     print(\"Investigating the 'datasets' dictionary:\")\n",
        "    \n",
        "#     # Print the keys at the root level of the dictionary\n",
        "#     root_keys = list(datasets.keys())\n",
        "#     print(f\"Root level keys: {root_keys}\")\n",
        "\n",
        "#     # Investigate each key\n",
        "#     for key in root_keys:\n",
        "#         print(f\"\\nInspecting key: {key}\")\n",
        "\n",
        "#         # If the value for this key is also a dictionary, print its keys\n",
        "#         if isinstance(datasets[key], dict):\n",
        "#             sub_keys = list(datasets[key].keys())\n",
        "#             print(f\"  It's a dictionary with keys: {sub_keys}\")\n",
        "            \n",
        "#             # Optionally, show the type of data for the first few items\n",
        "#             for sub_key in sub_keys[:3]:\n",
        "#                 sample_data = datasets[key][sub_key]\n",
        "#                 print(f\"    Type of data for sub_key '{sub_key}': {type(sample_data)}\")\n",
        "                \n",
        "#                 # Deeper investigation if it's another dictionary\n",
        "#                 if isinstance(sample_data, dict):\n",
        "#                     deeper_keys = list(sample_data.keys())\n",
        "#                     print(f\"      Deeper keys in '{sub_key}': {deeper_keys}\")\n",
        "#                     for deeper_key in deeper_keys[:3]:\n",
        "#                         print(f\"        Type of data for deeper_key '{deeper_key}': {type(sample_data[deeper_key])}\")\n",
        "\n",
        "#         # If it's not a dictionary, just print the type of the value\n",
        "#         else:\n",
        "#             print(f\"  Type of data: {type(datasets[key])}\")\n",
        "\n",
        "# # Call the function to investigate the 'datasets' variable\n",
        "# investigate_datasets(datasets)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CeOO6uK0M_oL"
      },
      "outputs": [],
      "source": [
        "from typing import Dict, List, Any\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "class PredictionPlotter:\n",
        "    def __init__(self, class_names_map: Dict[str, List[str]]):\n",
        "        self.class_names_map = class_names_map\n",
        "\n",
        "    def _plot_image_subplot(self, ax, image: Any) -> None:\n",
        "        ax.imshow(image, cmap='gray')\n",
        "        ax.axis('off')\n",
        "\n",
        "    def _plot_prediction_subplot(self, ax, true_label: int, model_predictions: Dict[str, Any], class_names: List[str], index: int) -> None:\n",
        "        actual_class = class_names[true_label]\n",
        "        texts = [f\"Actual: {actual_class}\"]\n",
        "        colors = ['black']\n",
        "\n",
        "        for model_name, prediction in model_predictions.items():\n",
        "            current_prediction = prediction[index].item()\n",
        "            predicted_class = class_names[int(current_prediction > 0.5)]\n",
        "            probability = current_prediction if predicted_class == class_names[1] else 1 - current_prediction\n",
        "            color = 'green' if actual_class == predicted_class else 'red'\n",
        "            texts.append(f\"{model_name}: {predicted_class} (Prob: {probability:.2f})\")\n",
        "            colors.append(color)\n",
        "\n",
        "        ax.axis('off')\n",
        "        text_spacing = 0.1\n",
        "        start_position = 1.0\n",
        "        for idx, (text, color) in enumerate(zip(texts, colors)):\n",
        "            ax.text(0.5, start_position - (idx * text_spacing), text, \n",
        "                    ha='center', va='center', fontsize=10, color=color, \n",
        "                    transform=ax.transAxes)\n",
        "\n",
        "    def plot_dataset_predictions(self, images: Any, true_labels: Any, model_predictions: Dict[str, Any], dataset_name: str, class_names: List[str], num_images_to_display: int) -> None:\n",
        "        images = images[:num_images_to_display]\n",
        "        true_labels = true_labels[:num_images_to_display]\n",
        "        fig, axes = plt.subplots(2, len(images), figsize=(3 * len(images), 5))\n",
        "        plt.suptitle(f\"Dataset: {dataset_name}\", fontsize=16, y=1.1)\n",
        "\n",
        "        for i in range(len(images)):\n",
        "            self._plot_image_subplot(axes[0, i], images[i])\n",
        "            self._plot_prediction_subplot(axes[1, i], true_labels[i], model_predictions, class_names, i)\n",
        "\n",
        "        plt.tight_layout(pad=1.0)\n",
        "        plt.subplots_adjust(hspace=0.2)\n",
        "        plt.show()\n",
        "\n",
        "def evaluate_models_on_datasets(datasets: Dict[str, Any], best_models: Dict[str, Any], class_names_map: Dict[str, List[str]], num_images_to_display: int = 5) -> None:\n",
        "    batch_size = config['BATCH_SIZE']\n",
        "    adjusted_class_names_map = {key.lower().replace(\"_label\", \"\"): value for key, value in class_names_map.items()}\n",
        "    plotter = PredictionPlotter(adjusted_class_names_map)\n",
        "    \n",
        "    for dataset_name, ds in datasets.items():\n",
        "        adjusted_dataset_name = dataset_name.lower().replace(\"_label\", \"\")\n",
        "        test_ds = ds['test'].batch(batch_size).cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "        test_images, test_labels = next(iter(test_ds))\n",
        "        test_labels = test_labels.numpy()\n",
        "        relevant_models = {key: model for key, model in best_models.items() if key.endswith(adjusted_dataset_name)}\n",
        "        predictions = {key.rsplit('_', 1)[0]: model.predict(test_images) for key, model in relevant_models.items()}\n",
        "        plotter.plot_dataset_predictions(test_images, test_labels, predictions, dataset_name, adjusted_class_names_map[adjusted_dataset_name], num_images_to_display)\n",
        "\n",
        "# Usage\n",
        "BATCH_SIZE = config['BATCH_SIZE']  # Assuming config is a dictionary defined elsewhere\n",
        "class_names_map = {\n",
        "    'Focus_Label': [\"OutOfFocus\", \"InFocus\"],\n",
        "    'StigX_Label': [\"NotStiggedX\", \"StiggedX\"],\n",
        "    'StigY_Label': [\"NotStiggedY\", \"StiggedY\"]\n",
        "}\n",
        "evaluate_models_on_datasets(datasets, best_models, class_names_map, num_images_to_display=5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ljdud4fAdg5"
      },
      "source": [
        "## In Development"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "def plot_confusion_matrix(true_labels, pred_labels, class_names):\n",
        "    confusion = tf.math.confusion_matrix(true_labels, pred_labels)\n",
        "    with tf.Session().as_default():\n",
        "        cm = confusion.eval()\n",
        "\n",
        "        # Normalize to get percentage heatmap\n",
        "        normalized_cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        normalized_cm *= 100\n",
        "\n",
        "        ax = _extracted_from_plot_confusion_matrix_11(\"Percentage Heatmap\")\n",
        "        sn.heatmap(normalized_cm, annot=True, cmap=\"Blues\", ax=ax, xticklabels=class_names, yticklabels=class_names, vmin=0, vmax=100)\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Calculate additional metrics for Count Heatmap\n",
        "        cm_with_metrics = np.array([np.append(row, [np.nan, np.sum(row), round((row[i]/np.sum(row))*100)], axis=0) for (i, row) in enumerate(cm)])\n",
        "        cm_with_metrics = cm_with_metrics.transpose()\n",
        "        cm_with_metrics = np.array(\n",
        "            [\n",
        "                np.append(\n",
        "                    row,\n",
        "                    [\n",
        "                        np.nan,\n",
        "                        np.sum(row),\n",
        "                        round((max(row) / np.sum(row)) * 100),\n",
        "                    ],\n",
        "                    axis=0,\n",
        "                )\n",
        "                for row in cm_with_metrics\n",
        "            ]\n",
        "        )\n",
        "        cm_with_metrics = cm_with_metrics.transpose()\n",
        "\n",
        "        last = len(cm_with_metrics) - 1\n",
        "        cm_with_metrics[last][last - 2] = np.sum(cm_with_metrics[last][:4] / len(cm_with_metrics[last][:4]))\n",
        "        cm_with_metrics = cm_with_metrics.transpose()\n",
        "        cm_with_metrics[last][last - 2] = np.sum(cm_with_metrics[last][:4] / len(cm_with_metrics[last][:4]))\n",
        "        cm_with_metrics = cm_with_metrics.transpose()\n",
        "\n",
        "        # Plot Count Heatmap\n",
        "        extended_class_names = class_names + [None, 'Total Ground Truth', 'Total Predictions', 'Recall', 'Precision']\n",
        "        ax = _extracted_from_plot_confusion_matrix_11(\"Count Heatmap\")\n",
        "        sn.heatmap(cm_with_metrics, annot=True, cmap=\"Blues\", fmt='g', ax=ax, xticklabels=extended_class_names, yticklabels=extended_class_names)\n",
        "        plt.tight_layout()\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "# TODO Rename this here and in `plot_confusion_matrix`\n",
        "def _extracted_from_plot_confusion_matrix_11(arg0):\n",
        "        # Plot Percentage Heatmap\n",
        "    fig, result = plt.subplots(figsize=(5, 5))\n",
        "    result.xaxis.tick_top()\n",
        "    result.set_title(arg0)\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_models_on_datasets(datasets: Dict[str, Any], best_models: Dict[str, Any], class_names_map: Dict[str, List[str]], num_images_to_display: int = 5) -> None:\n",
        "    batch_size = config['BATCH_SIZE']  # Assuming config is a dictionary defined elsewhere\n",
        "    adjusted_class_names_map = {key.lower().replace(\"_label\", \"\"): value for key, value in class_names_map.items()}\n",
        "    plotter = PredictionPlotter(adjusted_class_names_map)\n",
        "    \n",
        "    for dataset_name, ds in datasets.items():\n",
        "        adjusted_dataset_name = dataset_name.lower().replace(\"_label\", \"\")\n",
        "        test_ds = ds['test'].batch(batch_size).cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "        test_images, test_labels = next(iter(test_ds))\n",
        "        test_labels = test_labels.numpy()\n",
        "        relevant_models = {key: model for key, model in best_models.items() if key.endswith(adjusted_dataset_name)}\n",
        "        predictions = {key.rsplit('_', 1)[0]: model.predict(test_images) for key, model in relevant_models.items()}\n",
        "        \n",
        "        # Plot dataset predictions\n",
        "        plotter.plot_dataset_predictions(test_images, test_labels, predictions, dataset_name, adjusted_class_names_map[adjusted_dataset_name], num_images_to_display)\n",
        "\n",
        "        # Plot confusion matrices for each model\n",
        "        for model_name, pred in predictions.items():\n",
        "            pred_labels = np.argmax(pred, axis=1)\n",
        "            print(f\"Confusion Matrix for {model_name} on {dataset_name}\")\n",
        "            plot_confusion_matrix(test_labels, pred_labels, adjusted_class_names_map[adjusted_dataset_name])\n",
        "\n",
        "# Usage\n",
        "BATCH_SIZE = config['BATCH_SIZE']  # Assuming config is a dictionary defined elsewhere\n",
        "class_names_map = {\n",
        "    'Focus_Label': [\"OutOfFocus\", \"InFocus\"],\n",
        "    'StigX_Label': [\"NotStiggedX\", \"StiggedX\"],\n",
        "    'StigY_Label': [\"NotStiggedY\", \"StiggedY\"]\n",
        "}\n",
        "evaluate_models_on_datasets(datasets, best_models, class_names_map, num_images_to_display=5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bIJphomBC8cX"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, auc, precision_recall_curve, average_precision_score\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "sns.set(style=\"whitegrid\")  # Set seaborn style\n",
        "\n",
        "batch_size = 32  # Define the batch size\n",
        "\n",
        "# Rest of your code...\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, auc, precision_recall_curve, average_precision_score\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "sns.set(style=\"whitegrid\")  # Set seaborn style\n",
        "\n",
        "def plot_confusion_matrix(ax, y_true, y_pred, class_names):\n",
        "    \"\"\"Plot the confusion matrix.\"\"\"\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", ax=ax, cmap='Blues', cbar=False)\n",
        "    ax.set_title('Confusion Matrix')\n",
        "    ax.set_xticklabels(class_names)\n",
        "    ax.set_yticklabels(class_names, rotation=0)\n",
        "    ax.set_xlabel('Predicted')\n",
        "    ax.set_ylabel('Actual')\n",
        "\n",
        "def plot_roc_curve(ax, y_true, y_score):\n",
        "    \"\"\"Plot the ROC curve.\"\"\"\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_score)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    ax.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC (AUC = {roc_auc:.2f})')\n",
        "    ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    ax.set_xlabel('False Positive Rate')\n",
        "    ax.set_ylabel('True Positive Rate')\n",
        "    ax.set_title('ROC Curve')\n",
        "    ax.legend(loc='lower right')\n",
        "\n",
        "def plot_precision_recall_curve(ax, y_true, y_score):\n",
        "    \"\"\"Plot the Precision-Recall curve.\"\"\"\n",
        "    precision, recall, _ = precision_recall_curve(y_true, y_score)\n",
        "    average_precision = average_precision_score(y_true, y_score)\n",
        "    ax.plot(recall, precision, color='darkorange', lw=2, label=f'AP = {average_precision:.2f}')\n",
        "    ax.set_xlabel('Recall')\n",
        "    ax.set_ylabel('Precision')\n",
        "    ax.set_title('Precision-Recall Curve')\n",
        "    ax.legend(loc='upper right')\n",
        "\n",
        "def evaluate_and_plot_metrics(ax_row, model, test_dataset, class_names):\n",
        "    test_dataset = test_dataset.batch(batch_size)\n",
        "    test_images, test_labels = [], []\n",
        "\n",
        "    for images, labels in test_dataset:\n",
        "        test_images.append(images)\n",
        "        test_labels.append(labels)\n",
        "\n",
        "    test_images = np.vstack(test_images)\n",
        "    test_labels = np.concatenate(test_labels)\n",
        "\n",
        "    # If the shapes look okay, proceed with evaluation\n",
        "    evaluation_metrics = model.evaluate(test_dataset)\n",
        "    test_loss, test_accuracy = evaluation_metrics[0], evaluation_metrics[1]\n",
        "    print(f\"Test accuracy: {test_accuracy * 100:.2f}%\")\n",
        "\n",
        "    # ... (rest of your function)\n",
        "\n",
        "    # Get predictions\n",
        "    predictions = model.predict(test_images)\n",
        "    y_pred = (predictions > 0.5).astype(int).flatten()\n",
        "    y_score = predictions.flatten()\n",
        "\n",
        "    # Plot metrics\n",
        "    plot_confusion_matrix(ax_row[0], test_labels, y_pred, class_names)\n",
        "    plot_roc_curve(ax_row[1], test_labels, y_score)\n",
        "    plot_precision_recall_curve(ax_row[2], test_labels, y_score)\n",
        "\n",
        "def main_evaluation(datasets, best_models, class_names_map):\n",
        "    \"\"\"Main function for evaluation.\"\"\"\n",
        "    # Create subplots\n",
        "    num_datasets = len(datasets)\n",
        "    fig, axes = plt.subplots(3 * num_datasets, len(best_models), figsize=(15, 5 * num_datasets))\n",
        "\n",
        "    for i, (dataset_name, dataset_splits) in enumerate(datasets.items()):\n",
        "        print(f\"Evaluating models on {dataset_name} dataset...\")\n",
        "        \n",
        "        # Remove '_Label' from dataset_name to match with class_names_map keys\n",
        "        simplified_dataset_name = dataset_name.replace('_Label', '')\n",
        "        \n",
        "        class_names = class_names_map.get(simplified_dataset_name, ['Class 0', 'Class 1'])  # Default to ['Class 0', 'Class 1']\n",
        "\n",
        "        for j, (model_name, model) in enumerate(best_models.items()):\n",
        "            print(f\"Evaluating {model_name}...\")\n",
        "            ax_row = axes[3 * i: 3 * (i + 1), j]\n",
        "            \n",
        "            # Use 'test' split for evaluation\n",
        "            test_dataset = dataset_splits.get('test', None)\n",
        "            if test_dataset is not None:\n",
        "                evaluate_and_plot_metrics(ax_row, model, test_dataset, class_names)\n",
        "            else:\n",
        "                print(f\"Test dataset not found for {dataset_name}\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "# Run the main evaluation function\n",
        "main_evaluation(datasets, best_models, class_names_map)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "X5fVaBWTjbUp"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
